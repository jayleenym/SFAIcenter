{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 도서 정보 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "base_dir = \"/Users/jinym/Library/CloudStorage/OneDrive-개인/데이터L/selectstar\"\n",
    "# base_dir = \"/Users/yejin/Library/CloudStorage/OneDrive-개인/데이터L/selectstar\"\n",
    "data_dir = os.path.join(base_dir, 'data', 'ORIGINAL', '1C')\n",
    "\n",
    "analysis = {1:'1차 분석', 2:'2차 분석', 3: '3차 분석'}\n",
    "buy = {1:'1차 구매', 2:'2차 구매', 3: '3차 구매'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_analy = pd.read_excel(os.path.join(base_dir, '도서목록_전체통합.xlsx'), sheet_name=analysis[1], header=3)[['관리번호', 'ISBN', '도서명','분류']]\n",
    "excel_buy = pd.read_excel(os.path.join(base_dir, '도서목록_전체통합.xlsx'), sheet_name=buy[1], header=4)[['ISBN', '도서명', '출판일', '코퍼스 1분류', '코퍼스 2분류', '비고']]\n",
    "excel_buy.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lv2 파일명 변경, Lv3/4/5 폴더 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "Lv3_isbn_id = excel_analy[excel_analy['분류'] == 'Lv3/4']\n",
    "Lv5_isbn_id = excel_analy[excel_analy['분류'] == 'Lv5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lv3_isbn_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 폴더 만들어서 옮기기\n",
    "# for id in cycle1_isbn_id['관리번호']:\n",
    "#     id = str(id)\n",
    "\n",
    "#     os.mkdir(os.path.join(data_dir, id))\n",
    "#     os.rename(os.path.join(data_dir, id+'.json'), os.path.join(data_dir, id, id+'.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (isbn, id) in zip(cycle1_isbn_id['ISBN'], cycle1_isbn_id['관리번호']):\n",
    "#     # print(isbn, id)\n",
    "#     # 복사할 파일 경로\n",
    "#     source_file = os.path.join(data_dir, '1C_0902', str(isbn)+'.json')\n",
    "#     # 복사할 목적지 경로\n",
    "#     destination_path = os.path.join(data_dir, '1C_0902')\n",
    "#     # 이름변경\n",
    "#     shutil.copy2(source_file, os.path.join(destination_path, str(id)+\".json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lv분류\n",
    "lv34 = os.path.join(data_dir, \"Lv3_4\")\n",
    "lv5 = os.path.join(data_dir, \"Lv5\")\n",
    "\n",
    "for id in os.listdir(data_dir):\n",
    "    if os.path.splitext(id)[0] in Lv3_isbn_id['관리번호'].astype(str).tolist():\n",
    "        shutil.move(os.path.join(data_dir, str(id)), lv34)\n",
    "    elif os.path.splitext(id)[0] in Lv5_isbn_id['관리번호'].astype(str).tolist():\n",
    "        shutil.move(os.path.join(data_dir, str(id)), lv5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.splitext(id)[0] in Lv5_isbn_id['관리번호'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id in Lv3_isbn_id['관리번호'].astype(str).tolist()\n",
    "# print(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lv2 전체 형식 변경\n",
    "기본 형식  \n",
    "```json\n",
    "{\n",
    "    \"file_id\" : \"ISBN\",\n",
    "    \"title\" : \"도서명\",\n",
    "    \"코퍼스_1분류\" : \"\",\n",
    "    \"코퍼스_2분류\" : \"\",\n",
    "    \"비고\" : \"비문제집\",\n",
    "    \"출판일\" : \"2025-01-01\",\n",
    "    \"contents\": [\n",
    "        {\n",
    "            \"page\": \"0012\",\n",
    "            \"chapter\": \"\",\n",
    "            \"page_contents\": \"\",\n",
    "            \"add_info\": [\n",
    "                {\n",
    "                    \"tag\": \"note_0012_001\",\n",
    "                    \"type\": \"footnote\",\n",
    "                    \"description\": \"\",\n",
    "                    \"caption\": null,\n",
    "                    \"file_path\": null,\n",
    "                    \"bbox\": null\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_excel = pd.merge(excel_analy[excel_analy['분류'] == 'Lv2'], excel_buy, on=['ISBN', '도서명'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_excel = merge_excel[['관리번호', 'ISBN', '도서명', '출판일', '코퍼스 1분류', '코퍼스 2분류', '비고']].set_index('관리번호')\n",
    "merge_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "for id in os.listdir(data_dir):\n",
    "    id = 321494387\n",
    "    name = str(id)+'.json'\n",
    "    origin_name = str(merge_excel.loc[id, 'ISBN'])+'.json'\n",
    "    # new_name = str(id)+'_rev.json'\n",
    "    origin = json.load(open(os.path.join(base_dir, 'data', 'Lv2', '1C_107', origin_name), 'r', encoding='utf-8'))\n",
    "    # print(origin)\n",
    "    revision = {\n",
    "        'file_id': str(merge_excel.loc[id, 'ISBN']),\n",
    "        'title': merge_excel.loc[id, '도서명'],\n",
    "        'cat1_domain': merge_excel.loc[id, '코퍼스 1분류'],\n",
    "        'cat2_sub': merge_excel.loc[id, '코퍼스 2분류'],\n",
    "        'cat3_specific': merge_excel.loc[id, '비고'],\n",
    "        'pub_date': str(merge_excel.loc[id, '출판일'])[:10],\n",
    "        'contents': [],\n",
    "    }\n",
    "\n",
    "    for i in range(len(origin)):\n",
    "        contents_base = {\n",
    "        'page': f\"{origin[i]['page']:04d}\",\n",
    "        'chapter': \"\",\n",
    "        'page_contents': origin[i]['content'],\n",
    "            \"add_info\": []\n",
    "        }\n",
    "        revision['contents'].append(contents_base)\n",
    "    \n",
    "    json.dump(revision, open(os.path.join(data_dir, name), 'w', encoding='utf-8'), ensure_ascii=False, indent=4)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "for id in os.listdir(data_dir):\n",
    "    name = str(id)+'.json'\n",
    "    origin_name = str(merge_excel.loc[id, 'ISBN'])+'.json'\n",
    "    # new_name = str(id)+'_rev.json'\n",
    "    origin = json.load(open(os.path.join(base_dir, 'data', 'Lv2', '1C_107', origin_name), 'r', encoding='utf-8'))\n",
    "    # print(origin)\n",
    "    revision = {\n",
    "        'file_id': str(merge_excel.loc[id, 'ISBN']),\n",
    "        'title': merge_excel.loc[id, '도서명'],\n",
    "        'cat1_domain': merge_excel.loc[id, '코퍼스 1분류'],\n",
    "        'cat2_sub': merge_excel.loc[id, '코퍼스 2분류'],\n",
    "        'cat3_specific': merge_excel.loc[id, '비고'],\n",
    "        'pub_date': str(merge_excel.loc[id, '출판일'])[:10],\n",
    "        'contents': [],\n",
    "    }\n",
    "\n",
    "    for i in range(len(origin)):\n",
    "        contents_base = {\n",
    "        'page': f\"{origin[i]['page']:04d}\",\n",
    "        'chapter': \"\",\n",
    "        'page_contents': origin[i]['content'],\n",
    "            \"add_info\": []\n",
    "        }\n",
    "        revision['contents'].append(contents_base)\n",
    "    \n",
    "    json.dump(revision, open(os.path.join(data_dir, name), 'w', encoding='utf-8'), ensure_ascii=False, indent=4)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lv3/4/5 분류 이름 변경\n",
    "코퍼스_1분류, 코퍼스_2분류, 비고, 출판일 -> cat1_domain, cat2_sub, cat3_specific, pub_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>도서명</th>\n",
       "      <th>출판일</th>\n",
       "      <th>코퍼스 1분류</th>\n",
       "      <th>코퍼스 2분류</th>\n",
       "      <th>비고</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>관리번호</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290155840</th>\n",
       "      <td>9791138320030</td>\n",
       "      <td>2022 공무원 객관식 경제학 기출문제집 + 빈출계산문제 50선</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>금융</td>\n",
       "      <td>수험서</td>\n",
       "      <td>경제학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328073930</th>\n",
       "      <td>9791138342605</td>\n",
       "      <td>2024 SD에듀 공인회계사(CPA) 1차 세법 10개년 기출문제집</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>금융</td>\n",
       "      <td>수험서</td>\n",
       "      <td>CPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337872889</th>\n",
       "      <td>9791138371223</td>\n",
       "      <td>2024~2025 시대에듀 파생상품투자권유자문인력 한권으로 끝내기</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>증권</td>\n",
       "      <td>수험서</td>\n",
       "      <td>투자권유자문인력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339516636</th>\n",
       "      <td>9791138372602</td>\n",
       "      <td>2025 SD에듀 공인회계사 1차 경영학 10개년 기출문제해설</td>\n",
       "      <td>2024-05-30</td>\n",
       "      <td>금융</td>\n",
       "      <td>수험서</td>\n",
       "      <td>CPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342460463</th>\n",
       "      <td>9791138374910</td>\n",
       "      <td>2025 시대에듀 손해사정사 1차 10개년 기출문제해설 한권으로 끝내기</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>보험</td>\n",
       "      <td>수험서</td>\n",
       "      <td>손해사정사</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ISBN                                      도서명        출판일  \\\n",
       "관리번호                                                                           \n",
       "290155840  9791138320030      2022 공무원 객관식 경제학 기출문제집 + 빈출계산문제 50선 2022-04-04   \n",
       "328073930  9791138342605    2024 SD에듀 공인회계사(CPA) 1차 세법 10개년 기출문제집 2024-01-05   \n",
       "337872889  9791138371223     2024~2025 시대에듀 파생상품투자권유자문인력 한권으로 끝내기 2024-04-15   \n",
       "339516636  9791138372602       2025 SD에듀 공인회계사 1차 경영학 10개년 기출문제해설 2024-05-30   \n",
       "342460463  9791138374910  2025 시대에듀 손해사정사 1차 10개년 기출문제해설 한권으로 끝내기 2024-07-25   \n",
       "\n",
       "          코퍼스 1분류 코퍼스 2분류        비고  \n",
       "관리번호                                 \n",
       "290155840      금융     수험서       경제학  \n",
       "328073930      금융     수험서       CPA  \n",
       "337872889      증권     수험서  투자권유자문인력  \n",
       "339516636      금융     수험서       CPA  \n",
       "342460463      보험     수험서     손해사정사  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_excel = pd.merge(excel_analy[excel_analy['분류'] == 'Lv5'], excel_buy, on=['ISBN', '도서명'], how='inner')\n",
    "merge_excel = merge_excel[['관리번호', 'ISBN', '도서명', '출판일', '코퍼스 1분류', '코퍼스 2분류', '비고']].set_index('관리번호')\n",
    "merge_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>도서명</th>\n",
       "      <th>출판일</th>\n",
       "      <th>코퍼스 1분류</th>\n",
       "      <th>코퍼스 2분류</th>\n",
       "      <th>비고</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>관리번호</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290155840</th>\n",
       "      <td>9791138320030</td>\n",
       "      <td>2022 공무원 객관식 경제학 기출문제집 + 빈출계산문제 50선</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>금융</td>\n",
       "      <td>수험서</td>\n",
       "      <td>경제학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328073930</th>\n",
       "      <td>9791138342605</td>\n",
       "      <td>2024 SD에듀 공인회계사(CPA) 1차 세법 10개년 기출문제집</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>금융</td>\n",
       "      <td>수험서</td>\n",
       "      <td>CPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337872889</th>\n",
       "      <td>9791138371223</td>\n",
       "      <td>2024~2025 시대에듀 파생상품투자권유자문인력 한권으로 끝내기</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>증권</td>\n",
       "      <td>수험서</td>\n",
       "      <td>투자권유자문인력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339516636</th>\n",
       "      <td>9791138372602</td>\n",
       "      <td>2025 SD에듀 공인회계사 1차 경영학 10개년 기출문제해설</td>\n",
       "      <td>2024-05-30</td>\n",
       "      <td>금융</td>\n",
       "      <td>수험서</td>\n",
       "      <td>CPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342460463</th>\n",
       "      <td>9791138374910</td>\n",
       "      <td>2025 시대에듀 손해사정사 1차 10개년 기출문제해설 한권으로 끝내기</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>보험</td>\n",
       "      <td>수험서</td>\n",
       "      <td>손해사정사</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ISBN                                      도서명        출판일  \\\n",
       "관리번호                                                                           \n",
       "290155840  9791138320030      2022 공무원 객관식 경제학 기출문제집 + 빈출계산문제 50선 2022-04-04   \n",
       "328073930  9791138342605    2024 SD에듀 공인회계사(CPA) 1차 세법 10개년 기출문제집 2024-01-05   \n",
       "337872889  9791138371223     2024~2025 시대에듀 파생상품투자권유자문인력 한권으로 끝내기 2024-04-15   \n",
       "339516636  9791138372602       2025 SD에듀 공인회계사 1차 경영학 10개년 기출문제해설 2024-05-30   \n",
       "342460463  9791138374910  2025 시대에듀 손해사정사 1차 10개년 기출문제해설 한권으로 끝내기 2024-07-25   \n",
       "\n",
       "          코퍼스 1분류 코퍼스 2분류        비고  \n",
       "관리번호                                 \n",
       "290155840      금융     수험서       경제학  \n",
       "328073930      금융     수험서       CPA  \n",
       "337872889      증권     수험서  투자권유자문인력  \n",
       "339516636      금융     수험서       CPA  \n",
       "342460463      보험     수험서     손해사정사  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merg=merge_excel[merge_excel['코퍼스 2분류'] != '수험서']\n",
    "merg = merge_excel\n",
    "merg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 89] Operation canceled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m merg\u001b[38;5;241m.\u001b[39mindex:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     origin \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlv5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m         origin[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat1_domain\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/test/lib/python3.10/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 89] Operation canceled"
     ]
    }
   ],
   "source": [
    "# Lv분류\n",
    "# lv34 = os.path.join(data_dir, \"Lv3_4\")\n",
    "lv5 = os.path.join(data_dir, \"Lv5\")\n",
    "\n",
    "for id in merg.index:\n",
    "    id = str(id)\n",
    "    origin = json.load(open(os.path.join(lv5, id, id+\".json\"), 'r', encoding='utf-8'))\n",
    "    try:\n",
    "        origin['cat1_domain']\n",
    "    except:\n",
    "        revision = {\n",
    "            'file_id': origin['file_id'],\n",
    "            'title': origin['title'],\n",
    "            'cat1_domain': origin['코퍼스_1분류'],\n",
    "            'cat2_sub': origin['코퍼스_2분류'],\n",
    "            'cat3_specific': origin['비고'],\n",
    "            'pub_date': origin['출판일'],\n",
    "            'contents': origin['contents']\n",
    "        }\n",
    "    \n",
    "        json.dump(revision, open(os.path.join(lv5, id, id+\".json\"), 'w', encoding='utf-8'), ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'339516636'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 개별 처리\n",
    "- 불필요 페이지 제거\n",
    "- 오타\n",
    "- 페이지 머리말/꼬리말"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1차 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'356379574'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, json, os\n",
    "\n",
    "base_dir = \"data_yejin/FINAL/1C_0910\"\n",
    "data_dir = os.path.join(base_dir,'Lv3_4')\n",
    "\n",
    "# # lv2\n",
    "# name = sorted(os.listdir(data_dir))[1]\n",
    "\n",
    "# lv3/4\n",
    "names = []\n",
    "for n in sorted(os.listdir(data_dir)):\n",
    "    if n.endswith('workbook'):\n",
    "        names.append(n.split('_')[0])\n",
    "\n",
    "name = names[2].split('_')[0]\n",
    "origin = json.load(open(os.path.join(data_dir, name+'_workbook', name+'.json'), 'r', encoding='utf-8'))\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_split(txt, sep):\n",
    "    result = re.sub(r'(?<![.?!①②③④⑤\\[\\]])\\n(?!\\n)', ' ', txt)\n",
    "    return result.split(sep)\n",
    "\n",
    "def remove_enter(txt):\n",
    "    # 문장 내 엔터 처리 (안함)\n",
    "    return re.sub(r'(?<![.?!\\]])\\n(?!\\n)', ' ', txt)\n",
    "\n",
    "def extract_options(txt):\n",
    "    pattern = r'([①②③④⑤]\\s*[^①②③④⑤]*)'\n",
    "    options = re.findall(pattern, txt)\n",
    "    return [opt.replace(\"\\n\", \" \").strip() for opt in options if opt.strip()]\n",
    "\n",
    "def replace_number(number):\n",
    "    circle_numbers = {'1': '①', '2': '②', '3': '③', '4': '④', '5': '⑤'}\n",
    "    return circle_numbers[str(number)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chapter(c, n):\n",
    "    #  chapter 추출하기\n",
    "    page = int(c['page']) - n\n",
    "    regex = fr\"^(.*)\\n{page}\\n\"\n",
    "\n",
    "    chapter = re.findall(regex, c['page_contents'])\n",
    "\n",
    "    c['chapter'] = chapter[0].strip()\n",
    "    c['page_contents'] = re.sub(regex, \"\", c['page_contents'])\n",
    "    \n",
    "    # 248779244.json\n",
    "    # c['page_contents'] = re.sub(fr\"^{page}[가-힇]?\", \"\", c['page_contents'])\n",
    "    # c['page_contents'] = re.sub(title+str(page)+'\\n', \"\", c['page_contents'])\n",
    "    return c\n",
    "\n",
    "def fill_chapter(c):\n",
    "    # chapter 채우기\n",
    "    if (c['chapter'] == \"\") and i >= 1:\n",
    "        c['chapter'] = origin['contents'][i-1]['chapter']\n",
    "\n",
    "    # 284618539.json\n",
    "    # if c['page_contents'] == \"\": break\n",
    "    \n",
    "    # if (c['chapter'] == \"\") and i >= 1:\n",
    "    #     c['chapter'] = origin['contents'][i-1]['chapter']\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_qna(c):\n",
    "    print('---------------------')\n",
    "    print(c['page'])\n",
    "# for i in range(len())\n",
    "    # 문제추출\n",
    "    # qn_re = r'\\[문제\\d+\\]\\s'\n",
    "    qn_re = r'\\s?[0-9][0-9]'\n",
    "    # info_re = r'\\[\\w+[.]?\\d+\\w\\]\\s'\n",
    "    # q_re = r\"\\s*[^?]*\\?\"\n",
    "    # ans_re = r\"\\[정답\\]\"\n",
    "    ans_re = r\"\\s?정답\"\n",
    "    # exp_re = r\"\\s\\[해설\\]\"\n",
    "    exp_re = r\"\\s?해설\"\n",
    "    option_re = r\"\\s?①\"\n",
    "    \n",
    "    base_add_info = {\n",
    "                        'tag': \"\",\n",
    "                        'type': \"question\",\n",
    "                        \"description\": {\n",
    "                            \"number\": \"\",\n",
    "                            \"question\": \"\",\n",
    "                            \"options\": [],\n",
    "                            'answer' : \"\",\n",
    "                            \"explanation\": \"\"\n",
    "                        },\n",
    "                        \"caption\":[],\n",
    "                        \"file_path\": 0,\n",
    "                        \"bbox\": 0\n",
    "                        }\n",
    "\n",
    "    # 문제는 있음\n",
    "    if re.search(qn_re, c['page_contents']) is not None:\n",
    "\n",
    "        base_add_info['tag'] = f\"q_{c['page']}_0001\"\n",
    "\n",
    "        start = re.search(qn_re, c['page_contents']).span()[0]\n",
    "        try:\n",
    "            end = re.search(ans_re, c['page_contents']).span()[1]\n",
    "            # 한 페이지에 문제~정답 모두 있음\n",
    "            # qna = [qa for qa in re.split(fr\"({qn_re}|{info_re}|{q_re}|{exp_re}|{ans_re})\", c['page_contents'][start:]) if qa !=\"\"]\n",
    "            qna = [qa for qa in re.split(fr\"({qn_re}|{option_re}|{exp_re}|{ans_re})\", c['page_contents'][start:]) if qa !=\"\"]\n",
    "            # 태그처리\n",
    "            c['page_contents'] = c['page_contents'].replace(c['page_contents'][start:end+2], \"\\n{\"+f\"q_{c['page']}_0001\"+\"}\")\n",
    "        \n",
    "        except:\n",
    "            # 다음페이지 살펴보기\n",
    "            c2 = origin['contents'][i+1]\n",
    "            if re.search(ans_re, c2['page_contents']) is not None:\n",
    "                end = re.search(ans_re, c2['page_contents']).span()[1]\n",
    "\n",
    "                qna = [qa \n",
    "                    # for qa in re.split(fr\"({qn_re}|{info_re}|{q_re}|{exp_re}|{ans_re})\", \n",
    "                    for qa in re.split(fr\"({qn_re}|{option_re}|{exp_re}|{ans_re})\", \n",
    "                                        c['page_contents'][start:]+c2['page_contents'][:end+2])\n",
    "                    if qa !=\"\"\n",
    "                    ]\n",
    "                \n",
    "                # 태그처리\n",
    "                c['page_contents'] = c['page_contents'].replace(c['page_contents'][start:], \"\\n{\"+f\"q_{c['page']}_0001\"+\"}\")\n",
    "                c2['page_contents'] = c2['page_contents'].replace(c2['page_contents'][:end+2], \"\")\n",
    "            \n",
    "            # 그 다음 페이지도 살펴보기\n",
    "            elif re.search(ans_re, c2['page_contents']) is None:\n",
    "                c3 = origin['contents'][i+2]\n",
    "                if re.search(ans_re, c3['page_contents']) is not None:\n",
    "                    end = re.search(ans_re, c3['page_contents']).span()[1]\n",
    "                    qna = [qa \n",
    "                        # for qa in re.split(fr\"({qn_re}|{info_re}|{q_re}|{exp_re}|{ans_re})\", \n",
    "                        for qa in re.split(fr\"({qn_re}|{option_re}|{exp_re}|{ans_re})\", \n",
    "                                            c['page_contents'][start:]+c2['page_contents']+c3['page_contents'][:end+2])\n",
    "                        if qa !=\"\"\n",
    "                        ]\n",
    "                    \n",
    "                    # 태그처리\n",
    "                    c['page_contents'] = c['page_contents'].replace(c['page_contents'][start:], \"\\n{\"+f\"q_{c['page']}_0001\"+\"}\")\n",
    "                    c2['page_contents'] = c2['page_contents'].replace(c2['page_contents'], \"\")\n",
    "                    c3['page_contents'] = c3['page_contents'].replace(c3['page_contents'][:end+2], \"\")\n",
    "            else:\n",
    "                print(\"못찾겟다..\")\n",
    "\n",
    "        print(qna)\n",
    "        for x in range(len(qna)):\n",
    "            if re.search(qn_re, qna[x]) is not None:\n",
    "                # number = re.search(r'\\[문제(\\d+)*\\]', qna[x]).group(1)\n",
    "                number = qna[x].strip()\n",
    "                print('number:', number)\n",
    "                # if int(number) < 10:\n",
    "                #     number = f\"{int(number):02}\"\n",
    "                base_add_info['description']['number'] = number\n",
    "                try:\n",
    "                    question = qna[x+1]\n",
    "                    question = question.strip()\n",
    "\n",
    "                    base_add_info['description']['question'] = question\n",
    "                except:\n",
    "                    print(\"(ERROR) question:\", question)\n",
    "\n",
    "            # if re.search(info_re, qna[x]) is not None:\n",
    "            #     base_add_info['caption'].append(re.search(r'\\[(\\w+[.]?\\d+\\w)\\]', qna[x]).group(1))\n",
    "            #     if base_add_info['caption'][0].startswith(\"문제\"):\n",
    "            #         base_add_info['caption'].pop(0)\n",
    "\n",
    "            # if re.search(q_re, qna[x]) is not None:\n",
    "            #     question = re.search(r'\\s*([^?]*\\?)', qna[x]).group(1)\n",
    "            #     options = [ca.strip() for ca in n_split(qna[x+1].replace(\"❑\",\"\"), \"\\n\") if ca != \"\"]\n",
    "            #     for ct in range(len(options)):\n",
    "            #         if '①' not in options[0]:\n",
    "            #             question += \" \"+options[0]\n",
    "                        # options = options[1:]\n",
    "                \n",
    "            if re.search(option_re, qna[x]) is not None:\n",
    "                try:\n",
    "                    options = [qna[x]+qna[x+1]]\n",
    "                except:\n",
    "                    print(\"(ERROR) options:\", options)\n",
    "                if len(options) == 1:\n",
    "                    options = extract_options(options[0])\n",
    "                print(\"options_re:\", options)\n",
    "                base_add_info['description']['options'] = options\n",
    "\n",
    "            if re.search(exp_re, qna[x]) is not None:\n",
    "                explanation = qna[x+1].strip()\n",
    "                print(\"explanation:\", explanation)\n",
    "                base_add_info['description']['explanation'] = explanation\n",
    "\n",
    "            if re.search(ans_re, qna[x]) is not None:\n",
    "                answer = qna[x+1].strip()\n",
    "                print(\"answer:\", answer)\n",
    "                if answer in \"①②③④⑤\":\n",
    "                    base_add_info['description']['answer'] = answer\n",
    "                elif answer.isnumeric():\n",
    "                    answer = replace_number(answer)\n",
    "                    base_add_info['description']['answer'] = answer\n",
    "                else:\n",
    "                    print(c['page'], end, answer)\n",
    "            \n",
    "            base_add_info['caption'].append(\"매경 TEST 기출 문제\")\n",
    "\n",
    "        c['add_info'].append(base_add_info)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_footnote(c):\n",
    "    # 각주 처리\n",
    "    for fn in range(1, 43):\n",
    "        if f\"\\n{fn} \" in c['page_contents']:\n",
    "            start = c['page_contents'].find(f\"\\n{fn} \")\n",
    "            tag = f\"note_{c['page']}_{len(c['add_info'])+1:04}\"\n",
    "\n",
    "            c['add_info'].append(\n",
    "                {\n",
    "                    \"tag\": tag,\n",
    "                    \"type\": \"footnote\",\n",
    "                    \"description\": c['page_contents'][start+1:], # 두개 겹쳐있으면 그대로..\n",
    "                    \"caption\": 0,\n",
    "                    \"file_path\": 0,\n",
    "                    \"bbox\": 0\n",
    "                }\n",
    "            )\n",
    "            c['page_contents'] = c['page_contents'].replace(c['page_contents'][start:], \"{\"+tag+\"}\")\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = {\n",
    "    'file_id': origin['file_id'],\n",
    "    'title': origin['title'],\n",
    "    'cat1_domain': origin['cat1_domain'],\n",
    "    'cat2_sub': origin['cat2_sub'],\n",
    "    'cat3_specific': origin['cat3_specific'],\n",
    "    'pub_date': origin['pub_date'],\n",
    "    'contents': [],\n",
    "}\n",
    "\n",
    "for i in range(len(origin['contents'])):\n",
    "    contents = origin['contents'][i]\n",
    "    \n",
    "    # c = extract_qna(contents)\n",
    "    c = contents\n",
    "\n",
    "    \n",
    "    if len(c['page_contents']) > 0:\n",
    "        new['contents'].append(c)\n",
    "\n",
    "json.dump(new, open(os.path.join(data_dir, name+\"_workbook\", name+'.json'), 'w', encoding='utf-8'), ensure_ascii=False, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(new, open(os.path.join(data_dir, name+\"_workbook\", name+'_new.json'), 'w', encoding='utf-8'), ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = [\n",
    "  \"◆ ① (O) [상법 제317조 제2항 제8호, 제9호]\",\n",
    "                            \"◆ ② (O) [상법 제342조의2 제1항]\",\n",
    "                            \"◆ ③ (O) [상법 제382조 제3항 제1호]\",\n",
    "                            \"◆ ④ (X) 두지 못한다. [상법 제408조의2 제1항] / ⑤ (O) [상법 제408조의2 제2항]\",\n",
    "                            \"✓ 제408조의2(집행임원 설치회사, 집행임원과 회사의 관계) ① 회사는 집행임원을 둘 수 있다. 이 경우 집행임원을 둔 회사(이하 \\\"집행임원 설치회사\\\"라 한다) 는 대표이사를 두지 못한다.\",\n",
    "                            \"✓ ② 집행임원 설치회사와 집행임원의 관계는 「민법」 중 위임에 관한 규정을 준용한다.\"\n",
    "]\n",
    "\n",
    "exp = \"\\n\".join(exp).replace('◆ ', \"\")\n",
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2차 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, os\n",
    "\n",
    "base_dir = \"/Users/yejin/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/data/FINAL\"\n",
    "data_dir = os.path.join(base_dir, '1C_0902', 'Lv2')\n",
    "\n",
    "name = sorted(os.listdir(data_dir))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = json.load(open(os.path.join(data_dir, name, name+'.json'), 'r', encoding='utf-8'))\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5분 손해사정사 제3보험 (321494387) - 기출/답안 추출\n",
    "new = {\n",
    "    'file_id': origin['file_id'],\n",
    "    'title': origin['title'],\n",
    "    'cat1_domain': origin['cat1_domain'],\n",
    "    'cat2_sub': origin['cat2_sub'],\n",
    "    'cat3_specific': origin['cat3_specific'],\n",
    "    'pub_date': origin['pub_date'],\n",
    "    'contents': [],\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(len(origin['contents'])):\n",
    "    # i = 126\n",
    "    c = origin['contents'][i]\n",
    "\n",
    "    base_add_info = {\n",
    "    'tag': \"\",\n",
    "    'type': \"question\",\n",
    "    \"description\": {\n",
    "        \"number\": \"\",\n",
    "        \"question\": \"\",\n",
    "        \"options\": 0,\n",
    "        'answer' : \"\",\n",
    "        \"explanation\": \"\"\n",
    "    },\n",
    "    \"caption\":[],\n",
    "    \"file_path\": 0,\n",
    "    \"bbox\": 0\n",
    "    }\n",
    "    # 문제추출\n",
    "    q_re = r'\\[[0-9]{4} 기출\\]'\n",
    "    ans_re = r'\\[[0-9]{4} 답안\\]'\n",
    "    key_re = r'\\s키워드'\n",
    "\n",
    "    # break\n",
    "    try:\n",
    "    # if 1:\n",
    "        # [기출] ~ [답안]꼴\n",
    "        q_start = re.search(q_re, c['page_contents']).span()[0]\n",
    "        q_end = re.search(ans_re, c['page_contents'][q_start:]).span()[0] # 그꼴이 아니면 여기서 에러남\n",
    "        a_start = q_end + q_start\n",
    "        \n",
    "        question = c['page_contents'][q_start:q_start+q_end]\n",
    "\n",
    "       \n",
    "        # caption 달기\n",
    "        caption = re.findall(r'\\[([0-9]{4} 기출)\\]', question)[0]\n",
    "        base_add_info['caption'].append(caption)\n",
    "\n",
    "        question = re.sub(q_re, \"\", question).strip()      \n",
    "\n",
    "         # 문제번호 뽑기\n",
    "        number = re.findall(r\"\\D?(\\d+)\\D?\\s\", question)[0]\n",
    "        base_add_info['description']['number'] = number.strip()\n",
    "        question = re.sub(r\"\\D?\\d+\\D?\\s\", \"\", question).strip()\n",
    "\n",
    "\n",
    "        # 태그 처리\n",
    "        tag = f\"q_{c['page']}_0001\"\n",
    "        base_add_info['tag'] = tag\n",
    "\n",
    "        \n",
    "                \n",
    "        # 한 페이지에 [답안] 없으면\n",
    "        if re.search(key_re, c['page_contents'][a_start:]) is None:\n",
    "            print(\"in two pages\")\n",
    "            c2 = origin['contents'][i+1]\n",
    "            a_end = re.search(key_re, c2['page_contents']).span()[0]\n",
    "            # print(c2)\n",
    "            answer = c['page_contents'][a_start:] + '\\n' + c2['page_contents'][:a_end]\n",
    "\n",
    "            c['page_contents'] += '\\n' + c2['page_contents'][:a_end]\n",
    "            c2['page_contents'] = c2['page_contents'].replace(c2['page_contents'][:a_end], \"\")\n",
    "\n",
    "            c['page_contents'] = c['page_contents'].replace(c['page_contents'][q_start:], \"{\"+tag+\"}\")\n",
    "\n",
    "            if c2['page_contents'].strip().startswith('키워드'):\n",
    "                keyword_org = c2['page_contents'].strip().split(\"\\n\")[0]\n",
    "                keyword = keyword_org.replace(\"키워드\", \"키워드: \").replace(\"  \", \" \")\n",
    "                base_add_info['caption'].append(keyword)\n",
    "                c2['page_contents'] = c2['page_contents'].replace(\"\\n\"+keyword_org, \"\")\n",
    "            # print(c2)\n",
    "        # 한 페이지에 [답안]까지 있음\n",
    "        else:\n",
    "            print(\"in one page\")\n",
    "            a_end = re.search(key_re, c['page_contents'][a_start:]).span()[0]\n",
    "            answer = c['page_contents'][a_start:a_start+a_end]\n",
    "            if c['page_contents'][a_start+a_end:].strip().startswith('키워드'):\n",
    "                keyword_org = c['page_contents'][a_start+a_end:].strip().split(\"\\n\")[0]\n",
    "                keyword = keyword_org.replace(\"키워드\", \"키워드: \").replace(\"  \", \" \")\n",
    "                base_add_info['caption'].append(keyword)\n",
    "\n",
    "            c['page_contents'] = c['page_contents'].replace(c['page_contents'][q_start:a_start+a_end], \"{\"+tag+\"}\")\n",
    "            c['page_contents'] = c['page_contents'].replace(\"\\n\"+keyword_org, \"\")\n",
    "\n",
    "        answer = re.sub(ans_re, \"\", answer)\n",
    "        \n",
    "\n",
    "        base_add_info['description']['question'] = question.strip()\n",
    "        base_add_info['description']['answer'] = answer.strip()\n",
    "\n",
    "        c['add_info'].append(base_add_info)\n",
    "\n",
    "    except Exception as e:\n",
    "    # else:\n",
    "        if re.search(q_re, c['page_contents']) is not None:\n",
    "            print(c['page'])\n",
    "        else:\n",
    "            # print(e, c['page'])\n",
    "            pass\n",
    "\n",
    "    # break\n",
    "    if len(c['page_contents']) > 0:\n",
    "        new['contents'].append(c)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # break\n",
    "\n",
    "# json.dump(origin, open(os.path.join(data_dir, name, name+'_new.json'), 'w', encoding='utf-8'), ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# add_info\n",
    "```json\n",
    "{\n",
    "    \"tag\": \"q_0000_0001\",\n",
    "    \"type\": \"question\",\n",
    "    \"description\": {\n",
    "        \"number\": \"\",\n",
    "        \"question\": \"\",\n",
    "        \"options\": [],\n",
    "        \"options\": null,\n",
    "        \"answer\": \"\",\n",
    "        \"explanation\": \"\"\n",
    "    },\n",
    "    \"caption\": [\n",
    "        \" 기출\",\n",
    "        \"키워드: \"\n",
    "    ],\n",
    "    \"file_path\": null,\n",
    "    \"bbox\": null\n",
    "},\n",
    "{\n",
    "    \"tag\": \"note_0000_0001\",\n",
    "    \"type\": \"footnote\",\n",
    "    \"description\": \"1 이러한 계약을 법적으로는 금전소비대차계약이라고 한다. 차용증서를 영어로는 I owe you.의 소리를 따라 IOU 라고 한다.\",\n",
    "    \"caption\": null,\n",
    "    \"file_path\": null,\n",
    "    \"bbox\": null\n",
    "},\n",
    "{\n",
    "    \"tag\": \"tb_0000_0001\",\n",
    "    \"type\": \"table\",\n",
    "    \"description\": \"\\\\begin{tabular}{|c|c|c|c|}\\n\\\\hline\\n나라 이름 & 지수 이름 & 포괄 종목 & 작성 기관 \\\\\\\\\\\\hline\\n\\\\multirow{2}{*}{한 국} & KOSPI & \\\\makecell[l]{유가증권시장 상장\\\\\\\\전종목} & 한국거래소 \\\\\\\\\\\\cline{2-4}\\n& KOSDAQ & \\\\makecell[l]{코스닥 상장 전종목} & 한국거래소 \\\\\\\\\\\\hline\\n\\\\multirow{4}{*}{미 국} & DJIA & \\\\makecell[l]{뉴욕거래소, 나스닥\\\\\\\\상장 30 개 종목} & 다우존스사 \\\\\\\\\\\\cline{2-4}\\n& S\\\\&P 500 & \\\\makecell[l]{뉴욕거래소,\\\\\\\\미국거래소, 나스닥\\\\\\\\상장 500 개 종목} & \\\\makecell[c]{Standard \\\\&\\\\\\\\Poors 사} \\\\\\\\\\\\hline\\n\\\\multirow{3}{*}{일 본} & TOPIX & \\\\makecell[l]{동경거래소 상장\\\\\\\\전종목} & 동경거래소 \\\\\\\\\\\\cline{2-4}\\n& NIKKEI 225 & \\\\makecell[l]{동경거래소 상장\\\\\\\\225 개 종목} & 일본경제신문사 \\\\\\\\\\\\hline\\n영 국 & FTSE 100 & \\\\makecell[l]{런던거래소 상장\\\\\\\\100 개 종목} & FTSE \\\\\\\\\\\\hline\\n독 일 & DAX 30 & \\\\makecell[l]{프랑크푸르트 거래소\\\\\\\\상장 30 개 종목} & Deutsche Boerse \\\\\\\\\\\\hline\\n프랑스 & CAC 40 & \\\\makecell[l]{Euronext Paris 상장\\\\\\\\40 개 종목} & Euronext \\\\\\\\\\\\hline\\n중 국 & 상해종합지수 & \\\\makecell[l]{상해거래소 상장\\\\\\\\전종목} & 상해거래소 \\\\\\\\\\\\hline\\n\\\\end{tabular}\",\n",
    "    \"caption\": [\n",
    "        \"표2. 주가지수 개요\"\n",
    "    ],\n",
    "    \"file_path\": \"??????/crop/tb_0000_0001.png\",\n",
    "    \"bbox\": null\n",
    "},\n",
    "{\n",
    "    \"tag\": \"img_0000_0001\",\n",
    "    \"type\": \"image\",\n",
    "    \"description\": null,\n",
    "    \"caption\": [\n",
    "        \"도표1: 경제주체간 상품, 생산요소 및 자금의 흐름\"\n",
    "    ],\n",
    "    \"file_path\": \"?????/crop/img_0000_0001.png\",\n",
    "    \"bbox\": null\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, os\n",
    "\n",
    "base_dir = \"/Users/yejin/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/data/FINAL\"\n",
    "data_dir = os.path.join(base_dir, '1C_0902', 'Lv2')\n",
    "\n",
    "json_files = []\n",
    "for root, _, files in os.walk(data_dir):\n",
    "    for f in files:\n",
    "        if f.endswith(\".json\"):\n",
    "            json_files.append(os.path.join(root, f))\n",
    "\n",
    "# json_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for js in json_files:\n",
    "    origin = json.load(open(js, 'r', encoding='utf-8'))\n",
    "    if str(origin).find('\": 0,') != -1:\n",
    "        print(js)\n",
    "        new = str(origin)\n",
    "        new = new.replace('\": 0,', '\": null,')\n",
    "        json.dump(new, open(js, 'w', encoding='utf-8'), ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(origin).find(\": 0,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = str(origin)\n",
    "print(new[791:800])\n",
    "new = new.replace(\": 0,\", \": null,\")\n",
    "print(new[791:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
