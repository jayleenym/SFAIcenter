{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "            { \n",
    "                \"tag\": \"q_0000_0001\", \n",
    "                \"type\": \"question\", \n",
    "                \"description\": { \n",
    "                    \"number\": \"\", \n",
    "                    \"question\": \"\", \n",
    "                    \"options\": [], \n",
    "                    \"options\": null, \n",
    "                    \"answer\": \"\", \n",
    "                    \"explanation\": \"\" \n",
    "                    }, \n",
    "                \"caption\": [ \n",
    "                    \"\" \n",
    "                    ], \n",
    "                \"file_path\": null, \n",
    "                \"bbox\": null \n",
    "            }, \n",
    "{ \n",
    "    \"tag\": \"note_0000_0001\", \n",
    "    \"type\": \"footnote\", \n",
    "    \"description\": \"1 이러한 계약을 법적으로는 금전소비대차계약이라고 한다. 차용증서를 영어로는 I owe you.의 소리를 따라 IOU 라고 한다.\", \n",
    "    \"caption\": null, \n",
    "    \"file_path\": null, \n",
    "    \"bbox\": null \n",
    "}, \n",
    "{ \n",
    "    \"tag\": \"tb_0000_0001\", \n",
    "    \"type\": \"table\", \n",
    "    \"description\": \"\", \n",
    "    \"caption\": [], \n",
    "    \"file_path\": \"??????/crop/tb_0000_0001.png\", \n",
    "    \"bbox\": null \n",
    "}, \n",
    "{ \n",
    "    \"tag\": \"img_0000_0001\", \n",
    "    \"type\": \"image\", \n",
    "    \"description\": null, \n",
    "    \"caption\": [], \n",
    "    \"file_path\": \"?????/crop/img_0000_0001.png\", \n",
    "    \"bbox\": null \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lv2 파일명 변경, Lv3/4/5 폴더 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_path = \"/Users/jinym/Library/CloudStorage/OneDrive-개인/데이터L/selectstar\"\n",
    "analysis = {1:'1차 분석', 2:'2차 분석', 3: '3차 분석'}\n",
    "buy = {1:'1차 구매', 2:'2차 구매', 3: '3차 구매'}\n",
    "i = 2\n",
    "\n",
    "\n",
    "excel_analy = pd.read_excel(os.path.join(base_path, 'book_list_ALL.xlsx'), sheet_name=analysis[i], header=3)[['관리번호', 'ISBN', '도서명', '분류']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# zip_path = \"/Users/jinym/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/data/zip/250826_1차_원천코퍼스_보완사항반영\"\n",
    "# original_path = f\"/Users/jinym/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/data/ORIGINAL/{i}C\"\n",
    "\n",
    "# error_list = []\n",
    "\n",
    "# for fn, tn, isbn, lv in tqdm(zip(excel_analy['관리번호_old'], excel_analy['관리번호'], excel_analy['ISBN'], excel_analy['분류'])):\n",
    "#    fn = str(fn)\n",
    "#    if '/' in lv: \n",
    "#       lv = lv.replace(\"/\", '_')\n",
    "   \n",
    "#    if 'Lv' not in lv:\n",
    "#       continue\n",
    "\n",
    "#    # os.system(f\"cd /Users/yejin/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/data/ORIGINAL/1C/Lv2 && mv {isbn}.json {tn}.json\")\n",
    "#    if lv == 'Lv2':\n",
    "#       # os.system(f\"cd /Users/yejin/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/data/ORIGINAL/1C/Lv2 && mkdir {tn} && mv {tn}.json {tn}/\")\n",
    "#       continue\n",
    "#    else:\n",
    "#       os.system(f\"cp {zip_path}/{fn}.zip {original_path}/{lv}/{tn}.zip && cd {original_path}/{lv} && mkdir {tn} && unzip {tn}.zip -d {tn} && find . -type f -name '*{fn}*'| sed -e 'p' -e 's/{fn}/{tn}/g' | xargs -n 2 mv\")\n",
    "\n",
    "#       file_path = f\"{original_path}/{lv}/{tn}/{tn}.json\"\n",
    "#       try:\n",
    "#          with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#                content = f.read()\n",
    "         \n",
    "#          # Replace the old filename with new filename\n",
    "#          updated_content = content.replace(str(fn), str(tn))\n",
    "         \n",
    "#          with open(file_path, 'w', encoding='utf-8') as f:\n",
    "#                f.write(updated_content)\n",
    "               \n",
    "#          print(f\"Updated {fn} to {tn} in {file_path}\")\n",
    "#       except Exception as e:\n",
    "#          print(f\"Error processing {fn} to {tn}: {e}\")\n",
    "#          error_list.append((fn, tn, lv))\n",
    "#          # 이름 바꾸기\n",
    "#          # os.system(f\"cd {original_path}/{lv} && mkdir {tn} && unzip {tn}.zip -d {tn} && find . -type f -name '*{fn}*'| sed -e 'p' -e 's/{fn}/{tn}/g' | xargs -n 2 mv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import os, json\n",
    "\n",
    "original_path = \"/Users/jinym/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/data/ORIGINAL/2C/Lv5\"\n",
    "final_path = f\"/Users/jinym/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/data/FINAL/2C/Lv5\"\n",
    "\n",
    "for file in os.listdir(original_path):\n",
    "    if not file.startswith('SS'):\n",
    "        continue\n",
    "\n",
    "    with open(os.path.join(final_path, file, file+'.json.bak'), 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    with open(os.path.join(original_path, file, file+'.json'), 'r', encoding='utf-8') as f:\n",
    "        new_data = json.load(f)\n",
    "\n",
    "    # str_data = str(data)\n",
    "    # str_new_data = str(new_data)\n",
    "    # 'contents' 위치 찾기\n",
    "    # contents_pos_new = str_new_data.find('contents')\n",
    "    # contents_pos_data = str_data.find('contents')\n",
    "\n",
    "    # 슬라이싱을 사용하여 'contents' 이전 부분만 교체\n",
    "    # result = str_data[:contents_pos_data] + str_new_data[contents_pos_new:]\n",
    "    # break\n",
    "    with open(os.path.join(final_path, file, file+'.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(new_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "    # os.system(f\"cd {original_path} && mv -f {file}/{file}.json Lv5/{file}/ && rm -rf Lv5/{file}/crop && mv -f {file}/crop Lv5/{file}/\")\n",
    "    # os.system(f\"cd {original_path}/{file} && rmdir pdf_page && cd .. && rmdir {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from_path = \"/Users/jinym/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/evaluation/eval_data/8_multiple_exam_+\"\n",
    "to_path = \"yjmoon@oci004:/home/yjmoon/\"\n",
    "# to_path = \"yjmoon@oci004:/srv4-data/vanilla_models/\"\n",
    "\n",
    "\n",
    "# # 업로드\n",
    "os.system(f\"scp -r {from_path} {to_path}\")\n",
    "# # for ss in file:\n",
    "#     # os.system(f\"scp -r /Users/jinym/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/data/FINAL/3C/Lv3_4/{ss} yjmoon@oci004:/home/yjmoon/FINAL/{ss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"scp -r yjmoon@oci004:/home/yjmoon/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/evaluation/eval_data/8_multiple_exam_+/exam_+_result/* /Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/8_multiple_exam_+/exam_+_result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fn, tn, lv in zip(excel_analy['관리번호'], excel_analy['관리번호_new'], excel_analy['분류']):\n",
    "#     fn = str(fn)\n",
    "#     if '/' in lv: \n",
    "#        lv = lv.replace(\"/\", '_')\n",
    "# #     print(fn, tn, lv)\n",
    "    \n",
    "#     dir = os.path.join(pf.FINAL_DATA_PATH, pf.CYCLE_PATH[1], lv)\n",
    "#     os.system(f'cd {dir} && mv {fn}_low {tn}_low && cd {tn} &&'+f' for file in *{fn}*; do mv \"$file\" \"$'+'{file//'+fn+'/'+tn+'}\"; done')\n",
    "#     print(os.path.join(dir, fn))\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 개별 처리\n",
    "- 불필요 페이지 제거\n",
    "- 오타\n",
    "- 페이지 머리말/꼬리말"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 돌리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.ProcessFiles as pf\n",
    "\n",
    "excel = pf.get_excel_data(2)\n",
    "excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tools.ProcessLv2 as pl2\n",
    "\n",
    "path = '/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/data/FINAL/2C/Lv5'\n",
    "for file in os.listdir(path):\n",
    "    if not file.startswith('SS'):\n",
    "        continue\n",
    "\n",
    "    INPUT_PATH = os.path.join(path, file, file+'.json')\n",
    "    BACKUP_PATH = INPUT_PATH + \".bak\"\n",
    "\n",
    "    with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        origin = json.load(f)\n",
    "\n",
    "    # with open(BACKUP_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    #     json.dump(origin, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # id = excel[excel['ISBN'] == int(origin.get('file_id'))].index[0]\n",
    "    # break\n",
    "    id = os.path.splitext(os.path.basename(file))[0]\n",
    "    try:\n",
    "        new = {\n",
    "            'file_id': id,\n",
    "            'ISBN': str(excel.loc[id, 'ISBN']),\n",
    "            'title': excel.loc[id, '도서명'],\n",
    "            'cat1_domain': excel.loc[id, '코퍼스 1분류'],\n",
    "            'cat2_sub': excel.loc[id, '코퍼스 2분류'],\n",
    "            'cat3_specific': excel.loc[id, '비고'],\n",
    "            'pub_date': str(excel.loc[id, '출판일'])[:10],\n",
    "            # 'contents': [],\n",
    "            'contents': origin['contents']\n",
    "        }\n",
    "    except:\n",
    "        new = origin\n",
    "    \n",
    "    # break\n",
    "    # new = pl2.fill_chapter(origin)\n",
    "    # new = pl2.merge_paragraphs(origin)\n",
    "    # new = pl2.erase_page(origin, 1)\n",
    "    # new = pl2.format_change(3,origin)\n",
    "    # new = origin\n",
    "\n",
    "    # for i in range(len(new['contents'])):\n",
    "        # contents = new['contents'][i]\n",
    "        # # c = extract_qna(contents)\n",
    "        # page_contents = pl2.remove_enter(contents['page_contents'])\n",
    "        # contents['page_contents'] = page_contents\n",
    "        # # c = contents\n",
    "\n",
    "    with open(INPUT_PATH.replace(\".json\", \".json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    # # with open(INPUT_PATH.replace(\".json\", \"_new.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(new, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lv2 pdf_page 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# base_path = \"/Users/yejin/Library/CloudStorage/OneDrive-개인/데이터L/selectstar\"\n",
    "# analysis = {1:'1차 분석', 2:'2차 분석', 3: '3차 분석'}\n",
    "# buy = {1:'1차 구매', 2:'2차 구매', 3: '3차 구매'}\n",
    "# i = 3\n",
    "\n",
    "# excel_analy = pd.read_excel(os.path.join(base_path, 'book_list_ALL.xlsx'), sheet_name=analysis[i], header=3, engine='openpyxl')[['관리번호', 'ISBN', '도서명', '분류']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lv = excel_analy[excel_analy['관리번호'] == tn]['분류'].tolist()[0]\n",
    "# lv\n",
    "# # print(lv == 'Lv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fixed version - using Python file operations instead of sed\n",
    "# import shutil\n",
    "# from tqdm import tqdm\n",
    "# import fitz\n",
    "\n",
    "# dpi = 300\n",
    "# mat = fitz.Matrix(dpi / 150, dpi / 150)\n",
    "\n",
    "# # for tn, isbn, lv in tqdm(zip(excel_analy['관리번호'], excel_analy['ISBN'], excel_analy['분류'])):\n",
    "# for tn in tqdm(excel_analy['관리번호']):\n",
    "#    # if '/' in lv: \n",
    "#    #    lv = lv.replace(\"/\", '_')\n",
    "   \n",
    "#    # if 'Lv' not in lv:\n",
    "#    #    continue\n",
    "#    lv = excel_analy[excel_analy['관리번호'] == tn]['분류'].tolist()[0]\n",
    "#    # os.system(f\"cd /Users/yejin/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/data/ORIGINAL/1C/Lv2 && mv {isbn}.json {tn}.json\")\n",
    "#    if lv == 'Lv2':\n",
    "#       os.system(f\"cd /Users/yejin/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/data/ORIGINAL/{i}C/Lv2 && mkdir {tn} && mv {tn}*.json {tn}/ && cd {tn} && mkdir pdf_page\")\n",
    "#       # pdf_page 만들기\n",
    "#       pdf_path = f\"/Users/yejin/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/data/ORIGINAL/{i}C/Lv1/{tn}.pdf\"\n",
    "#       doc = fitz.open(pdf_path)\n",
    "#       for p, page in enumerate(doc):\n",
    "#          img = page.get_pixmap(matrix=mat)\n",
    "#          img.save(f\"/Users/yejin/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/data/ORIGINAL/{i}C/Lv2/{tn}/pdf_page/{tn}_{p+1:04d}.png\")\n",
    "      \n",
    "#       # break\n",
    "\n",
    "#    # SS0041 - SS0045 사이에서 MuPDF error: syntax error: invalid key in dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1C Lv2/3/4 문제에서 부족한 문제 뽑기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
