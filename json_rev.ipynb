{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도서 정보 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.ProcessFiles as pre_b\n",
    "excel = pre_b.get_excel_data(1) # i차 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lv2 파일명 변경, Lv3/4/5 폴더 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.ProcessFiles as pre_b\n",
    "pre_b.move_jsons(1) # i차 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 개별 처리\n",
    "- 불필요 페이지 제거\n",
    "- 오타\n",
    "- 페이지 머리말/꼬리말"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.ProcessWorkbook.quizbook3 as quiz\n",
    "\n",
    "# quiz.main(json_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 돌리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json\n",
    "from typing import List, Dict, Any\n",
    "import tools.ProcessFiles as pf\n",
    "import tools.ProcessLv2 as pl2\n",
    "\n",
    "json_files = pf.get_filelist(3)\n",
    "json_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = pf.get_excel_data(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in json_files:\n",
    "if True:\n",
    "    j = '/Users/yejin/Desktop/Desktop_AICenter✨/SFAIcenter/data_yejin/FINAL/2C_0902/Lv2/SS0014_conversation/SS0014.json'\n",
    "    INPUT_PATH = j\n",
    "    BACKUP_PATH = INPUT_PATH + \".bak\"\n",
    "\n",
    "    with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        origin = json.load(f)\n",
    "\n",
    "    with open(BACKUP_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(origin, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # id = excel[excel['ISBN'] == int(origin.get('file_id'))].index[0]\n",
    "    # new = {\n",
    "    #     'file_id': str(excel.loc[id, 'ISBN']),\n",
    "    #     'title': excel.loc[id, '도서명'],\n",
    "    #     'cat1_domain': excel.loc[id, '코퍼스 1분류'],\n",
    "    #     'cat2_sub': excel.loc[id, '코퍼스 2분류'],\n",
    "    #     'cat3_specific': excel.loc[id, '비고'],\n",
    "    #     'pub_date': str(excel.loc[id, '출판일'])[:10],\n",
    "    #     'contents': [],\n",
    "    # }\n",
    "\n",
    "    # new['contents'] = pl2.fill_chapter(origin['contents'])\n",
    "    \n",
    "    \n",
    "    # for i in range(len(origin['contents'])):\n",
    "        # contents = origin['contents'][i]\n",
    "        # c = extract_qna(contents)\n",
    "        # page_contents = remove_enter(contents['page_contents'])\n",
    "        # contents['page_contents'] = page_contents\n",
    "        # c = contents\n",
    "        # print(contents)  \n",
    "    # new = pl2.fill_chapter(origin)\n",
    "    new = pl2.merge_paragraphs(origin)\n",
    "\n",
    "    with open(INPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(new, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function id(obj, /)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for js in json_files:\n",
    "#     INPUT_PATH = js\n",
    "#     BACKUP_PATH = INPUT_PATH + \".bak\"\n",
    "\n",
    "#     if not os.path.exists(INPUT_PATH):\n",
    "#         raise FileNotFoundError(INPUT_PATH)\n",
    "\n",
    "#     with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "#         data = json.load(f)\n",
    "\n",
    "#     with open(BACKUP_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "#     contents: List[Dict[str, Any]] = data.get(\"contents\", [])\n",
    "#     data[\"contents\"] = build_output(contents)\n",
    "\n",
    "#     with open(INPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in enumerate(json_files):\n",
    "    if '276709608' in j:\n",
    "        print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def process_footnotes(content: str, page: str) -> tuple[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    본문에서 각주 표시(•, ••, •••)를 찾아서 태그로 변환하고, \n",
    "    add_info에 footnote 정보를 추가하는 함수\n",
    "    \n",
    "    Args:\n",
    "        content: 페이지 내용\n",
    "        page: 페이지 번호 (4자리)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (변환된 본문, footnote add_info 리스트)\n",
    "    \"\"\"\n",
    "    # 각주 패턴 찾기: •, ••, ••• 등\n",
    "    footnote_pattern = r'([^•\\n]*?)(•+)'\n",
    "    \n",
    "    # ───── 구분선 이후의 각주 내용들 추출\n",
    "    footnote_section_pattern = r'─────\\n(.*?)(?=\\n[^•]|\\Z)'\n",
    "    footnote_section_match = re.search(footnote_section_pattern, content, re.DOTALL)\n",
    "    \n",
    "    footnotes = []\n",
    "    footnote_counter = 1\n",
    "    \n",
    "    if footnote_section_match:\n",
    "        footnote_section = footnote_section_match.group(1)\n",
    "        \n",
    "        # 각주 내용들을 개별적으로 추출\n",
    "        footnote_items = re.findall(r'•+\\n(.*?)(?=\\n•|\\Z)', footnote_section, re.DOTALL)\n",
    "        \n",
    "        # 본문에서 각주 표시를 찾아서 태그로 변환\n",
    "        def replace_footnote(match):\n",
    "            nonlocal footnote_counter\n",
    "            text_before = match.group(1)\n",
    "            dots = match.group(2)\n",
    "            \n",
    "            # 각주 번호 계산 (•의 개수)\n",
    "            footnote_num = len(dots)\n",
    "            \n",
    "            # 해당하는 각주 내용 찾기\n",
    "            if footnote_num <= len(footnote_items):\n",
    "                footnote_content = footnote_items[footnote_num - 1].strip()\n",
    "                \n",
    "                # add_info에 추가할 footnote 정보\n",
    "                footnote_info = {\n",
    "                    \"tag\": f\"note_{page}_{footnote_counter:04d}\",\n",
    "                    \"type\": \"footnote\",\n",
    "                    \"description\": footnote_content,\n",
    "                    \"caption\": None,\n",
    "                    \"file_path\": None,\n",
    "                    \"bbox\": None\n",
    "                }\n",
    "                footnotes.append(footnote_info)\n",
    "                \n",
    "                # 본문에서 각주 표시를 태그로 변환\n",
    "                tag = f\"{{note_{page}_{footnote_counter:04d}}}\"\n",
    "                footnote_counter += 1\n",
    "                \n",
    "                return text_before + tag\n",
    "            else:\n",
    "                return match.group(0)  # 매칭되는 각주 내용이 없으면 원본 유지\n",
    "        \n",
    "        # 본문에서 각주 표시를 태그로 변환\n",
    "        modified_content = re.sub(footnote_pattern, replace_footnote, content)\n",
    "        \n",
    "        # ───── 구분선과 각주 내용 제거\n",
    "        modified_content = re.sub(footnote_section_pattern, '', modified_content, flags=re.DOTALL)\n",
    "        \n",
    "    else:\n",
    "        modified_content = content\n",
    "    \n",
    "    return modified_content, footnotes\n",
    "\n",
    "# 테스트\n",
    "test_content = \"\"\"약세 전환의 가능성이 좀 더 크다고 생각해. 몇 가지 이유가 있는데, 그중에서 딱 한 가 지만 말해줄게. 바로, 외국인들이 이머징emerging• 주식을 매수하고 있다는 점이야. 외국인들은 달러의 중기적 강세를 전망할 때는 대체로 이머징 주식을 매수하지 않거든. 어떤 종목을 사서 5% 수익이 났는데, 달러가 10% 강해졌다면 오히려 5%의 손실이 나니까 말이야.\n",
    "─────\n",
    "•\n",
    "새롭게 부상한다는 의미로 신흥 시장을 가리킨다.\n",
    "이수\n",
    "달러가 왜 약세를 보이기 시작했는지 알려주세요.\"\"\"\n",
    "\n",
    "modified, footnotes = process_footnotes(test_content, \"0023\")\n",
    "print(\"변환된 본문:\")\n",
    "print(modified)\n",
    "print(\"\\n추출된 각주:\")\n",
    "for footnote in footnotes:\n",
    "    print(json.dumps(footnote, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_footnotes(json_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    JSON 데이터의 모든 페이지에서 각주를 처리하는 함수\n",
    "    \n",
    "    Args:\n",
    "        json_data: 원본 JSON 데이터\n",
    "    \n",
    "    Returns:\n",
    "        처리된 JSON 데이터\n",
    "    \"\"\"\n",
    "    processed_data = json_data.copy()\n",
    "    \n",
    "    if 'contents' in processed_data:\n",
    "        for content_item in processed_data['contents']:\n",
    "            if 'page_contents' in content_item and 'page' in content_item:\n",
    "                page_num = content_item['page']\n",
    "                original_content = content_item['page_contents']\n",
    "                \n",
    "                # 각주 처리\n",
    "                modified_content, footnotes = process_footnotes(original_content, page_num)\n",
    "                \n",
    "                # 본문 업데이트\n",
    "                content_item['page_contents'] = modified_content\n",
    "                \n",
    "                # add_info에 footnote 추가\n",
    "                if 'add_info' not in content_item:\n",
    "                    content_item['add_info'] = []\n",
    "                \n",
    "                # 기존 add_info에 새로운 footnote들 추가\n",
    "                content_item['add_info'].extend(footnotes)\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# 실제 파일에 적용해보기\n",
    "INPUT_PATH = '/Users/yejin/Desktop/Desktop_AICenter✨/SFAIcenter/data_yejin/FINAL/2C_0902/Lv2/SS0014_conversation/SS0014.json'\n",
    "\n",
    "with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    original_data = json.load(f)\n",
    "\n",
    "# 각주 처리\n",
    "processed_data = process_json_footnotes(original_data)\n",
    "\n",
    "# 결과 확인 - 첫 번째 페이지만 출력\n",
    "if processed_data['contents']:\n",
    "    first_page = processed_data['contents'][0]\n",
    "    print(\"처리된 첫 번째 페이지:\")\n",
    "    print(f\"페이지: {first_page['page']}\")\n",
    "    print(f\"본문 길이: {len(first_page['page_contents'])}\")\n",
    "    print(f\"add_info 개수: {len(first_page.get('add_info', []))}\")\n",
    "    \n",
    "    # add_info에 footnote가 있는지 확인\n",
    "    footnotes_in_page = [item for item in first_page.get('add_info', []) if item.get('type') == 'footnote']\n",
    "    print(f\"추출된 각주 개수: {len(footnotes_in_page)}\")\n",
    "    \n",
    "    if footnotes_in_page:\n",
    "        print(\"\\n첫 번째 각주:\")\n",
    "        print(json.dumps(footnotes_in_page[0], ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_footnotes_improved(content: str, page: str) -> tuple[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    개선된 각주 처리 함수\n",
    "    \"\"\"\n",
    "    footnotes = []\n",
    "    footnote_counter = 1\n",
    "    \n",
    "    # ───── 구분선 이후의 각주 섹션 찾기\n",
    "    footnote_section_pattern = r'─────\\n(.*?)(?=\\n[^•\\n]|\\Z)'\n",
    "    footnote_section_match = re.search(footnote_section_pattern, content, re.DOTALL)\n",
    "    \n",
    "    if not footnote_section_match:\n",
    "        return content, footnotes\n",
    "    \n",
    "    footnote_section = footnote_section_match.group(1)\n",
    "    \n",
    "    # 각주 항목들을 추출 (•로 시작하는 각 줄)\n",
    "    footnote_lines = []\n",
    "    for line in footnote_section.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line.startswith('•'):\n",
    "            # • 제거하고 내용만 추출\n",
    "            footnote_content = line[1:].strip()\n",
    "            if footnote_content:\n",
    "                footnote_lines.append(footnote_content)\n",
    "    \n",
    "    if not footnote_lines:\n",
    "        return content, footnotes\n",
    "    \n",
    "    # 본문에서 각주 표시를 찾아서 태그로 변환\n",
    "    # •, ••, ••• 패턴을 찾되, 단어 뒤에 오는 것만\n",
    "    footnote_pattern = r'(\\w+)(•+)'\n",
    "    \n",
    "    def replace_footnote(match):\n",
    "        nonlocal footnote_counter\n",
    "        word = match.group(1)\n",
    "        dots = match.group(2)\n",
    "        \n",
    "        # 각주 번호 계산 (•의 개수)\n",
    "        footnote_num = len(dots)\n",
    "        \n",
    "        # 해당하는 각주 내용 찾기\n",
    "        if footnote_num <= len(footnote_lines):\n",
    "            footnote_content = footnote_lines[footnote_num - 1]\n",
    "            \n",
    "            # add_info에 추가할 footnote 정보\n",
    "            footnote_info = {\n",
    "                \"tag\": f\"note_{page}_{footnote_counter:04d}\",\n",
    "                \"type\": \"footnote\",\n",
    "                \"description\": footnote_content,\n",
    "                \"caption\": None,\n",
    "                \"file_path\": None,\n",
    "                \"bbox\": None\n",
    "            }\n",
    "            footnotes.append(footnote_info)\n",
    "            \n",
    "            # 본문에서 각주 표시를 태그로 변환\n",
    "            tag = f\"{{note_{page}_{footnote_counter:04d}}}\"\n",
    "            footnote_counter += 1\n",
    "            \n",
    "            return word + tag\n",
    "        else:\n",
    "            return match.group(0)  # 매칭되는 각주 내용이 없으면 원본 유지\n",
    "    \n",
    "    # 본문에서 각주 표시를 태그로 변환\n",
    "    modified_content = re.sub(footnote_pattern, replace_footnote, content)\n",
    "    \n",
    "    # ───── 구분선과 각주 내용 제거\n",
    "    modified_content = re.sub(footnote_section_pattern, '', modified_content, flags=re.DOTALL)\n",
    "    \n",
    "    return modified_content, footnotes\n",
    "\n",
    "# 테스트\n",
    "test_content = \"\"\"약세 전환의 가능성이 좀 더 크다고 생각해. 몇 가지 이유가 있는데, 그중에서 딱 한 가 지만 말해줄게. 바로, 외국인들이 이머징emerging• 주식을 매수하고 있다는 점이야. 외국인들은 달러의 중기적 강세를 전망할 때는 대체로 이머징 주식을 매수하지 않거든. 어떤 종목을 사서 5% 수익이 났는데, 달러가 10% 강해졌다면 오히려 5%의 손실이 나니까 말이야.\n",
    "─────\n",
    "•\n",
    "새롭게 부상한다는 의미로 신흥 시장을 가리킨다.\n",
    "이수\n",
    "달러가 왜 약세를 보이기 시작했는지 알려주세요.\"\"\"\n",
    "\n",
    "modified, footnotes = process_footnotes_improved(test_content, \"0023\")\n",
    "print(\"변환된 본문:\")\n",
    "print(modified)\n",
    "print(\"\\n추출된 각주:\")\n",
    "for footnote in footnotes:\n",
    "    print(json.dumps(footnote, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_footnotes(json_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    JSON 데이터의 모든 페이지에서 각주를 처리하는 완전한 함수\n",
    "    \"\"\"\n",
    "    processed_data = json_data.copy()\n",
    "    total_footnotes = 0\n",
    "    \n",
    "    if 'contents' in processed_data:\n",
    "        for content_item in processed_data['contents']:\n",
    "            if 'page_contents' in content_item and 'page' in content_item:\n",
    "                page_num = content_item['page']\n",
    "                original_content = content_item['page_contents']\n",
    "                \n",
    "                # 각주 처리\n",
    "                modified_content, footnotes = process_footnotes_improved(original_content, page_num)\n",
    "                \n",
    "                # 본문 업데이트\n",
    "                content_item['page_contents'] = modified_content\n",
    "                \n",
    "                # add_info에 footnote 추가\n",
    "                if 'add_info' not in content_item:\n",
    "                    content_item['add_info'] = []\n",
    "                \n",
    "                # 기존 add_info에 새로운 footnote들 추가\n",
    "                content_item['add_info'].extend(footnotes)\n",
    "                total_footnotes += len(footnotes)\n",
    "                \n",
    "                if footnotes:\n",
    "                    print(f\"페이지 {page_num}: {len(footnotes)}개 각주 처리됨\")\n",
    "    \n",
    "    print(f\"총 {total_footnotes}개 각주가 처리되었습니다.\")\n",
    "    return processed_data\n",
    "\n",
    "# 실제 파일에 적용\n",
    "print(\"각주 처리 시작...\")\n",
    "processed_data = process_all_footnotes(original_data)\n",
    "\n",
    "# 결과 확인 - 각주가 있는 페이지들만 출력\n",
    "print(\"\\n=== 각주 처리 결과 ===\")\n",
    "for i, content_item in enumerate(processed_data['contents']):\n",
    "    footnotes = [item for item in content_item.get('add_info', []) if item.get('type') == 'footnote']\n",
    "    if footnotes:\n",
    "        print(f\"\\n페이지 {content_item['page']} ({i+1}번째):\")\n",
    "        print(f\"  - 각주 개수: {len(footnotes)}\")\n",
    "        for j, footnote in enumerate(footnotes[:2]):  # 처음 2개만 출력\n",
    "            print(f\"  - 각주 {j+1}: {footnote['description'][:50]}...\")\n",
    "        if len(footnotes) > 2:\n",
    "            print(f\"  - ... 외 {len(footnotes)-2}개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처리된 결과를 파일에 저장\n",
    "OUTPUT_PATH = INPUT_PATH.replace('.json', '_footnotes_processed.json')\n",
    "\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(processed_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\n처리된 파일이 저장되었습니다: {OUTPUT_PATH}\")\n",
    "\n",
    "# 원본 파일도 백업 후 업데이트할지 선택\n",
    "print(\"\\n원본 파일을 업데이트하시겠습니까? (y/n)\")\n",
    "# 실제로는 사용자가 선택할 수 있도록 주석 처리\n",
    "# choice = input()\n",
    "# if choice.lower() == 'y':\n",
    "#     with open(INPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(processed_data, f, ensure_ascii=False, indent=4)\n",
    "#     print(\"원본 파일이 업데이트되었습니다.\")\n",
    "# else:\n",
    "#     print(\"원본 파일은 그대로 유지됩니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# add_info\n",
    "{\n",
    "    \"tag\": \"q_0000_0001\",\n",
    "    \"type\": \"question\",\n",
    "    \"description\": {\n",
    "        \"number\": \"\",\n",
    "        \"question\": \"\",\n",
    "        \"options\": [],\n",
    "        \"options\": null,\n",
    "        \"answer\": \"\",\n",
    "        \"explanation\": \"\"\n",
    "    },\n",
    "    \"caption\": [\n",
    "        \" 기출\",\n",
    "        \"키워드: \"\n",
    "    ],\n",
    "    \"file_path\": null,\n",
    "    \"bbox\": null\n",
    "},\n",
    "{\n",
    "    \"tag\": \"note_0000_0001\",\n",
    "    \"type\": \"footnote\",\n",
    "    \"description\": \"1 이러한 계약을 법적으로는 금전소비대차계약이라고 한다. 차용증서를 영어로는 I owe you.의 소리를 따라 IOU 라고 한다.\",\n",
    "    \"caption\": null,\n",
    "    \"file_path\": null,\n",
    "    \"bbox\": null\n",
    "},\n",
    "{\n",
    "    \"tag\": \"tb_0000_0001\",\n",
    "    \"type\": \"table\",\n",
    "    \"description\": \"\\\\begin{tabular}{|c|c|c|c|}\\n\\\\hline\\n나라 이름 & 지수 이름 & 포괄 종목 & 작성 기관 \\\\\\\\\\\\hline\\n\\\\multirow{2}{*}{한 국} & KOSPI & \\\\makecell[l]{유가증권시장 상장\\\\\\\\전종목} & 한국거래소 \\\\\\\\\\\\cline{2-4}\\n& KOSDAQ & \\\\makecell[l]{코스닥 상장 전종목} & 한국거래소 \\\\\\\\\\\\hline\\n\\\\multirow{4}{*}{미 국} & DJIA & \\\\makecell[l]{뉴욕거래소, 나스닥\\\\\\\\상장 30 개 종목} & 다우존스사 \\\\\\\\\\\\cline{2-4}\\n& S\\\\&P 500 & \\\\makecell[l]{뉴욕거래소,\\\\\\\\미국거래소, 나스닥\\\\\\\\상장 500 개 종목} & \\\\makecell[c]{Standard \\\\&\\\\\\\\Poors 사} \\\\\\\\\\\\hline\\n\\\\multirow{3}{*}{일 본} & TOPIX & \\\\makecell[l]{동경거래소 상장\\\\\\\\전종목} & 동경거래소 \\\\\\\\\\\\cline{2-4}\\n& NIKKEI 225 & \\\\makecell[l]{동경거래소 상장\\\\\\\\225 개 종목} & 일본경제신문사 \\\\\\\\\\\\hline\\n영 국 & FTSE 100 & \\\\makecell[l]{런던거래소 상장\\\\\\\\100 개 종목} & FTSE \\\\\\\\\\\\hline\\n독 일 & DAX 30 & \\\\makecell[l]{프랑크푸르트 거래소\\\\\\\\상장 30 개 종목} & Deutsche Boerse \\\\\\\\\\\\hline\\n프랑스 & CAC 40 & \\\\makecell[l]{Euronext Paris 상장\\\\\\\\40 개 종목} & Euronext \\\\\\\\\\\\hline\\n중 국 & 상해종합지수 & \\\\makecell[l]{상해거래소 상장\\\\\\\\전종목} & 상해거래소 \\\\\\\\\\\\hline\\n\\\\end{tabular}\",\n",
    "    \"caption\": [\n",
    "        \"표2. 주가지수 개요\"\n",
    "    ],\n",
    "    \"file_path\": \"??????/crop/tb_0000_0001.png\",\n",
    "    \"bbox\": null\n",
    "},\n",
    "{\n",
    "    \"tag\": \"img_0000_0001\",\n",
    "    \"type\": \"image\",\n",
    "    \"description\": null,\n",
    "    \"caption\": [\n",
    "        \"도표1: 경제주체간 상품, 생산요소 및 자금의 흐름\"\n",
    "    ],\n",
    "    \"file_path\": \"?????/crop/img_0000_0001.png\",\n",
    "    \"bbox\": null\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
