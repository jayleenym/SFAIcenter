#!/usr/bin/env python3
"""
FIN_workbook í•˜ìœ„ì˜ extracted_qna.json íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ì—¬
qna_domain/qna_typeë³„ í†µê³„ë¥¼ í™•ì¸í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import json
import os
import glob
import re
from collections import defaultdict, Counter
import pandas as pd
from pathlib import Path
from datetime import datetime

# ìœ íš¨í•œ Domain Type ì •ì˜
VALID_DOMAINS = {
    'ê²½ì œ', 'ê²½ì˜', 'íšŒê³„', 'ì„¸ë¬´', 'ë…¸ë¬´', 'í†µê³„', 
    'ë‚´ë¶€í†µì œ', 'ì˜ì—…', 'ë””ì§€í„¸', 'ìì‚°ìš´ìš©', 'ë¦¬ìŠ¤í¬ê´€ë¦¬', 'ë³´í—˜ê³„ì•½', 'ë³´ìƒì²˜ë¦¬'
}

def find_extracted_qna_files(base_path):
    """FIN_workbook í•˜ìœ„ì˜ ëª¨ë“  extracted_qna.json íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
    pattern = os.path.join(base_path, "**", "*extracted_qna.json")
    files = glob.glob(pattern, recursive=True)
    # mergedë¡œ ì‹œì‘í•˜ëŠ” íŒŒì¼ë“¤ê³¼ ë°±ì—… íŒŒì¼ë“¤ ì œì™¸
    filtered_files = []
    for f in files:
        if (not f.endswith('.bak') and 
            not f.endswith('.backup') and 
            not os.path.basename(f).startswith('merged')):
            filtered_files.append(f)
    return filtered_files

def is_valid_domain(domain):
    """ë„ë©”ì¸ì´ ìœ íš¨í•œì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    return domain in VALID_DOMAINS

def extract_ss_pattern_from_question(question_text):
    """ì§ˆë¬¸ì—ì„œ SS0000_q_0000_0000 íŒ¨í„´ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not question_text:
        return None
    
    # SS0000_q_0000_0000 íŒ¨í„´ ì°¾ê¸°
    pattern = r'SS\d{4}_q_\d{4}_\d{4}'
    matches = re.findall(pattern, question_text)
    return matches[0] if matches else None

def load_json_file(file_path):
    """JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"Error loading {file_path}: {e}")
        return None

def analyze_qna_statistics(files):
    """QnA íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ì—¬ í†µê³„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    stats = {
        'total_files': 0,
        'total_qna_items': 0,
        'valid_domain_items': 0,
        'invalid_domain_items': 0,
        'qna_domain_stats': defaultdict(int),
        'qna_type_stats': defaultdict(int),
        'domain_type_combination': defaultdict(lambda: defaultdict(int)),
        'file_stats': [],
        'domain_type_details': defaultdict(lambda: defaultdict(list)),
        'invalid_domain_details': defaultdict(list),
        'ss_pattern_details': defaultdict(list)
    }
    
    for file_path in files:
        print(f"Processing: {file_path}")
        data = load_json_file(file_path)
        
        if data is None:
            continue
            
        stats['total_files'] += 1
        file_id = os.path.basename(file_path).replace('_extracted_qna.json', '')
        file_qna_count = 0
        file_valid_domain_count = 0
        file_invalid_domain_count = 0
        
        for item in data:
            if not isinstance(item, dict):
                continue
                
            stats['total_qna_items'] += 1
            file_qna_count += 1
            
            qna_domain = item.get('qna_domain', '')
            qna_type = item.get('qna_type', 'Unknown')
            question_text = item.get('qna_data', {}).get('description', {}).get('question', '')
            
            # ë¹ˆ ë„ë©”ì¸ì„ ""ë¡œ ëª…ì‹œ
            if not qna_domain or qna_domain.strip() == '':
                qna_domain = ''
            
            # ë„ë©”ì¸ ìœ íš¨ì„± ê²€ì‚¬
            if is_valid_domain(qna_domain):
                stats['valid_domain_items'] += 1
                file_valid_domain_count += 1
                
                # ê¸°ë³¸ í†µê³„
                stats['qna_domain_stats'][qna_domain] += 1
                stats['qna_type_stats'][qna_type] += 1
                
                # ë„ë©”ì¸-íƒ€ì… ì¡°í•© í†µê³„
                stats['domain_type_combination'][qna_domain][qna_type] += 1
                
                # ìƒì„¸ ì •ë³´ ì €ì¥ (íŒŒì¼ë³„)
                stats['domain_type_details'][qna_domain][qna_type].append({
                    'file_id': file_id,
                    'title': item.get('title', ''),
                    'chapter': item.get('chapter', ''),
                    'page': item.get('page', ''),
                    'qna_reason': item.get('qna_reason', ''),
                    'question': question_text[:100] + '...' if len(question_text) > 100 else question_text
                })
            else:
                stats['invalid_domain_items'] += 1
                file_invalid_domain_count += 1
                
                # SS íŒ¨í„´ ì¶”ì¶œ
                ss_pattern = extract_ss_pattern_from_question(question_text)
                
                # ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ ìƒì„¸ ì •ë³´ ì €ì¥
                stats['invalid_domain_details'][qna_domain].append({
                    'file_id': file_id,
                    'title': item.get('title', ''),
                    'chapter': item.get('chapter', ''),
                    'page': item.get('page', ''),
                    'qna_reason': item.get('qna_reason', ''),
                    'question': question_text[:100] + '...' if len(question_text) > 100 else question_text,
                    'ss_pattern': ss_pattern,
                    'original_domain': qna_domain,
                    'qna_type': qna_type
                })
                
                # SS íŒ¨í„´ë³„ ê·¸ë£¹í™”
                if ss_pattern:
                    stats['ss_pattern_details'][ss_pattern].append({
                        'file_id': file_id,
                        'domain': qna_domain,
                        'type': qna_type,
                        'question': question_text[:100] + '...' if len(question_text) > 100 else question_text
                    })
        
        stats['file_stats'].append({
            'file_id': file_id,
            'file_path': file_path,
            'qna_count': file_qna_count,
            'valid_domain_count': file_valid_domain_count,
            'invalid_domain_count': file_invalid_domain_count
        })
    
    return stats

def print_statistics(stats):
    """í†µê³„ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("=" * 80)
    print("QnA í†µê³„ ë¶„ì„ ê²°ê³¼")
    print("=" * 80)
    
    print(f"\nğŸ“Š ì „ì²´ í†µê³„:")
    print(f"  - ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜: {stats['total_files']:,}")
    print(f"  - ì´ QnA í•­ëª© ìˆ˜: {stats['total_qna_items']:,}")
    print(f"  - ìœ íš¨í•œ ë„ë©”ì¸ í•­ëª©: {stats['valid_domain_items']:,}")
    print(f"  - ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ í•­ëª©: {stats['invalid_domain_items']:,}")
    
    print(f"\nğŸ“ˆ ìœ íš¨í•œ QnA Domainë³„ í†µê³„:")
    domain_stats = sorted(stats['qna_domain_stats'].items(), key=lambda x: x[1], reverse=True)
    for domain, count in domain_stats:
        percentage = (count / stats['valid_domain_items']) * 100 if stats['valid_domain_items'] > 0 else 0
        print(f"  - {domain}: {count:,}ê°œ ({percentage:.1f}%)")
    
    print(f"\nğŸ“‹ QnA Typeë³„ í†µê³„:")
    type_stats = sorted(stats['qna_type_stats'].items(), key=lambda x: x[1], reverse=True)
    for qna_type, count in type_stats:
        percentage = (count / stats['valid_domain_items']) * 100 if stats['valid_domain_items'] > 0 else 0
        print(f"  - {qna_type}: {count:,}ê°œ ({percentage:.1f}%)")
    
    print(f"\nğŸ”— Domain-Type ì¡°í•©ë³„ í†µê³„:")
    for domain in sorted(stats['domain_type_combination'].keys()):
        print(f"\n  ğŸ“Œ {domain}:")
        type_combinations = sorted(stats['domain_type_combination'][domain].items(), 
                                 key=lambda x: x[1], reverse=True)
        for qna_type, count in type_combinations:
            percentage = (count / stats['qna_domain_stats'][domain]) * 100
            print(f"    - {qna_type}: {count:,}ê°œ ({percentage:.1f}%)")
    
    if stats['invalid_domain_items'] > 0:
        print(f"\nâš ï¸  ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ í†µê³„:")
        invalid_domain_stats = Counter()
        for domain, items in stats['invalid_domain_details'].items():
            invalid_domain_stats[domain] = len(items)
        for domain, count in invalid_domain_stats.most_common(10):
            print(f"  - {domain}: {count:,}ê°œ")

def save_txt_report(stats, output_file):
    """ìƒì„¸ ë³´ê³ ì„œë¥¼ txt íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("=" * 100 + "\n")
        f.write("QnA í†µê³„ ë¶„ì„ ìƒì„¸\n")
        f.write(f"ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("=" * 100 + "\n\n")
        
        # ì „ì²´ í†µê³„
        f.write("1. ì „ì²´ í†µê³„\n")
        f.write("-" * 50 + "\n")
        f.write(f"ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜: {stats['total_files']:,}\n")
        f.write(f"ì´ QnA í•­ëª© ìˆ˜: {stats['total_qna_items']:,}\n")
        f.write(f"ìœ íš¨í•œ ë„ë©”ì¸ í•­ëª©: {stats['valid_domain_items']:,}\n")
        f.write(f"ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ í•­ëª©: {stats['invalid_domain_items']:,}\n\n")
        
        # ìœ íš¨í•œ ë„ë©”ì¸ë³„ í†µê³„
        f.write("2. ìœ íš¨í•œ QnA Domainë³„ í†µê³„\n")
        f.write("-" * 50 + "\n")
        domain_stats = sorted(stats['qna_domain_stats'].items(), key=lambda x: x[1], reverse=True)
        for domain, count in domain_stats:
            percentage = (count / stats['valid_domain_items']) * 100 if stats['valid_domain_items'] > 0 else 0
            f.write(f"{domain}: {count:,}ê°œ ({percentage:.1f}%)\n")
        f.write("\n")
        
        # QnA Typeë³„ í†µê³„
        f.write("3. QnA Typeë³„ í†µê³„\n")
        f.write("-" * 50 + "\n")
        type_stats = sorted(stats['qna_type_stats'].items(), key=lambda x: x[1], reverse=True)
        for qna_type, count in type_stats:
            percentage = (count / stats['valid_domain_items']) * 100 if stats['valid_domain_items'] > 0 else 0
            f.write(f"{qna_type}: {count:,}ê°œ ({percentage:.1f}%)\n")
        f.write("\n")
        
        # Domain-Type ì¡°í•©ë³„ í†µê³„
        f.write("4. Domain-Type ì¡°í•©ë³„ í†µê³„\n")
        f.write("-" * 50 + "\n")
        for domain in sorted(stats['domain_type_combination'].keys()):
            f.write(f"\n[{domain}]\n")
            type_combinations = sorted(stats['domain_type_combination'][domain].items(), 
                                     key=lambda x: x[1], reverse=True)
            for qna_type, count in type_combinations:
                percentage = (count / stats['qna_domain_stats'][domain]) * 100
                f.write(f"  {qna_type}: {count:,}ê°œ ({percentage:.1f}%)\n")
        f.write("\n")
        
        # ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ í†µê³„
        if stats['invalid_domain_items'] > 0:
            f.write("5. ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ í†µê³„\n")
            f.write("-" * 50 + "\n")
            invalid_domain_stats = Counter()
            for domain, items in stats['invalid_domain_details'].items():
                invalid_domain_stats[domain] = len(items)
            for domain, count in invalid_domain_stats.most_common():
                percentage = (count / stats['invalid_domain_items']) * 100
                f.write(f"{domain}: {count:,}ê°œ ({percentage:.1f}%)\n")
            f.write("\n")
            
            # SS íŒ¨í„´ë³„ ë¶„ì„
            if stats['ss_pattern_details']:
                f.write("6. SS íŒ¨í„´ë³„ ë¶„ì„ (ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸)\n")
                f.write("-" * 50 + "\n")
                for ss_pattern, items in sorted(stats['ss_pattern_details'].items()):
                    f.write(f"\n[{ss_pattern}] - {len(items)}ê°œ\n")
                    for item in items[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                        f.write(f"  íŒŒì¼: {item['file_id']}, ë„ë©”ì¸: {item['domain']}, íƒ€ì…: {item['type']}\n")
                        f.write(f"  ì§ˆë¬¸: {item['question']}\n")
                    if len(items) > 5:
                        f.write(f"  ... ì™¸ {len(items) - 5}ê°œ\n")
                f.write("\n")
        
        # íŒŒì¼ë³„ í†µê³„
        f.write("7. íŒŒì¼ë³„ í†µê³„\n")
        f.write("-" * 50 + "\n")
        f.write("íŒŒì¼ID\t\tì´QnA\tìœ íš¨ë„ë©”ì¸\të¬´íš¨ë„ë©”ì¸\n")
        f.write("-" * 50 + "\n")
        for file_stat in sorted(stats['file_stats'], key=lambda x: x['file_id']):
            f.write(f"{file_stat['file_id']}\t{file_stat['qna_count']}\t{file_stat['valid_domain_count']}\t{file_stat['invalid_domain_count']}\n")
        f.write("\n")
        
        # ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ ìƒì„¸ ì •ë³´
        if stats['invalid_domain_details']:
            f.write("8. ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ ìƒì„¸ ì •ë³´\n")
            f.write("-" * 50 + "\n")
            for domain, items in sorted(stats['invalid_domain_details'].items()):
                f.write(f"\n[{domain}] - {len(items)}ê°œ\n")
                for i, item in enumerate(items[:10]):  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
                    f.write(f"  {i+1}. íŒŒì¼: {item['file_id']}, í˜ì´ì§€: {item['page']}\n")
                    f.write(f"     ì œëª©: {item['title']}\n")
                    f.write(f"     ì±•í„°: {item['chapter']}\n")
                    f.write(f"     ì›ë˜ ë„ë©”ì¸: '{item['original_domain']}'\n")
                    f.write(f"     QnA íƒ€ì…: {item['qna_type']}\n")
                    f.write(f"     ì§ˆë¬¸: {item['question']}\n")
                    if item['ss_pattern']:
                        f.write(f"     SSíŒ¨í„´: {item['ss_pattern']}\n")
                    f.write("\n")
                if len(items) > 10:
                    f.write(f"  ... ì™¸ {len(items) - 10}ê°œ\n\n")
    
    print(f"\nğŸ’¾ ìƒì„¸ txt ë³´ê³ ì„œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")

def save_detailed_report(stats, output_file):
    """ìƒì„¸ ë³´ê³ ì„œë¥¼ Excel íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    # Domain-Type ì¡°í•©ë³„ ìƒì„¸ ë°ì´í„° ìƒì„±
    detailed_data = []
    
    for domain, type_data in stats['domain_type_details'].items():
        for qna_type, items in type_data.items():
            for item in items:
                detailed_data.append({
                    'Domain': domain,
                    'Type': qna_type,
                    'File_ID': item['file_id'],
                    'Title': item['title'],
                    'Chapter': item['chapter'],
                    'Page': item['page'],
                    'QnA_Reason': item['qna_reason']
                })
    
    # DataFrame ìƒì„±
    df = pd.DataFrame(detailed_data)
    
    # Excel íŒŒì¼ë¡œ ì €ì¥ (ì—¬ëŸ¬ ì‹œíŠ¸)
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        # ì „ì²´ ë°ì´í„°
        df.to_excel(writer, sheet_name='ì „ì²´_ë°ì´í„°', index=False)
        
        # Domainë³„ ìš”ì•½
        domain_summary = df.groupby('Domain').agg({
            'Type': 'count',
            'File_ID': 'nunique'
        }).rename(columns={'Type': 'QnA_Count', 'File_ID': 'File_Count'})
        domain_summary.to_excel(writer, sheet_name='Domainë³„_ìš”ì•½')
        
        # Typeë³„ ìš”ì•½
        type_summary = df.groupby('Type').agg({
            'Domain': 'count',
            'File_ID': 'nunique'
        }).rename(columns={'Domain': 'QnA_Count', 'File_ID': 'File_Count'})
        type_summary.to_excel(writer, sheet_name='Typeë³„_ìš”ì•½')
        
        # Domain-Type ì¡°í•©ë³„ ìš”ì•½
        combination_summary = df.groupby(['Domain', 'Type']).agg({
            'File_ID': 'nunique'
        }).rename(columns={'File_ID': 'File_Count'})
        combination_summary['QnA_Count'] = df.groupby(['Domain', 'Type']).size()
        combination_summary.to_excel(writer, sheet_name='Domain_Type_ì¡°í•©')
        
        # íŒŒì¼ë³„ ìš”ì•½
        file_summary = df.groupby('File_ID').agg({
            'Domain': 'nunique',
            'Type': 'nunique',
            'QnA_Reason': 'count'
        }).rename(columns={
            'Domain': 'Domain_Count', 
            'Type': 'Type_Count',
            'QnA_Reason': 'QnA_Count'
        })
        file_summary.to_excel(writer, sheet_name='íŒŒì¼ë³„_ìš”ì•½')
    
    print(f"\nğŸ’¾ ìƒì„¸ ë³´ê³ ì„œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    base_path = "/Users/jinym/Desktop/Desktop_AICenterâœ¨/SFAIcenter/evaluation/workbook_data"
    
    print("ğŸ” FIN_workbook í•˜ìœ„ì˜ extracted_qna.json íŒŒì¼ë“¤ì„ ì°¾ëŠ” ì¤‘...")
    files = find_extracted_qna_files(base_path)
    
    if not files:
        print("âŒ extracted_qna.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… {len(files)}ê°œì˜ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    
    print("\nğŸ“Š QnA í†µê³„ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    stats = analyze_qna_statistics(files)
    
    # í†µê³„ ì¶œë ¥
    print_statistics(stats)
    
    # txt ìƒì„¸ ë³´ê³ ì„œ ì €ì¥
    txt_output_file = "/Users/jinym/Desktop/Desktop_AICenterâœ¨/SFAIcenter/qna_statistics_report.txt"
    save_txt_report(stats, txt_output_file)
    
    # Excel ìƒì„¸ ë³´ê³ ì„œ ì €ì¥
    excel_output_file = "/Users/jinym/Desktop/Desktop_AICenterâœ¨/SFAIcenter/qna_statistics_report.xlsx"
    save_detailed_report(stats, excel_output_file)
    
    # print(f"\nğŸ‰ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    # print(f"ğŸ“„ txt ë³´ê³ ì„œ: {txt_output_file}")
    # print(f"ğŸ“Š Excel ë³´ê³ ì„œ: {excel_output_file}")

if __name__ == "__main__":
    main()
