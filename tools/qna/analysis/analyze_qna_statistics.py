#!/usr/bin/env python3
"""
workbook_data í•˜ìœ„ì˜ extracted_qna.json íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ì—¬
qna_domain/qna_typeë³„ í†µê³„ë¥¼ í™•ì¸í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import json
import os
import glob
import re
from collections import defaultdict, Counter
from pathlib import Path
from datetime import datetime

# ìœ íš¨í•œ Domain Type ì •ì˜
VALID_DOMAINS = {
    'ê²½ì œ', 'ê²½ì˜', 'íšŒê³„', 'ì„¸ë¬´', 'ë…¸ë¬´', 'í†µê³„', 
    'ë‚´ë¶€í†µì œ', 'ì˜ì—…', 'ë””ì§€í„¸', 'ìì‚°ìš´ìš©', 'ë¦¬ìŠ¤í¬ê´€ë¦¬', 'ë³´í—˜ê³„ì•½', 'ë³´ìƒì²˜ë¦¬'
}

def find_extracted_qna_files(base_path):
    """workbook_data í•˜ìœ„ì˜ ëª¨ë“  extracted_qna.json íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
    pattern = os.path.join(base_path, "**", "*extracted_qna.json")
    files = glob.glob(pattern, recursive=True)
    # mergedë¡œ ì‹œì‘í•˜ëŠ” íŒŒì¼ë“¤ê³¼ ë°±ì—… íŒŒì¼ë“¤ ì œì™¸
    filtered_files = []
    for f in files:
        if (not f.endswith('.bak') and 
            not f.endswith('.backup') and 
            not os.path.basename(f).startswith('merged')):
            filtered_files.append(f)
    return filtered_files

def is_valid_domain(domain):
    """ë„ë©”ì¸ì´ ìœ íš¨í•œì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    return domain in VALID_DOMAINS

def extract_ss_pattern_from_question(question_text):
    """ì§ˆë¬¸ì—ì„œ SS0000_q_0000_0000 íŒ¨í„´ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not question_text:
        return None
    
    # SS0000_q_0000_0000 íŒ¨í„´ ì°¾ê¸°
    pattern = r'SS\d{4}_q_\d{4}_\d{4}'
    matches = re.findall(pattern, question_text)
    return matches[0] if matches else None

def load_json_file(file_path):
    """JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"Error loading {file_path}: {e}")
        return None

def analyze_qna_statistics(files):
    """QnA íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ì—¬ í†µê³„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    stats = {
        'total_files': 0,
        'total_qna_items': 0,
        'valid_domain_items': 0,
        'invalid_domain_items': 0,
        'qna_domain_stats': defaultdict(int),
        'qna_type_stats': defaultdict(int),
        'domain_type_combination': defaultdict(lambda: defaultdict(int)),
        'file_stats': [],
        'domain_type_details': defaultdict(lambda: defaultdict(list)),
        'invalid_domain_details': defaultdict(list),
        'ss_pattern_details': defaultdict(list)
    }
    
    for file_path in files:
        print(f"Processing: {file_path}")
        data = load_json_file(file_path)
        
        if data is None:
            continue
            
        stats['total_files'] += 1
        file_id = os.path.basename(file_path).replace('_extracted_qna.json', '')
        file_qna_count = 0
        file_valid_domain_count = 0
        file_invalid_domain_count = 0
        
        for item in data:
            if not isinstance(item, dict):
                continue
                
            stats['total_qna_items'] += 1
            file_qna_count += 1
            
            qna_domain = item.get('qna_domain', '')
            qna_type = item.get('qna_type', 'Unknown')
            question_text = item.get('qna_data', {}).get('description', {}).get('question', '')
            
            # ë¹ˆ ë„ë©”ì¸ì„ ""ë¡œ ëª…ì‹œ
            if not qna_domain or qna_domain.strip() == '':
                qna_domain = ''
            
            # ë„ë©”ì¸ ìœ íš¨ì„± ê²€ì‚¬
            if is_valid_domain(qna_domain):
                stats['valid_domain_items'] += 1
                file_valid_domain_count += 1
                
                # ê¸°ë³¸ í†µê³„
                stats['qna_domain_stats'][qna_domain] += 1
                stats['qna_type_stats'][qna_type] += 1
                
                # ë„ë©”ì¸-íƒ€ì… ì¡°í•© í†µê³„
                stats['domain_type_combination'][qna_domain][qna_type] += 1
                
                # ìƒì„¸ ì •ë³´ ì €ì¥ (íŒŒì¼ë³„)
                stats['domain_type_details'][qna_domain][qna_type].append({
                    'file_id': file_id,
                    'title': item.get('title', ''),
                    'chapter': item.get('chapter', ''),
                    'page': item.get('page', ''),
                    'qna_reason': item.get('qna_reason', ''),
                    'question': question_text[:100] + '...' if len(question_text) > 100 else question_text
                })
            else:
                stats['invalid_domain_items'] += 1
                file_invalid_domain_count += 1
                
                # SS íŒ¨í„´ ì¶”ì¶œ
                ss_pattern = extract_ss_pattern_from_question(question_text)
                
                # ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ ìƒì„¸ ì •ë³´ ì €ì¥
                stats['invalid_domain_details'][qna_domain].append({
                    'file_id': file_id,
                    'title': item.get('title', ''),
                    'chapter': item.get('chapter', ''),
                    'page': item.get('page', ''),
                    'qna_reason': item.get('qna_reason', ''),
                    'question': question_text[:100] + '...' if len(question_text) > 100 else question_text,
                    'ss_pattern': ss_pattern,
                    'original_domain': qna_domain,
                    'qna_type': qna_type
                })
                
                # SS íŒ¨í„´ë³„ ê·¸ë£¹í™”
                if ss_pattern:
                    stats['ss_pattern_details'][ss_pattern].append({
                        'file_id': file_id,
                        'domain': qna_domain,
                        'type': qna_type,
                        'question': question_text[:100] + '...' if len(question_text) > 100 else question_text
                    })
        
        stats['file_stats'].append({
            'file_id': file_id,
            'file_path': file_path,
            'qna_count': file_qna_count,
            'valid_domain_count': file_valid_domain_count,
            'invalid_domain_count': file_invalid_domain_count
        })
    
    return stats

def print_statistics(stats):
    """í†µê³„ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("=" * 80)
    print("QnA í†µê³„ ë¶„ì„ ê²°ê³¼")
    print("=" * 80)
    
    print(f"\nğŸ“Š ì „ì²´ í†µê³„:")
    print(f"  - ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜: {stats['total_files']:,}")
    print(f"  - ì´ QnA í•­ëª© ìˆ˜: {stats['total_qna_items']:,}")
    print(f"  - ìœ íš¨í•œ ë„ë©”ì¸ í•­ëª©: {stats['valid_domain_items']:,}")
    print(f"  - ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ í•­ëª©: {stats['invalid_domain_items']:,}")
    
    print(f"\nğŸ“ˆ ìœ íš¨í•œ QnA Domainë³„ í†µê³„:")
    domain_stats = sorted(stats['qna_domain_stats'].items(), key=lambda x: x[1], reverse=True)
    for domain, count in domain_stats:
        percentage = (count / stats['valid_domain_items']) * 100 if stats['valid_domain_items'] > 0 else 0
        print(f"  - {domain}: {count:,}ê°œ ({percentage:.1f}%)")
    
    print(f"\nğŸ“‹ QnA Typeë³„ í†µê³„:")
    type_stats = sorted(stats['qna_type_stats'].items(), key=lambda x: x[1], reverse=True)
    for qna_type, count in type_stats:
        percentage = (count / stats['valid_domain_items']) * 100 if stats['valid_domain_items'] > 0 else 0
        print(f"  - {qna_type}: {count:,}ê°œ ({percentage:.1f}%)")
    
    print(f"\nğŸ”— Domain-Type ì¡°í•©ë³„ í†µê³„:")
    for domain in sorted(stats['domain_type_combination'].keys()):
        print(f"\n  ğŸ“Œ {domain}:")
        type_combinations = sorted(stats['domain_type_combination'][domain].items(), 
                                 key=lambda x: x[1], reverse=True)
        for qna_type, count in type_combinations:
            percentage = (count / stats['qna_domain_stats'][domain]) * 100
            print(f"    - {qna_type}: {count:,}ê°œ ({percentage:.1f}%)")
    
    if stats['invalid_domain_items'] > 0:
        print(f"\nâš ï¸  ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ í†µê³„:")
        invalid_domain_stats = Counter()
        for domain, items in stats['invalid_domain_details'].items():
            invalid_domain_stats[domain] = len(items)
        for domain, count in invalid_domain_stats.most_common(10):
            print(f"  - {domain}: {count:,}ê°œ")

def save_txt_report(stats, output_file):
    """ìƒì„¸ ë³´ê³ ì„œë¥¼ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# QnA í†µê³„ ë¶„ì„ ìƒì„¸\n\n")
        f.write(f"**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("---\n\n")
        
        # ì „ì²´ í†µê³„
        f.write("## 1. ì „ì²´ í†µê³„\n\n")
        f.write("| í•­ëª© | ê°’ |\n")
        f.write("|------|-----|\n")
        f.write(f"| ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜ | {stats['total_files']:,}ê°œ |\n")
        f.write(f"| ì´ QnA í•­ëª© ìˆ˜ | {stats['total_qna_items']:,}ê°œ |\n")
        f.write(f"| ìœ íš¨í•œ ë„ë©”ì¸ í•­ëª© | {stats['valid_domain_items']:,}ê°œ |\n")
        f.write(f"| ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ í•­ëª© | {stats['invalid_domain_items']:,}ê°œ |\n\n")
        
        # ìœ íš¨í•œ ë„ë©”ì¸ë³„ í†µê³„
        f.write("## 2. ìœ íš¨í•œ QnA Domainë³„ í†µê³„\n\n")
        f.write("| ë„ë©”ì¸ | ê°œìˆ˜ | ë¹„ìœ¨ |\n")
        f.write("|--------|------|------|\n")
        domain_stats = sorted(stats['qna_domain_stats'].items(), key=lambda x: x[1], reverse=True)
        for domain, count in domain_stats:
            percentage = (count / stats['valid_domain_items']) * 100 if stats['valid_domain_items'] > 0 else 0
            f.write(f"| {domain} | {count:,}ê°œ | {percentage:.1f}% |\n")
        f.write("\n")
        
        # QnA Typeë³„ í†µê³„
        f.write("## 3. QnA Typeë³„ í†µê³„\n\n")
        f.write("| íƒ€ì… | ê°œìˆ˜ | ë¹„ìœ¨ |\n")
        f.write("|------|------|------|\n")
        type_stats = sorted(stats['qna_type_stats'].items(), key=lambda x: x[1], reverse=True)
        for qna_type, count in type_stats:
            percentage = (count / stats['valid_domain_items']) * 100 if stats['valid_domain_items'] > 0 else 0
            f.write(f"| {qna_type} | {count:,}ê°œ | {percentage:.1f}% |\n")
        f.write("\n")
        
        # Domain-Type ì¡°í•©ë³„ í†µê³„
        f.write("## 4. Domain-Type ì¡°í•©ë³„ í†µê³„\n\n")
        for domain in sorted(stats['domain_type_combination'].keys()):
            f.write(f"### {domain}\n\n")
            f.write("| íƒ€ì… | ê°œìˆ˜ | ë¹„ìœ¨ |\n")
            f.write("|------|------|------|\n")
            type_combinations = sorted(stats['domain_type_combination'][domain].items(), 
                                     key=lambda x: x[1], reverse=True)
            for qna_type, count in type_combinations:
                percentage = (count / stats['qna_domain_stats'][domain]) * 100
                f.write(f"| {qna_type} | {count:,}ê°œ | {percentage:.1f}% |\n")
            f.write("\n")
        
        # ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ í†µê³„
        if stats['invalid_domain_items'] > 0:
            f.write("## 5. ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ í†µê³„\n\n")
            f.write("| ë„ë©”ì¸ | ê°œìˆ˜ | ë¹„ìœ¨ |\n")
            f.write("|--------|------|------|\n")
            invalid_domain_stats = Counter()
            for domain, items in stats['invalid_domain_details'].items():
                invalid_domain_stats[domain] = len(items)
            for domain, count in invalid_domain_stats.most_common():
                percentage = (count / stats['invalid_domain_items']) * 100
                f.write(f"| {domain} | {count:,}ê°œ | {percentage:.1f}% |\n")
            f.write("\n")
            
            # SS íŒ¨í„´ë³„ ë¶„ì„
            if stats['ss_pattern_details']:
                f.write("## 6. SS íŒ¨í„´ë³„ ë¶„ì„ (ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸)\n\n")
                for ss_pattern, items in sorted(stats['ss_pattern_details'].items()):
                    f.write(f"### {ss_pattern} - {len(items)}ê°œ\n\n")
                    for item in items[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                        f.write(f"- **íŒŒì¼**: {item['file_id']}, **ë„ë©”ì¸**: {item['domain']}, **íƒ€ì…**: {item['type']}\n")
                        f.write(f"  - ì§ˆë¬¸: {item['question']}\n")
                    if len(items) > 5:
                        f.write(f"\n... ì™¸ {len(items) - 5}ê°œ\n")
                    f.write("\n")
        
        # íŒŒì¼ë³„ í†µê³„
        f.write("## 7. íŒŒì¼ë³„ í†µê³„\n\n")
        f.write("| íŒŒì¼ID | ì´QnA | ìœ íš¨ë„ë©”ì¸ | ë¬´íš¨ë„ë©”ì¸ |\n")
        f.write("|--------|-------|-----------|-----------|\n")
        for file_stat in sorted(stats['file_stats'], key=lambda x: x['file_id']):
            f.write(f"| {file_stat['file_id']} | {file_stat['qna_count']} | {file_stat['valid_domain_count']} | {file_stat['invalid_domain_count']} |\n")
        f.write("\n")
        
        # ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ ìƒì„¸ ì •ë³´
        if stats['invalid_domain_details']:
            f.write("## 8. ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ ìƒì„¸ ì •ë³´\n\n")
            for domain, items in sorted(stats['invalid_domain_details'].items()):
                f.write(f"### {domain} - {len(items)}ê°œ\n\n")
                for i, item in enumerate(items[:10]):  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
                    f.write(f"{i+1}. **íŒŒì¼**: {item['file_id']}, **í˜ì´ì§€**: {item['page']}\n")
                    f.write(f"   - ì œëª©: {item['title']}\n")
                    f.write(f"   - ì±•í„°: {item['chapter']}\n")
                    f.write(f"   - ì›ë˜ ë„ë©”ì¸: '{item['original_domain']}'\n")
                    f.write(f"   - QnA íƒ€ì…: {item['qna_type']}\n")
                    f.write(f"   - ì§ˆë¬¸: {item['question']}\n")
                    if item['ss_pattern']:
                        f.write(f"   - SSíŒ¨í„´: {item['ss_pattern']}\n")
                    f.write("\n")
                if len(items) > 10:
                    f.write(f"... ì™¸ {len(items) - 10}ê°œ\n\n")
        
        # Domain-Type ì¡°í•©ë³„ ìƒì„¸ ì •ë³´
        if 'domain_type_details' in stats and stats['domain_type_details']:
            f.write("## 9. Domain-Type ì¡°í•©ë³„ ìƒì„¸ ì •ë³´\n\n")
            for domain in sorted(stats['domain_type_details'].keys()):
                f.write(f"### {domain}\n\n")
                for qna_type in sorted(stats['domain_type_details'][domain].keys()):
                    items = stats['domain_type_details'][domain][qna_type]
                    f.write(f"#### {qna_type} ({len(items)}ê°œ)\n\n")
                    f.write("| íŒŒì¼ID | ì œëª© | ì±•í„° | í˜ì´ì§€ |\n")
                    f.write("|--------|------|------|--------|\n")
                    for item in items[:20]:  # ìƒìœ„ 20ê°œë§Œ í‘œì‹œ
                        title = item.get('title', '')[:50]  # ì œëª© ê¸¸ì´ ì œí•œ
                        chapter = item.get('chapter', '')[:30]  # ì±•í„° ê¸¸ì´ ì œí•œ
                        f.write(f"| {item.get('file_id', '')} | {title} | {chapter} | {item.get('page', '')} |\n")
                    if len(items) > 20:
                        f.write(f"\n... ì™¸ {len(items) - 20}ê°œ\n")
                    f.write("\n")
    
    print(f"\nğŸ’¾ ìƒì„¸ ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # pipeline/configì—ì„œ ONEDRIVE_PATH, PROJECT_ROOT_PATH import ì‹œë„
    try:
        import sys
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_dir)))
        sys.path.insert(0, project_root)
        from tools import ONEDRIVE_PATH, PROJECT_ROOT_PATH
        base_path = os.path.join(ONEDRIVE_PATH, 'evaluation', 'workbook_data')
        txt_output_file = os.path.join(PROJECT_ROOT_PATH, 'STATS_qna.md')
    except ImportError:
        # fallback: pipelineì´ ì—†ëŠ” ê²½ìš° í”Œë«í¼ë³„ ê¸°ë³¸ê°’ ì‚¬ìš©
        import platform
        system = platform.system()
        home_dir = os.path.expanduser("~")
        if system == "Windows":
            base_path = os.path.join(home_dir, "Desktop", "SFAIcenter", "evaluation", "workbook_data")
            txt_output_file = os.path.join(home_dir, "Desktop", "SFAIcenter", "STATS_qna.md")
        else:
            base_path = os.path.join(home_dir, "Desktop", "Desktop_AICenterâœ¨", "SFAIcenter", "evaluation", "workbook_data")
            txt_output_file = os.path.join(home_dir, "Desktop", "Desktop_AICenterâœ¨", "SFAIcenter", "STATS_qna.md")
    
    print("ğŸ” workbook_data í•˜ìœ„ì˜ extracted_qna.json íŒŒì¼ë“¤ì„ ì°¾ëŠ” ì¤‘...")
    files = find_extracted_qna_files(base_path)
    
    if not files:
        print("âŒ extracted_qna.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… {len(files)}ê°œì˜ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    
    print("\nğŸ“Š QnA í†µê³„ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    stats = analyze_qna_statistics(files)
    
    # í†µê³„ ì¶œë ¥
    print_statistics(stats)
    
    # ë§ˆí¬ë‹¤ìš´ ìƒì„¸ ë³´ê³ ì„œ ì €ì¥
    save_txt_report(stats, txt_output_file)

if __name__ == "__main__":
    main()
