#!/usr/bin/env python3
"""
ì¤‘ë³µ QnA ê²€ì‚¬ ë° ì‚­ì œ ìŠ¤í¬ë¦½íŠ¸
- ë¬¸ì œ/ì •ë‹µ/í•´ì„¤/ì„ íƒì§€ê°€ ëª¨ë‘ ë™ì¼í•œ ì§„ì§œ ì¤‘ë³µì„ ì°¾ì•„ ë¦¬í¬íŠ¸ ìƒì„±
- ì˜µì…˜ìœ¼ë¡œ ì¤‘ë³µ ì‚­ì œ ê°€ëŠ¥
"""

import json
import os
import sys
import glob
import shutil
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Any, Tuple, Optional

# tools ëª¨ë“ˆ import
try:
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(os.path.dirname(current_dir))
    sys.path.insert(0, project_root)
    from tools import ONEDRIVE_PATH
except ImportError:
    import platform
    system = platform.system()
    home_dir = os.path.expanduser("~")
    if system == "Windows":
        ONEDRIVE_PATH = os.path.join(home_dir, "OneDrive", "ë°ì´í„°L", "selectstar")
    else:
        ONEDRIVE_PATH = os.path.join(home_dir, "Library", "CloudStorage", "OneDrive-ê°œì¸", "ë°ì´í„°L", "selectstar")


def check_duplicates_single_file(file_path: str, return_details: bool = False) -> Tuple[int, int, Optional[Dict]]:
    """
    ë‹¨ì¼ íŒŒì¼ì—ì„œ ë¬¸ì œ/ì •ë‹µ/í•´ì„¤/ì„ íƒì§€ê°€ ëª¨ë‘ ë™ì¼í•œ ì§„ì§œ ì¤‘ë³µì„ í™•ì¸
    
    Args:
        file_path: ê²€ì‚¬í•  íŒŒì¼ ê²½ë¡œ
        return_details: ìƒì„¸ ì •ë³´ ë°˜í™˜ ì—¬ë¶€
        
    Returns:
        (ì´ QnA ìˆ˜, ì¤‘ë³µ ê·¸ë£¹ ìˆ˜, ì¤‘ë³µ ìƒì„¸ì •ë³´)
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {file_path} - {e}")
        return (0, 0, {}) if return_details else (0, 0)
    
    print(f"ğŸ“ íŒŒì¼: {os.path.basename(file_path)}")
    print(f"   ì´ Q&A ê°œìˆ˜: {len(data)}")
    
    # ë¬¸ì œ/ì •ë‹µ/í•´ì„¤/ì„ íƒì§€ë¥¼ ì¡°í•©í•œ í‚¤ë¡œ ì¤‘ë³µ í™•ì¸
    content_keys = defaultdict(list)
    
    for i, item in enumerate(data):
        qna_data = item.get('qna_data', {})
        description = qna_data.get('description', {})
        
        question = description.get('question', '').strip()
        answer = description.get('answer', '').strip()
        explanation = description.get('explanation', '').strip()
        options = description.get('options', [])
        tag = qna_data.get('tag', '')  # q_0000_0000 í˜•ì‹ì˜ íƒœê·¸
        
        options_str = '|'.join([opt.strip() for opt in options]) if options else ''
        content_key = f"{question}|{answer}|{explanation}|{options_str}"
        
        content_keys[content_key].append({
            'index': i,
            'page': item.get('page', ''),
            'tag': tag,
            'question': question,
            'answer': answer,
            'explanation': explanation,
            'options': options
        })
    
    # ì§„ì§œ ì¤‘ë³µ ì°¾ê¸°
    real_duplicates = {key: items for key, items in content_keys.items() if len(items) > 1}
    
    print(f"   ê³ ìœ í•œ Q&A ì¡°í•©: {len(content_keys)}ê°œ")
    print(f"   ì¤‘ë³µëœ Q&A ì¡°í•©: {len(real_duplicates)}ê°œ")
    
    if real_duplicates:
        print(f"   âš ï¸  ì§„ì§œ ì¤‘ë³µ ë°œê²¬:")
        for i, (content_key, items) in enumerate(real_duplicates.items()):
            print(f"     ì¤‘ë³µ ê·¸ë£¹ {i+1}:")
            for item in items:
                tag_info = f", íƒœê·¸ {item['tag']}" if item.get('tag') else ""
                print(f"       - ì¸ë±ìŠ¤ {item['index']}, í˜ì´ì§€ {item['page']}{tag_info}: {item['question'][:20]}...")
    else:
        print(f"   âœ… ì§„ì§œ ì¤‘ë³µ ì—†ìŒ")
    
    if return_details:
        return len(data), len(real_duplicates), real_duplicates
    else:
        return len(data), len(real_duplicates)


def save_duplicates_report(duplicates_data: Dict[str, Any], output_dir: str) -> str:
    """ì¤‘ë³µ ê²€ì‚¬ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    
    txt_file = os.path.join(os.path.dirname(output_dir), f"duplicates_report_{timestamp}.txt")
    with open(txt_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("ì¤‘ë³µ ê²€ì‚¬ ê²°ê³¼ ë¦¬í¬íŠ¸\n")
        f.write("=" * 80 + "\n")
        f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"ê²€ì‚¬ëœ íŒŒì¼ ìˆ˜: {duplicates_data['summary']['total_files']}ê°œ\n")
        f.write(f"ì´ Q&A ê°œìˆ˜: {duplicates_data['summary']['total_qna']}ê°œ\n")
        f.write(f"ì´ ì¤‘ë³µ ê·¸ë£¹ ìˆ˜: {duplicates_data['summary']['total_duplicates']}ê°œ\n")
        f.write(f"ì¤‘ë³µì´ ìˆëŠ” íŒŒì¼ ìˆ˜: {duplicates_data['summary']['files_with_duplicates']}ê°œ\n")
        f.write("\n")
        
        if duplicates_data['summary']['files_with_duplicates'] > 0:
            f.write("ì¤‘ë³µì´ ë°œê²¬ëœ íŒŒì¼ë“¤:\n")
            f.write("-" * 40 + "\n")
            
            for file_info in duplicates_data['files_with_duplicates']:
                f.write(f"\nğŸ“ íŒŒì¼: {file_info['filename']}\n")
                f.write(f"   ê²½ë¡œ: {file_info['filepath']}\n")
                f.write(f"   ì´ Q&A ê°œìˆ˜: {file_info['total_qna']}ê°œ\n")
                f.write(f"   ì¤‘ë³µ ê·¸ë£¹ ìˆ˜: {file_info['duplicate_groups']}ê°œ\n")
                f.write("\n")
                
                for group_idx, (content_key, items) in enumerate(file_info['duplicates'].items(), 1):
                    f.write(f"   ì¤‘ë³µ ê·¸ë£¹ {group_idx}:\n")
                    for item in items:
                        f.write(f"     - ì¸ë±ìŠ¤ {item['index']}, í˜ì´ì§€ {item['page']}\n")
                        f.write(f"       ë¬¸ì œ: {item['question'][:100]}{'...' if len(item['question']) > 100 else ''}\n")
                        f.write(f"       ì •ë‹µ: {item['answer'][:100]}{'...' if len(item['answer']) > 100 else ''}\n")
                        f.write(f"       í•´ì„¤: {item['explanation'][:100]}{'...' if len(item['explanation']) > 100 else ''}\n")
                        if item.get('options'):
                            f.write(f"       ì„ íƒì§€:\n")
                            for opt_idx, option in enumerate(item['options'], 1):
                                f.write(f"         {opt_idx}. {option[:80]}{'...' if len(option) > 80 else ''}\n")
                        f.write("\n")
        else:
            f.write("âœ… ëª¨ë“  íŒŒì¼ì—ì„œ ì¤‘ë³µ ì—†ìŒ - ëª¨ë“  Q&Aê°€ ê³ ìœ í•©ë‹ˆë‹¤!\n")
    
    return txt_file


def remove_duplicates_from_file(file_path: str, duplicates_data: Dict, create_backup: bool = True) -> Tuple[int, int]:
    """
    íŒŒì¼ì—ì„œ ì¤‘ë³µëœ ë¬¸ì œë“¤ì„ ì‚­ì œ (ì¸ë±ìŠ¤ê°€ í° ê²ƒë“¤ ì‚­ì œ)
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if create_backup:
            backup_path = file_path + f".backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            shutil.copy2(file_path, backup_path)
            print(f"ğŸ“ ë°±ì—… íŒŒì¼ ìƒì„±: {backup_path}")
        
        indices_to_remove = set()
        
        for content_key, items in duplicates_data.items():
            if len(items) > 1:
                sorted_items = sorted(items, key=lambda x: x['index'])
                for item in sorted_items[1:]:
                    indices_to_remove.add(item['index'])
        
        sorted_indices = sorted(indices_to_remove, reverse=True)
        
        removed_count = 0
        for index in sorted_indices:
            if 0 <= index < len(data):
                del data[index]
                removed_count += 1
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… {removed_count}ê°œì˜ ì¤‘ë³µ ë¬¸ì œ ì‚­ì œ ì™„ë£Œ")
        return removed_count, len(data)
        
    except Exception as e:
        print(f"âŒ ì¤‘ë³µ ì‚­ì œ ì‹¤íŒ¨: {file_path} - {e}")
        return 0, 0


def find_extracted_qna_files(directory_path: str) -> List[str]:
    """ë””ë ‰í† ë¦¬ í•˜ìœ„ì˜ ëª¨ë“  extracted_qna.json íŒŒì¼ì„ ì°¾ëŠ” í•¨ìˆ˜"""
    pattern = os.path.join(directory_path, "**", "*extracted_qna.json")
    files = glob.glob(pattern, recursive=True)
    return sorted(files)


def check_duplicates(directory_path: str, remove_duplicates: bool = False) -> Tuple[int, int]:
    """
    ë””ë ‰í† ë¦¬ í•˜ìœ„ì˜ ëª¨ë“  extracted_qna.json íŒŒì¼ì„ ê²€ì‚¬
    
    Args:
        directory_path: ê²€ì‚¬í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
        remove_duplicates: ì¤‘ë³µ ì‚­ì œ ì—¬ë¶€
        
    Returns:
        (ì´ QnA ìˆ˜, ì´ ì¤‘ë³µ ê·¸ë£¹ ìˆ˜)
    """
    print(f"ğŸ” ê²€ì‚¬ ëŒ€ìƒ ë””ë ‰í† ë¦¬: {directory_path}")
    
    files = find_extracted_qna_files(directory_path)
    
    if not files:
        print(f"âŒ extracted_qna.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return 0, 0
    
    print(f"ğŸ“‹ ë°œê²¬ëœ íŒŒì¼ ìˆ˜: {len(files)}ê°œ")
    print("=" * 80)
    
    total_qna = 0
    total_duplicates = 0
    files_with_duplicates = 0
    files_with_duplicates_data = []
    
    for i, file_path in enumerate(files, 1):
        print(f"\n[{i}/{len(files)}]")
        qna_count, duplicate_count, duplicates = check_duplicates_single_file(file_path, return_details=True)
        
        total_qna += qna_count
        total_duplicates += duplicate_count
        if duplicate_count > 0:
            files_with_duplicates += 1
            files_with_duplicates_data.append({
                'filename': os.path.basename(file_path),
                'filepath': file_path,
                'total_qna': qna_count,
                'duplicate_groups': duplicate_count,
                'duplicates': duplicates
            })
        
        print("-" * 40)
    
    # ì „ì²´ ìš”ì•½
    print(f"\n{'='*80}")
    print(f"ğŸ“Š ì „ì²´ ê²€ì‚¬ ê²°ê³¼ ìš”ì•½")
    print(f"{'='*80}")
    print(f"ê²€ì‚¬ëœ íŒŒì¼ ìˆ˜: {len(files)}ê°œ")
    print(f"ì´ Q&A ê°œìˆ˜: {total_qna}ê°œ")
    print(f"ì´ ì¤‘ë³µ ê·¸ë£¹ ìˆ˜: {total_duplicates}ê°œ")
    print(f"ì¤‘ë³µì´ ìˆëŠ” íŒŒì¼ ìˆ˜: {files_with_duplicates}ê°œ")
    
    if total_duplicates == 0:
        print(f"âœ… ëª¨ë“  íŒŒì¼ì—ì„œ ì¤‘ë³µ ì—†ìŒ - ëª¨ë“  Q&Aê°€ ê³ ìœ í•©ë‹ˆë‹¤!")
    else:
        print(f"âš ï¸  {files_with_duplicates}ê°œ íŒŒì¼ì—ì„œ ì¤‘ë³µ ë°œê²¬ - ì •ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        if files_with_duplicates >= 1:
            print(f"\nğŸ’¾ ì¤‘ë³µ ê²€ì‚¬ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤...")
            
            duplicates_data = {
                'summary': {
                    'total_files': len(files),
                    'total_qna': total_qna,
                    'total_duplicates': total_duplicates,
                    'files_with_duplicates': files_with_duplicates
                },
                'files_with_duplicates': files_with_duplicates_data
            }
            
            try:
                txt_file = save_duplicates_report(duplicates_data, directory_path)
                print(f"âœ… í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ì €ì¥: {txt_file}")
            except Exception as e:
                print(f"âŒ ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            
            if remove_duplicates:
                print(f"\nğŸ—‘ï¸  ì¤‘ë³µ ë¬¸ì œ ì‚­ì œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
                total_removed = 0
                files_processed = 0
                
                for file_info in files_with_duplicates_data:
                    file_path = file_info['filepath']
                    print(f"\nğŸ“ ì²˜ë¦¬ ì¤‘: {os.path.basename(file_path)}")
                    
                    removed_count, remaining_count = remove_duplicates_from_file(
                        file_path, 
                        file_info['duplicates']
                    )
                    
                    if removed_count > 0:
                        total_removed += removed_count
                        files_processed += 1
                        print(f"   ì‚­ì œëœ ë¬¸ì œ: {removed_count}ê°œ")
                        print(f"   ë‚¨ì€ ë¬¸ì œ: {remaining_count}ê°œ")
                
                print(f"\nğŸ“Š ì¤‘ë³µ ì‚­ì œ ì™„ë£Œ:")
                print(f"   ì²˜ë¦¬ëœ íŒŒì¼: {files_processed}ê°œ")
                print(f"   ì´ ì‚­ì œëœ ë¬¸ì œ: {total_removed}ê°œ")
                
                # ì‚­ì œ í›„ ì¬ê²€ì‚¬
                print(f"\nğŸ” ì‚­ì œ í›„ ì¬ê²€ì‚¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
                check_duplicates(directory_path, remove_duplicates=False)
    
    return total_qna, total_duplicates


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python check_duplicates.py <cycle> [--remove]")
        print("ì˜ˆì‹œ: python check_duplicates.py 1")
        print("ì˜ˆì‹œ: python check_duplicates.py 1 --remove")
        sys.exit(1)
    
    cycle = sys.argv[1]
    remove_flag = len(sys.argv) >= 3 and sys.argv[2] == "--remove"
    
    directory_path = os.path.join(ONEDRIVE_PATH, 'evaluation', 'workbook_data', f'{cycle}C', 'Lv5')
    
    if not os.path.exists(directory_path):
        print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {directory_path}")
        sys.exit(1)
    
    if not os.path.isdir(directory_path):
        print(f"âŒ ê²½ë¡œê°€ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {directory_path}")
        sys.exit(1)
    
    check_duplicates(directory_path, remove_flag)


if __name__ == "__main__":
    main()

