#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import os
from collections import defaultdict, Counter

def classify_questions_by_book_domain(multiple_for_grp):
    """
    multiple_for_grp ë¦¬ìŠ¤íŠ¸ì—ì„œ ë„ì„œì™€ domainë³„ë¡œ ë¬¸ì œë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    
    Args:
        multiple_for_grp: ë¬¸ì œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    
    Returns:
        dict: ë„ì„œë³„, ë„ë©”ì¸ë³„ë¡œ ë¶„ë¥˜ëœ ë¬¸ì œ ë”•ì…”ë„ˆë¦¬
    """
    
    # ë„ì„œë³„, ë„ë©”ì¸ë³„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    book_domain_classification = defaultdict(lambda: defaultdict(list))
    
    print(f"ì´ {len(multiple_for_grp)}ê°œ ë¬¸ì œë¥¼ ë„ì„œì™€ ë„ë©”ì¸ë³„ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤...")
    
    for i, question in enumerate(multiple_for_grp):
        try:
            # ë„ì„œ ì œëª©ê³¼ ë„ë©”ì¸ ì •ë³´ ì¶”ì¶œ
            id = question.get('file_id', 'Unknown ID')
            title = question.get('title', 'Unknown Book')
            book_title = f"{id}_{title}"
            domain = question.get('qna_domain', 'Unknown Domain')
            
            # ë¬¸ì œ ë°ì´í„°ë¥¼ í•´ë‹¹ ë„ì„œ-ë„ë©”ì¸ì— ì¶”ê°€
            book_domain_classification[book_title][domain].append({
                'index': i,
                'question_data': question
            })
            
        except Exception as e:
            print(f"ë¬¸ì œ {i} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue
    
    return dict(book_domain_classification)

def save_classified_questions(book_domain_data, output_dir="book_domain_classified"):
    """
    ë¶„ë¥˜ëœ ë¬¸ì œë“¤ì„ ë„ì„œë³„, ë„ë©”ì¸ë³„ë¡œ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        book_domain_data: ë¶„ë¥˜ëœ ë¬¸ì œ ë°ì´í„°
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"\në¶„ë¥˜ëœ ë¬¸ì œë“¤ì„ '{output_dir}' ë””ë ‰í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤...")
    
    # í†µê³„ ì •ë³´
    total_books = len(book_domain_data)
    total_domains = sum(len(domains) for domains in book_domain_data.values())
    total_questions = sum(
        len(questions) 
        for domains in book_domain_data.values() 
        for questions in domains.values()
    )
    
    print(f"ì´ {total_books}ê°œ ë„ì„œ, {total_domains}ê°œ ë„ë©”ì¸, {total_questions}ê°œ ë¬¸ì œ")
    
    # ë„ì„œë³„ë¡œ íŒŒì¼ ì €ì¥
    book_summary = []
    
    for book_title, domains in book_domain_data.items():
        # ë„ì„œëª…ì—ì„œ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
        safe_book_name = "".join(c for c in book_title if c.isalnum() or c in (' ', '-', '_')).rstrip()
        safe_book_name = safe_book_name.replace(' ', '_')
        
        book_file = os.path.join(output_dir, f"{safe_book_name}.json")
        
        # ë„ì„œë³„ ë°ì´í„° êµ¬ì„±
        book_data = {
            'book_info': {
                'title': book_title,
                'total_domains': len(domains),
                'total_questions': sum(len(questions) for questions in domains.values())
            },
            'domains': {}
        }
        
        # ë„ë©”ì¸ë³„ ë°ì´í„° êµ¬ì„±
        for domain_name, questions in domains.items():
            domain_data = {
                'domain_name': domain_name,
                'question_count': len(questions),
                'questions': []
            }
            
            for item in questions:
                question_data = {
                    'index': item['index'],
                    'tag': item['question_data'].get('qna_id', ''),
                    'domain': item['question_data'].get('qna_domain', ''),
                    'question': item['question_data'].get('qna_question', ''),
                    'options': item['question_data'].get('qna_options', []),
                    'answer': item['question_data'].get('qna_answer', ''),
                    'explanation': item['question_data'].get('qna_explanation', ''),
                    'file_id': item['question_data'].get('file_id', '')
                }
                domain_data['questions'].append(question_data)
            
            book_data['domains'][domain_name] = domain_data
        
        # ë„ì„œë³„ JSON íŒŒì¼ ì €ì¥
        with open(book_file, 'w', encoding='utf-8') as f:
            json.dump(book_data, f, ensure_ascii=False, indent=2)
        
        # ìš”ì•½ ì •ë³´ ìˆ˜ì§‘
        book_summary.append({
            'book_title': book_title,
            'file_name': f"{safe_book_name}.json",
            'total_domains': len(domains),
            'total_questions': sum(len(questions) for questions in domains.values()),
            'domains': list(domains.keys())
        })
        
        print(f"  ğŸ“š {book_title}: {len(domains)}ê°œ ë„ë©”ì¸, {sum(len(questions) for questions in domains.values())}ê°œ ë¬¸ì œ")
    
    # ì „ì²´ ìš”ì•½ ì •ë³´ ì €ì¥
    summary_file = os.path.join(output_dir, "domain_classification_summary.json")
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump({
            'total_books': total_books,
            'total_domains': total_domains,
            'total_questions': total_questions,
            'books': book_summary
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ë¶„ë¥˜ ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_dir}/")
    print(f"ğŸ“Š ìš”ì•½ ì •ë³´: {summary_file}")
    
    return book_summary

def create_analysis_report(book_domain_data, output_dir="book_domain_classified"):
    """
    ë¶„ë¥˜ ê²°ê³¼ì— ëŒ€í•œ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        book_domain_data: ë¶„ë¥˜ëœ ë¬¸ì œ ë°ì´í„°
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    
    report = []
    report.append("# ë„ì„œë³„, ë„ë©”ì¸ë³„ ë¬¸ì œ ë¶„ë¥˜ ë¶„ì„ ë¦¬í¬íŠ¸")
    report.append("=" * 60)
    
    # ì „ì²´ í†µê³„
    total_books = len(book_domain_data)
    total_domains = sum(len(domains) for domains in book_domain_data.values())
    total_questions = sum(
        len(questions) 
        for domains in book_domain_data.values() 
        for questions in domains.values()
    )
    
    report.append(f"## ì „ì²´ í†µê³„")
    report.append(f"- ì´ ë„ì„œ ìˆ˜: {total_books}ê°œ")
    report.append(f"- ì´ ë„ë©”ì¸ ìˆ˜: {total_domains}ê°œ")
    report.append(f"- ì´ ë¬¸ì œ ìˆ˜: {total_questions}ê°œ")
    report.append(f"- í‰ê·  ë„ë©”ì¸ë‹¹ ë¬¸ì œ ìˆ˜: {total_questions/total_domains:.1f}ê°œ")
    report.append("")
    
    # ë„ì„œë³„ ìƒì„¸ ì •ë³´
    report.append("## ë„ì„œë³„ ìƒì„¸ ì •ë³´")
    
    for book_title, domains in book_domain_data.items():
        book_question_count = sum(len(questions) for questions in domains.values())
        
        report.append(f"### ğŸ“š {book_title}")
        report.append(f"- ì´ ë„ë©”ì¸ ìˆ˜: {len(domains)}ê°œ")
        report.append(f"- ì´ ë¬¸ì œ ìˆ˜: {book_question_count}ê°œ")
        report.append("")
        
        # ë„ë©”ì¸ë³„ ì •ë³´
        report.append("**ë„ë©”ì¸ë³„ ë¬¸ì œ ë¶„í¬:**")
        for domain_name, questions in sorted(domains.items(), key=lambda x: len(x[1]), reverse=True):
            report.append(f"- {domain_name}: {len(questions)}ê°œ")
        report.append("")
        report.append("---")
        report.append("")
    
    # ë„ë©”ì¸ë³„ í†µê³„
    report.append("## ë„ë©”ì¸ë³„ í†µê³„ (ë¬¸ì œ ìˆ˜ ìƒìœ„ 20ê°œ)")
    
    all_domains = []
    for book_title, domains in book_domain_data.items():
        for domain_name, questions in domains.items():
            all_domains.append({
                'book': book_title,
                'domain': domain_name,
                'question_count': len(questions)
            })
    
    # ë¬¸ì œ ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    all_domains.sort(key=lambda x: x['question_count'], reverse=True)
    
    for i, domain_info in enumerate(all_domains[:20], 1):
        report.append(f"{i}. **{domain_info['book']}** - {domain_info['domain']}: {domain_info['question_count']}ê°œ")
    
    # ì „ì²´ ë„ë©”ì¸ í†µê³„
    report.append("\n## ì „ì²´ ë„ë©”ì¸ í†µê³„")
    domain_counts = Counter()
    for domains in book_domain_data.values():
        for domain_name, questions in domains.items():
            domain_counts[domain_name] += len(questions)
    
    report.append("**ë„ë©”ì¸ë³„ ì´ ë¬¸ì œ ìˆ˜:**")
    for domain, count in domain_counts.most_common(20):
        report.append(f"- {domain}: {count}ê°œ")
    
    # ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥
    report_file = os.path.join(output_dir, "domain_analysis_report.md")
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report))
    
    print(f"ğŸ“Š ë¶„ì„ ë¦¬í¬íŠ¸ê°€ '{report_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    
    # multiple_for_grp ë¦¬ìŠ¤íŠ¸ë¥¼ ë¡œë“œ (ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ì´ ë¶€ë¶„ì„ ìˆ˜ì •)
    print("multiple_for_grp ë¦¬ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
    
    # ì˜ˆì‹œ: multiple.jsonì—ì„œ ë°ì´í„° ë¡œë“œ
    try:
        with open('/Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/multiple.json', 'r', encoding='utf-8') as f:
            multiple_for_grp = json.load(f)
        print(f"âœ… {len(multiple_for_grp)}ê°œ ë¬¸ì œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    except FileNotFoundError:
        print("âŒ multiple.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("multiple_for_grp ë¦¬ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ì œê³µí•´ì£¼ì„¸ìš”.")
        return
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return
    
    # ë„ì„œì™€ ë„ë©”ì¸ë³„ë¡œ ë¶„ë¥˜
    book_domain_data = classify_questions_by_book_domain(multiple_for_grp)
    
    # ë¶„ë¥˜ëœ ë¬¸ì œë“¤ì„ íŒŒì¼ë¡œ ì €ì¥
    book_summary = save_classified_questions(book_domain_data)
    
    # ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
    create_analysis_report(book_domain_data)
    
    print(f"\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ğŸ“ ê²°ê³¼ íŒŒì¼ë“¤: book_domain_classified/ ë””ë ‰í† ë¦¬")

if __name__ == "__main__":
    main()

