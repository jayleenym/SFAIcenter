#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import os
from collections import defaultdict, Counter

def classify_questions_by_book_chapter(multiple_for_grp):
    """
    multiple_for_grp ë¦¬ìŠ¤íŠ¸ì—ì„œ ë„ì„œì™€ chapterë³„ë¡œ ë¬¸ì œë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    
    Args:
        multiple_for_grp: ë¬¸ì œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    
    Returns:
        dict: ë„ì„œë³„, ì±•í„°ë³„ë¡œ ë¶„ë¥˜ëœ ë¬¸ì œ ë”•ì…”ë„ˆë¦¬
    """
    
    # ë„ì„œë³„, ì±•í„°ë³„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    book_chapter_classification = defaultdict(lambda: defaultdict(list))
    
    print(f"ì´ {len(multiple_for_grp)}ê°œ ë¬¸ì œë¥¼ ë„ì„œì™€ ì±•í„°ë³„ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤...")
    
    for i, question in enumerate(multiple_for_grp):
        try:
            # ë„ì„œ ì œëª©ê³¼ ì±•í„° ì •ë³´ ì¶”ì¶œ
            id = question.get('file_id', 'Unknown ID')
            title = question.get('title', 'Unknown Book')
            book_title = f"{id}_{title}"
            chapter = question.get('chapter', 'Unknown Chapter')
            
            # ë¬¸ì œ ë°ì´í„°ë¥¼ í•´ë‹¹ ë„ì„œ-ì±•í„°ì— ì¶”ê°€
            book_chapter_classification[book_title][chapter].append({
                'index': i,
                'question_data': question
            })
            
        except Exception as e:
            print(f"ë¬¸ì œ {i} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue
    
    return dict(book_chapter_classification)

def save_classified_questions(book_chapter_data, output_dir="book_chapter_classified"):
    """
    ë¶„ë¥˜ëœ ë¬¸ì œë“¤ì„ ë„ì„œë³„, ì±•í„°ë³„ë¡œ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        book_chapter_data: ë¶„ë¥˜ëœ ë¬¸ì œ ë°ì´í„°
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"\në¶„ë¥˜ëœ ë¬¸ì œë“¤ì„ '{output_dir}' ë””ë ‰í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤...")
    
    # í†µê³„ ì •ë³´
    total_books = len(book_chapter_data)
    total_chapters = sum(len(chapters) for chapters in book_chapter_data.values())
    total_questions = sum(
        len(questions) 
        for chapters in book_chapter_data.values() 
        for questions in chapters.values()
    )
    
    print(f"ì´ {total_books}ê°œ ë„ì„œ, {total_chapters}ê°œ ì±•í„°, {total_questions}ê°œ ë¬¸ì œ")
    
    # ë„ì„œë³„ë¡œ íŒŒì¼ ì €ì¥
    book_summary = []

    for book_title, chapters in book_chapter_data.items():
        # ë„ì„œëª…ì—ì„œ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
        safe_book_name = "".join(c for c in book_title if c.isalnum() or c in (' ', '-', '_')).rstrip()
        safe_book_name = safe_book_name.replace(' ', '_')
        
        book_file = os.path.join(output_dir, f"{safe_book_name}.json")
        
        # ë„ì„œë³„ ë°ì´í„° êµ¬ì„±
        book_data = {
            'book_info': {
                'title': book_title,
                'total_chapters': len(chapters),
                'total_questions': sum(len(questions) for questions in chapters.values())
            },
            'chapters': {}
        }
        
        # ì±•í„°ë³„ ë°ì´í„° êµ¬ì„±
        for chapter_name, questions in chapters.items():
            chapter_data = {
                'chapter_name': chapter_name,
                'question_count': len(questions),
                'questions': []
            }
            
            for item in questions:
                question_data = {
                    'index': item['index'],
                    'tag': item['question_data'].get('qna_id', ''),
                    'domain': item['question_data'].get('qna_domain', ''),
                    'question': item['question_data'].get('qna_question', ''),
                    'options': item['question_data'].get('qna_options', []),
                    'answer': item['question_data'].get('qna_answer', ''),
                    'explanation': item['question_data'].get('qna_explanation', ''),
                    
                    # 'page': item['question_data'].get('page', ''),
                    
                }
                chapter_data['questions'].append(question_data)
            
            book_data['chapters'][chapter_name] = chapter_data
        
        # ë„ì„œë³„ JSON íŒŒì¼ ì €ì¥
        with open(book_file, 'w', encoding='utf-8') as f:
            json.dump(book_data, f, ensure_ascii=False, indent=2)
        
        # ìš”ì•½ ì •ë³´ ìˆ˜ì§‘
        book_summary.append({
            'book_title': book_title,
            'file_name': f"{safe_book_name}.json",
            'total_chapters': len(chapters),
            'total_questions': sum(len(questions) for questions in chapters.values()),
            'chapters': list(chapters.keys())
        })
        
        print(f"  ğŸ“š {book_title}: {len(chapters)}ê°œ ì±•í„°, {sum(len(questions) for questions in chapters.values())}ê°œ ë¬¸ì œ")
    
    # ì „ì²´ ìš”ì•½ ì •ë³´ ì €ì¥
    summary_file = os.path.join(output_dir, "classification_summary.json")
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump({
            'total_books': total_books,
            'total_chapters': total_chapters,
            'total_questions': total_questions,
            'books': book_summary
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ë¶„ë¥˜ ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_dir}/")
    print(f"ğŸ“Š ìš”ì•½ ì •ë³´: {summary_file}")
    
    return book_summary

def create_analysis_report(book_chapter_data, output_dir="book_chapter_classified"):
    """
    ë¶„ë¥˜ ê²°ê³¼ì— ëŒ€í•œ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        book_chapter_data: ë¶„ë¥˜ëœ ë¬¸ì œ ë°ì´í„°
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    
    report = []
    report.append("# ë„ì„œë³„, ì±•í„°ë³„ ë¬¸ì œ ë¶„ë¥˜ ë¶„ì„ ë¦¬í¬íŠ¸")
    report.append("=" * 60)
    
    # ì „ì²´ í†µê³„
    total_books = len(book_chapter_data)
    total_chapters = sum(len(chapters) for chapters in book_chapter_data.values())
    total_questions = sum(
        len(questions) 
        for chapters in book_chapter_data.values() 
        for questions in chapters.values()
    )
    
    report.append(f"## ì „ì²´ í†µê³„")
    report.append(f"- ì´ ë„ì„œ ìˆ˜: {total_books}ê°œ")
    report.append(f"- ì´ ì±•í„° ìˆ˜: {total_chapters}ê°œ")
    report.append(f"- ì´ ë¬¸ì œ ìˆ˜: {total_questions}ê°œ")
    report.append(f"- í‰ê·  ì±•í„°ë‹¹ ë¬¸ì œ ìˆ˜: {total_questions/total_chapters:.1f}ê°œ")
    report.append("")
    
    # ë„ì„œë³„ ìƒì„¸ ì •ë³´
    report.append("## ë„ì„œë³„ ìƒì„¸ ì •ë³´")
    
    for book_title, chapters in book_chapter_data.items():
        book_question_count = sum(len(questions) for questions in chapters.values())
        
        report.append(f"### ğŸ“š {book_title}")
        report.append(f"- ì´ ì±•í„° ìˆ˜: {len(chapters)}ê°œ")
        report.append(f"- ì´ ë¬¸ì œ ìˆ˜: {book_question_count}ê°œ")
        report.append("")
        
        # ì±•í„°ë³„ ì •ë³´
        report.append("**ì±•í„°ë³„ ë¬¸ì œ ë¶„í¬:**")
        for chapter_name, questions in sorted(chapters.items(), key=lambda x: len(x[1]), reverse=True):
            report.append(f"- {chapter_name}: {len(questions)}ê°œ")
        report.append("")
        
        # ë„ë©”ì¸ë³„ ë¶„í¬
        domains = []
        for questions in chapters.values():
            for item in questions:
                domain = item['question_data'].get('qna_domain', 'Unknown')
                domains.append(domain)
        
        domain_counts = Counter(domains)
        if domain_counts:
            report.append("**ì£¼ìš” ë„ë©”ì¸:**")
            for domain, count in domain_counts.most_common(5):
                report.append(f"- {domain}: {count}ê°œ")
        report.append("")
        report.append("---")
        report.append("")
    
    # ì±•í„°ë³„ í†µê³„
    report.append("## ì±•í„°ë³„ í†µê³„ (ë¬¸ì œ ìˆ˜ ìƒìœ„ 20ê°œ)")
    
    all_chapters = []
    for book_title, chapters in book_chapter_data.items():
        for chapter_name, questions in chapters.items():
            all_chapters.append({
                'book': book_title,
                'chapter': chapter_name,
                'question_count': len(questions)
            })
    
    # ë¬¸ì œ ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    all_chapters.sort(key=lambda x: x['question_count'], reverse=True)
    
    for i, chapter_info in enumerate(all_chapters[:20], 1):
        report.append(f"{i}. **{chapter_info['book']}** - {chapter_info['chapter']}: {chapter_info['question_count']}ê°œ")
    
    # ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥
    report_file = os.path.join(output_dir, "analysis_report.md")
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report))
    
    print(f"ğŸ“Š ë¶„ì„ ë¦¬í¬íŠ¸ê°€ '{report_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    
    # multiple_for_grp ë¦¬ìŠ¤íŠ¸ë¥¼ ë¡œë“œ (ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ì´ ë¶€ë¶„ì„ ìˆ˜ì •)
    print("multiple_for_grp ë¦¬ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
    
    # ì˜ˆì‹œ: multiple.jsonì—ì„œ ë°ì´í„° ë¡œë“œ
    try:
        with open('/Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/multiple.json', 'r', encoding='utf-8') as f:
            multiple_for_grp = json.load(f)
        print(f"âœ… {len(multiple_for_grp)}ê°œ ë¬¸ì œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    except FileNotFoundError:
        print("âŒ multiple.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("multiple_for_grp ë¦¬ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ì œê³µí•´ì£¼ì„¸ìš”.")
        return
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return
    
    # ë„ì„œì™€ ì±•í„°ë³„ë¡œ ë¶„ë¥˜
    book_chapter_data = classify_questions_by_book_chapter(multiple_for_grp)
    
    # ë¶„ë¥˜ëœ ë¬¸ì œë“¤ì„ íŒŒì¼ë¡œ ì €ì¥
    book_summary = save_classified_questions(book_chapter_data)
    
    # ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
    create_analysis_report(book_chapter_data)
    
    print(f"\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ğŸ“ ê²°ê³¼ íŒŒì¼ë“¤: book_chapter_classified/ ë””ë ‰í† ë¦¬")

if __name__ == "__main__":
    main()
