#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import os
from collections import defaultdict, Counter

def classify_questions_by_domain_chapter(multiple_for_grp):
    """
    multiple_for_grp ë¦¬ìŠ¤íŠ¸ì—ì„œ qna_domainê³¼ chapterë³„ë¡œ ë¬¸ì œë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    
    Args:
        multiple_for_grp: ë¬¸ì œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    
    Returns:
        dict: ë„ë©”ì¸ë³„, ì±•í„°ë³„ë¡œ ë¶„ë¥˜ëœ ë¬¸ì œ ë”•ì…”ë„ˆë¦¬
    """
    
    # ë„ë©”ì¸ë³„, ì±•í„°ë³„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    domain_chapter_classification = defaultdict(lambda: defaultdict(list))
    
    print(f"ì´ {len(multiple_for_grp)}ê°œ ë¬¸ì œë¥¼ ë„ë©”ì¸ê³¼ ì±•í„°ë³„ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤...")
    
    for i, question in enumerate(multiple_for_grp):
        try:
            # ë„ë©”ì¸ê³¼ ì±•í„° ì •ë³´ ì¶”ì¶œ
            domain = question.get('qna_domain', 'Unknown Domain')
            chapter = question.get('chapter', 'Unknown Chapter')
            book_title = question.get('title', 'Unknown Book')
            
            # ë¬¸ì œ ë°ì´í„°ë¥¼ í•´ë‹¹ ë„ë©”ì¸-ì±•í„°ì— ì¶”ê°€
            domain_chapter_classification[domain][chapter].append({
                'index': i,
                'question_data': question,
                'book_title': book_title
            })
            
        except Exception as e:
            print(f"ë¬¸ì œ {i} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue
    
    return dict(domain_chapter_classification)

def analyze_domain_chapters(domain_chapter_data):
    """
    ë„ë©”ì¸ë³„ë¡œ ë³´ìœ í•˜ê³  ìˆëŠ” ì±•í„°ë“¤ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        domain_chapter_data: ë¶„ë¥˜ëœ ë¬¸ì œ ë°ì´í„°
    
    Returns:
        tuple: (ë„ë©”ì¸ë³„ ì±•í„° ë¶„ì„, ë„ë©”ì¸ë³„ ë„ì„œ-ì±•í„° ë§¤í•‘)
    """
    
    domain_chapter_analysis = {}
    domain_book_chapters = {}
    
    print("\në„ë©”ì¸ë³„ ì±•í„° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
    
    for domain, chapters in domain_chapter_data.items():
        # ë„ë©”ì¸ë³„ í†µê³„
        total_questions = sum(len(questions) for questions in chapters.values())
        total_chapters = len(chapters)
        
        # ë„ë©”ì¸ë³„ ë„ì„œ-ì±•í„° ë§¤í•‘
        book_chapter_mapping = defaultdict(set)
        for chapter_name, questions in chapters.items():
            for item in questions:
                book_title = item['book_title']
                book_chapter_mapping[book_title].add(chapter_name)
        
        # ë„ë©”ì¸ë³„ ì±•í„° ë¶„ì„ ë°ì´í„°
        domain_chapter_analysis[domain] = {
            'domain_name': domain,
            'total_questions': total_questions,
            'total_chapters': total_chapters,
            'total_books': len(book_chapter_mapping),
            'chapters': list(chapters.keys()),
            'chapter_question_counts': {
                chapter: len(questions) for chapter, questions in chapters.items()
            }
        }
        
        # ë„ë©”ì¸ë³„ ë„ì„œ-ì±•í„° ë§¤í•‘
        domain_book_chapters[domain] = {
            book_title: list(chapters) for book_title, chapters in book_chapter_mapping.items()
        }
        
        print(f"  ğŸ“Š {domain}: {total_questions}ê°œ ë¬¸ì œ, {total_chapters}ê°œ ì±•í„°, {len(book_chapter_mapping)}ê°œ ë„ì„œ")
    
    return domain_chapter_analysis, domain_book_chapters

def save_domain_classified_questions(domain_chapter_data, output_dir="book_domain_chapter_classified"):
    """
    ë¶„ë¥˜ëœ ë¬¸ì œë“¤ì„ ë„ë©”ì¸ë³„, ì±•í„°ë³„ë¡œ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        domain_chapter_data: ë¶„ë¥˜ëœ ë¬¸ì œ ë°ì´í„°
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"\në¶„ë¥˜ëœ ë¬¸ì œë“¤ì„ '{output_dir}' ë””ë ‰í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤...")
    
    # í†µê³„ ì •ë³´
    total_domains = len(domain_chapter_data)
    total_chapters = sum(len(chapters) for chapters in domain_chapter_data.values())
    total_questions = sum(
        len(questions) 
        for chapters in domain_chapter_data.values() 
        for questions in chapters.values()
    )
    
    print(f"ì´ {total_domains}ê°œ ë„ë©”ì¸, {total_chapters}ê°œ ì±•í„°, {total_questions}ê°œ ë¬¸ì œ")
    
    # ë„ë©”ì¸ë³„ë¡œ íŒŒì¼ ì €ì¥
    domain_summary = []
    
    for domain, chapters in domain_chapter_data.items():
        # ë„ë©”ì¸ëª…ì—ì„œ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
        safe_domain_name = "".join(c for c in domain if c.isalnum() or c in (' ', '-', '_')).rstrip()
        safe_domain_name = safe_domain_name.replace(' ', '_')
        
        domain_file = os.path.join(output_dir, f"domain_{safe_domain_name}.json")
        
        # ë„ë©”ì¸ë³„ ë°ì´í„° êµ¬ì„±
        domain_data = {
            'domain_info': {
                'domain_name': domain,
                'total_chapters': len(chapters),
                'total_questions': sum(len(questions) for questions in chapters.values())
            },
            'chapters': {}
        }
        
        # ì±•í„°ë³„ ë°ì´í„° êµ¬ì„±
        for chapter_name, questions in chapters.items():
            chapter_data = {
                'chapter_name': chapter_name,
                'question_count': len(questions),
                'books': list(set(item['book_title'] for item in questions)),
                'questions': []
            }
            
            for item in questions:
                # ì›ë³¸ ë°ì´í„° êµ¬ì¡°ì—ì„œ ë¬¸ì œ ë°ì´í„° ì¶”ì¶œ
                question_data = {
                    'index': item['index'],
                    'file_id': item['question_data'].get('file_id', ''),
                    'book_title': item['book_title'],
                    'chapter': item['question_data'].get('chapter', ''),
                    # 'page': item['question_data'].get('page', ''),
                    'qna_domain': item['question_data'].get('qna_domain', ''),
                    'qna_id': item['question_data'].get('qna_id', ''),
                    'qna_reason': item['question_data'].get('qna_reason', ''),
                    'question': item['question_data'].get('qna_question', ''),
                    'options': item['question_data'].get('qna_options', []),
                    'answer': item['question_data'].get('qna_answer', ''),
                    'explanation': item['question_data'].get('qna_explanation', '')
                }
                chapter_data['questions'].append(question_data)
            
            domain_data['chapters'][chapter_name] = chapter_data
        
        # ë„ë©”ì¸ë³„ JSON íŒŒì¼ ì €ì¥
        with open(domain_file, 'w', encoding='utf-8') as f:
            json.dump(domain_data, f, ensure_ascii=False, indent=2)
        
        # ìš”ì•½ ì •ë³´ ìˆ˜ì§‘
        domain_summary.append({
            'domain_name': domain,
            'file_name': f"domain_{safe_domain_name}.json",
            'total_chapters': len(chapters),
            'total_questions': sum(len(questions) for questions in chapters.values()),
            'chapters': list(chapters.keys())
        })
        
        print(f"  ğŸ“Š {domain}: {len(chapters)}ê°œ ì±•í„°, {sum(len(questions) for questions in chapters.values())}ê°œ ë¬¸ì œ")
    
    # ì „ì²´ ìš”ì•½ ì •ë³´ ì €ì¥
    summary_file = os.path.join(output_dir, "domain_classification_summary.json")
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump({
            'total_domains': total_domains,
            'total_chapters': total_chapters,
            'total_questions': total_questions,
            'domains': domain_summary
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ë¶„ë¥˜ ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_dir}/")
    print(f"ğŸ“Š ìš”ì•½ ì •ë³´: {summary_file}")
    
    return domain_summary

def save_domain_chapter_analysis(domain_chapter_analysis, domain_book_chapters, output_dir="book_domain_chapter_classified"):
    """
    ë„ë©”ì¸ë³„ ì±•í„° ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        domain_chapter_analysis: ë„ë©”ì¸ë³„ ì±•í„° ë¶„ì„ ë°ì´í„°
        domain_book_chapters: ë„ë©”ì¸ë³„ ë„ì„œ-ì±•í„° ë§¤í•‘
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    
    # ë„ë©”ì¸ë³„ ì±•í„° ë¶„ì„ ê²°ê³¼ ì €ì¥
    analysis_file = os.path.join(output_dir, "domain_chapter_analysis.json")
    with open(analysis_file, 'w', encoding='utf-8') as f:
        json.dump({
            'domain_analysis': domain_chapter_analysis,
            'domain_book_chapters': domain_book_chapters
        }, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“Š ë„ë©”ì¸ë³„ ì±•í„° ë¶„ì„ ê²°ê³¼ê°€ '{analysis_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return analysis_file

def create_domain_chapter_report(domain_chapter_analysis, domain_book_chapters, output_dir="book_domain_chapter_classified"):
    """
    ë„ë©”ì¸ë³„ ì±•í„° ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        domain_chapter_analysis: ë„ë©”ì¸ë³„ ì±•í„° ë¶„ì„ ë°ì´í„°
        domain_book_chapters: ë„ë©”ì¸ë³„ ë„ì„œ-ì±•í„° ë§¤í•‘
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    
    report = []
    report.append("# ë„ë©”ì¸ë³„, ì±•í„°ë³„ ë¬¸ì œ ë¶„ë¥˜ ë¶„ì„ ë¦¬í¬íŠ¸")
    report.append("=" * 60)
    
    # ì „ì²´ í†µê³„
    total_domains = len(domain_chapter_analysis)
    total_chapters = sum(data['total_chapters'] for data in domain_chapter_analysis.values())
    total_questions = sum(data['total_questions'] for data in domain_chapter_analysis.values())
    total_books = sum(data['total_books'] for data in domain_chapter_analysis.values())
    
    report.append(f"## ì „ì²´ í†µê³„")
    report.append(f"- ì´ ë„ë©”ì¸ ìˆ˜: {total_domains}ê°œ")
    report.append(f"- ì´ ì±•í„° ìˆ˜: {total_chapters}ê°œ")
    report.append(f"- ì´ ë¬¸ì œ ìˆ˜: {total_questions}ê°œ")
    report.append(f"- ì´ ë„ì„œ ìˆ˜: {total_books}ê°œ")
    report.append(f"- í‰ê·  ë„ë©”ì¸ë‹¹ ì±•í„° ìˆ˜: {total_chapters/total_domains:.1f}ê°œ")
    report.append(f"- í‰ê·  ë„ë©”ì¸ë‹¹ ë¬¸ì œ ìˆ˜: {total_questions/total_domains:.1f}ê°œ")
    report.append("")
    
    # ë„ë©”ì¸ë³„ ìƒì„¸ ì •ë³´
    report.append("## ë„ë©”ì¸ë³„ ìƒì„¸ ì •ë³´")
    
    # ë¬¸ì œ ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_domains = sorted(domain_chapter_analysis.items(), key=lambda x: x[1]['total_questions'], reverse=True)
    
    for domain, data in sorted_domains:
        report.append(f"### ğŸ“Š {domain}")
        report.append(f"- ì´ ë¬¸ì œ ìˆ˜: {data['total_questions']}ê°œ")
        report.append(f"- ì´ ì±•í„° ìˆ˜: {data['total_chapters']}ê°œ")
        report.append(f"- ì´ ë„ì„œ ìˆ˜: {data['total_books']}ê°œ")
        report.append("")
        
        # ì±•í„°ë³„ ë¬¸ì œ ë¶„í¬ (ìƒìœ„ 10ê°œ)
        chapter_counts = data['chapter_question_counts']
        sorted_chapters = sorted(chapter_counts.items(), key=lambda x: x[1], reverse=True)
        
        report.append("**ì±•í„°ë³„ ë¬¸ì œ ë¶„í¬ (ìƒìœ„ 10ê°œ):**")
        for chapter_name, count in sorted_chapters[:10]:
            report.append(f"- {chapter_name}: {count}ê°œ")
        report.append("")
        
        # ë„ì„œë³„ ì±•í„° ë¶„í¬
        if domain in domain_book_chapters:
            book_chapters = domain_book_chapters[domain]
            report.append("**ë„ì„œë³„ ì±•í„° ë¶„í¬:**")
            for book_title, chapters in sorted(book_chapters.items(), key=lambda x: len(x[1]), reverse=True):
                report.append(f"- **{book_title}**: {len(chapters)}ê°œ ì±•í„°")
                for chapter in sorted(chapters)[:5]:  # ìƒìœ„ 5ê°œ ì±•í„°ë§Œ í‘œì‹œ
                    report.append(f"  - {chapter}")
                if len(chapters) > 5:
                    report.append(f"  - ... ì™¸ {len(chapters) - 5}ê°œ ì±•í„°")
            report.append("")
        
        report.append("---")
        report.append("")
    
    # ë„ë©”ì¸ë³„ ì±•í„° ê³µí†µì„± ë¶„ì„
    report.append("## ë„ë©”ì¸ë³„ ì±•í„° ê³µí†µì„± ë¶„ì„")
    
    # ëª¨ë“  ì±•í„° ìˆ˜ì§‘
    all_chapters = set()
    for data in domain_chapter_analysis.values():
        all_chapters.update(data['chapters'])
    
    # ì±•í„°ë³„ ë„ë©”ì¸ ë¶„í¬
    chapter_domain_mapping = defaultdict(list)
    for domain, data in domain_chapter_analysis.items():
        for chapter in data['chapters']:
            chapter_domain_mapping[chapter].append(domain)
    
    # ì—¬ëŸ¬ ë„ë©”ì¸ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì±•í„°
    common_chapters = {chapter: domains for chapter, domains in chapter_domain_mapping.items() if len(domains) > 1}
    
    if common_chapters:
        report.append("**ì—¬ëŸ¬ ë„ë©”ì¸ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì±•í„°:**")
        for chapter, domains in sorted(common_chapters.items(), key=lambda x: len(x[1]), reverse=True):
            report.append(f"- **{chapter}**: {', '.join(domains)} ({len(domains)}ê°œ ë„ë©”ì¸)")
        report.append("")
    
    # ë„ë©”ì¸ë³„ ê³ ìœ  ì±•í„°
    report.append("**ë„ë©”ì¸ë³„ ê³ ìœ  ì±•í„° (í•´ë‹¹ ë„ë©”ì¸ì—ì„œë§Œ ì‚¬ìš©):**")
    for domain, data in sorted_domains:
        unique_chapters = []
        for chapter in data['chapters']:
            if len(chapter_domain_mapping[chapter]) == 1:
                unique_chapters.append(chapter)
        
        if unique_chapters:
            report.append(f"- **{domain}**: {len(unique_chapters)}ê°œ ê³ ìœ  ì±•í„°")
            for chapter in sorted(unique_chapters)[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                report.append(f"  - {chapter}")
            if len(unique_chapters) > 5:
                report.append(f"  - ... ì™¸ {len(unique_chapters) - 5}ê°œ")
        else:
            report.append(f"- **{domain}**: ê³ ìœ  ì±•í„° ì—†ìŒ (ëª¨ë“  ì±•í„°ê°€ ë‹¤ë¥¸ ë„ë©”ì¸ê³¼ ê³µìœ )")
        report.append("")
    
    # ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥
    report_file = os.path.join(output_dir, "book_domain_chapter_report.md")
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report))
    
    print(f"ğŸ“‹ ë„ë©”ì¸ë³„ ì±•í„° ë¶„ì„ ë¦¬í¬íŠ¸ê°€ '{report_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    
    # multiple_for_grp ë¦¬ìŠ¤íŠ¸ë¥¼ ë¡œë“œ
    print("multiple_for_grp ë¦¬ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
    
    try:
        with open('/Users/jinym/Desktop/Desktop_AICenterâœ¨/SFAIcenter/multiple.json', 'r', encoding='utf-8') as f:
            multiple_for_grp = json.load(f)
        print(f"âœ… {len(multiple_for_grp)}ê°œ ë¬¸ì œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    except FileNotFoundError:
        print("âŒ multiple.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("multiple_for_grp ë¦¬ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ì œê³µí•´ì£¼ì„¸ìš”.")
        return
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return
    
    # ë„ë©”ì¸ê³¼ ì±•í„°ë³„ë¡œ ë¶„ë¥˜
    domain_chapter_data = classify_questions_by_domain_chapter(multiple_for_grp)
    
    # ë„ë©”ì¸ë³„ ì±•í„° ë¶„ì„
    domain_chapter_analysis, domain_book_chapters = analyze_domain_chapters(domain_chapter_data)
    
    # ë¶„ë¥˜ëœ ë¬¸ì œë“¤ì„ íŒŒì¼ë¡œ ì €ì¥
    domain_summary = save_domain_classified_questions(domain_chapter_data)
    
    # ë„ë©”ì¸ë³„ ì±•í„° ë¶„ì„ ê²°ê³¼ ì €ì¥
    analysis_file = save_domain_chapter_analysis(domain_chapter_analysis, domain_book_chapters)
    
    # ë„ë©”ì¸ë³„ ì±•í„° ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
    create_domain_chapter_report(domain_chapter_analysis, domain_book_chapters)
    
    print(f"\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ğŸ“ ê²°ê³¼ íŒŒì¼ë“¤: domain_chapter_classified/ ë””ë ‰í† ë¦¬")
    print(f"ğŸ“Š ë„ë©”ì¸ë³„ ì±•í„° ë¶„ì„: domain_chapter_analysis.json")
    print(f"ğŸ“‹ ë„ë©”ì¸ë³„ ì±•í„° ë¦¬í¬íŠ¸: domain_chapter_report.md")

if __name__ == "__main__":
    main()
