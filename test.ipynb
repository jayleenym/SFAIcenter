{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/hhhhh.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# 새로운거 빈 도메인만..\n",
    "\n",
    "!python hhhhh.py multiple-fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple options 오류들\n",
    "- find_multiple_choice_invalid_options.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원본에 옮기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, time\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# file_list = []\n",
    "\n",
    "# for t in tqdm(to_multiple):\n",
    "#     file_id = t.get('file_id')\n",
    "#     file_list.append(file_id)\n",
    "#     # print(file_id)\n",
    "#     tag = t.get('tag')\n",
    "#     time.sleep(0.5)\n",
    "        \n",
    "#     file_path = os.popen(f\"find /Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/data/FINAL -type f -name '{file_id}_v2.json'\").read().strip()\n",
    "#     if file_path == \"\":\n",
    "#         file_path = os.popen(f\"find /Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/data/FINAL -type f -name '{file_id}.json'\").read().strip()\n",
    "#     # print(file_path)\n",
    "\n",
    "#     with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "    \n",
    "#     contents = data['contents']\n",
    "\n",
    "#     for d in contents:\n",
    "#         if d.get('page') == tag.split('_')[1]:\n",
    "#             add_info = d.get('add_info')\n",
    "#             for info in add_info:\n",
    "#                 if info.get('tag') == tag:\n",
    "#                     if info.get('description').get('question') == t.get('question'):\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         # print(\"질문 다름\")\n",
    "#                         info['description']['question'] = t.get('question')\n",
    "\n",
    "#                     if info.get('description').get('answer') == t.get('answer'):\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         # print(\"답 다름\")\n",
    "#                         info['description']['answer'] = t.get('answer')\n",
    "#                     if info.get('description').get('options') == t.get('options'):\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         # print(\"옵션 다름\")\n",
    "#                         info['description']['options'] = t.get('options')\n",
    "#     if file_path.endswith(\"_v2.json\"):\n",
    "#         with open(file_path, 'w', encoding='utf-8') as f:\n",
    "#             json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "#     else:\n",
    "#         with open(file_path.replace(\".json\", \"_v2.json\"), 'w', encoding='utf-8') as f:\n",
    "#             json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(list(set(file_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from tools.qna.processing.qna_subdomain_classifier import QnASubdomainClassifier\n",
    "from tools.pipeline.config import ONEDRIVE_PATH\n",
    "\n",
    "# file_name = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json')\n",
    "file_name = os.path.join(ONEDRIVE_PATH, 'evaluation', 'eval_data', '2_subdomain', 'multiple_subdomain_classified_ALL.json')\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    multiple = json.load(f)\n",
    "\n",
    "classifier = QnASubdomainClassifier()\n",
    "classifier.save_statistics(multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도메인별 통계 계산\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "calculation = defaultdict(int)  # 계산 문제 개수\n",
    "total_by_domain = defaultdict(int)  # 전체 문제 개수\n",
    "\n",
    "for question in fifth_exam:\n",
    "    domain = question.get('domain', '미분류')\n",
    "    total_by_domain[domain] += 1\n",
    "    if question.get('is_calculation') == True:\n",
    "        calculation[domain] += 1\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=\" * 60)\n",
    "print(\"도메인별 통계\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'도메인':<20} {'전체':<10} {'계산문제':<10} {'비율':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for domain in sorted(total_by_domain.keys()):\n",
    "    total = total_by_domain[domain]\n",
    "    calc_count = calculation[domain]\n",
    "    ratio = (calc_count / total * 100) if total > 0 else 0\n",
    "    print(f\"{domain:<20} {total:<10} {calc_count:<10} {ratio:.2f}%\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'합계':<20} {sum(total_by_domain.values()):<10} {sum(calculation.values()):<10} {sum(calculation.values())/sum(total_by_domain.values())*100:.2f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python tools/main_pipeline.py --steps evaluate_exams --eval_sets 5 --eval_models google/gemini-2.5-pro openai/gpt-5 anthropic/claude-sonnet-4.5 google/gemini-2.5-flash anthropic/claude-3.7-sonnet openai/gpt-4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation 파일 수정하고 다시 돌리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "from tools.pipeline.config import ONEDRIVE_PATH\n",
    "\n",
    "EXAM_DIR = os.path.join(ONEDRIVE_PATH, 'evaluation','eval_data','4_multiple_exam')\n",
    "# EXAM_DIR = os.path.join(os.path.expanduser(\"~\"), '4_multiple_exam')\n",
    "\n",
    "for exams in os.listdir(EXAM_DIR):\n",
    "    # if exams == \"1st\":\n",
    "    #     first_exam = []\n",
    "    #     for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "    #         with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "    #             first_exam += json.load(f)\n",
    "    # elif exams == \"2nd\":\n",
    "    #     second_exam = []\n",
    "    #     for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "    #         with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "    #             second_exam += json.load(f)\n",
    "    # elif exams == \"3rd\":\n",
    "    #     third_exam = []\n",
    "    #     for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "    #         with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "    #             third_exam += json.load(f)\n",
    "    # elif exams == \"4th\":\n",
    "    #     fourth_exam = []\n",
    "    #     for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "    #         with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "    #             fourth_exam += json.load(f)\n",
    "    if exams == \"5th\":\n",
    "        fifth_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "            with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "                fifth_exam += json.load(f)\n",
    "\n",
    "# multiple = first_exam + second_exam + third_exam + fourth_exam + fifth_exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jinym/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/evaluation/eval_data/6_exam_evaluation/5th/5th_evaluation_many.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tools.pipeline.config import ONEDRIVE_PATH\n",
    "\n",
    "model_name = 'many'\n",
    "excel_path = os.path.join(ONEDRIVE_PATH, f'evaluation/eval_data/6_exam_evaluation/5th/5th_evaluation_{model_name}.xlsx')\n",
    "print(excel_path)\n",
    "pred_wide = pd.read_excel(excel_path, sheet_name='모델별예측')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "empty_ids = pred_wide[pred_wide['google/gemini-2.5-pro'].isna()].id.tolist()\n",
    "# print(pred_wide.columns[-1])\n",
    "print(empty_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_json = []\n",
    "for q in empty_ids:\n",
    "    for m in fifth_exam:\n",
    "        if m['file_id']+\"_\"+m['tag'] == q:\n",
    "            # print(m)\n",
    "            new_json.append(m)\n",
    "\n",
    "print(len(new_json) == len(empty_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(os.path.join(ONEDRIVE_PATH, 'evaluation/model_new.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(new_json, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Excel 파일 업데이트 완료: /Users/jinym/Library/CloudStorage/OneDrive-개인/데이터L/selectstar/evaluation/eval_data/6_exam_evaluation/5th/5th_evaluation_many.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Excel 파일에서 정확도 계산 (전체, subject별, domain별, subdomain별)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Set\n",
    "import ast\n",
    "\n",
    "# Excel 파일 경로 설정\n",
    "# excel_path = f'/Users/yejin/Downloads/2nd_evaluation_ALL.xlsx'\n",
    "\n",
    "# Excel 파일 읽기\n",
    "df_sample = pd.read_excel(excel_path, sheet_name='전체데이터')\n",
    "pred_wide = pd.read_excel(excel_path, sheet_name='모델별예측')\n",
    "\n",
    "# pred_wide를 pred_long 형식으로 변환 (melt 사용)\n",
    "# pred_wide는 id 컬럼과 각 모델명이 컬럼으로 있는 와이드 포맷\n",
    "# pred_long은 id, model_name, answer 컬럼이 있는 롱 포맷\n",
    "pred_long = pred_wide.melt(\n",
    "    id_vars=['id'],  # id 컬럼은 그대로 유지\n",
    "    var_name='model_name',  # 모델명 컬럼 이름\n",
    "    value_name='answer'  # 예측값 컬럼 이름\n",
    ")\n",
    "\n",
    "# answer_set을 Set[int]로 변환하는 헬퍼 함수\n",
    "def _parse_answer_set(answer_set):\n",
    "    if isinstance(answer_set, set):\n",
    "        return answer_set\n",
    "    elif isinstance(answer_set, str):\n",
    "        try:\n",
    "            # 문자열을 파싱해서 Set[int]로 변환\n",
    "            parsed = ast.literal_eval(answer_set)\n",
    "            if isinstance(parsed, set):\n",
    "                return parsed\n",
    "            elif isinstance(parsed, (list, tuple)):\n",
    "                return set(parsed)\n",
    "            else:\n",
    "                return {int(parsed)}\n",
    "        except:\n",
    "            # 파싱 실패 시 빈 집합 반환\n",
    "            return set()\n",
    "    else:\n",
    "        # 숫자나 다른 타입인 경우\n",
    "        try:\n",
    "            return {int(answer_set)}\n",
    "        except:\n",
    "            return set()\n",
    "\n",
    "# 정답 여부 계산 함수\n",
    "def _is_correct(pred: float, s: Set[int]) -> float:\n",
    "    if np.isnan(pred) or not s:\n",
    "        return np.nan\n",
    "    return float(int(pred) in s)\n",
    "\n",
    "# 데이터 병합 및 정확도 계산\n",
    "key = df_sample[[\"id\", \"answer_set\"]].copy()\n",
    "merged = pred_long.merge(key, on=\"id\", how=\"left\")\n",
    "merged[\"answer_set\"] = merged[\"answer_set\"].apply(_parse_answer_set)\n",
    "merged[\"correct\"] = merged.apply(lambda r: _is_correct(r[\"answer\"], r[\"answer_set\"]), axis=1)\n",
    "\n",
    "# 전체 정확도 계산\n",
    "acc_by_model = (\n",
    "    merged.groupby(\"model_name\", dropna=False)[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"correct\": \"accuracy\"})\n",
    "    .sort_values(\"accuracy\", ascending=False)\n",
    ")\n",
    "\n",
    "# Excel 파일에 결과 저장\n",
    "# 기존 파일을 읽어서 모든 시트를 유지하면서 특정 시트만 업데이트\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# 기존 파일의 모든 시트 읽기 (업데이트할 시트 제외)\n",
    "existing_sheets = {}\n",
    "try:\n",
    "    book = load_workbook(excel_path)\n",
    "    for sheet_name in book.sheetnames:\n",
    "        if sheet_name not in [\"전체데이터\", \"모델별예측\", \"정확도\", \"Subject별정확도\", \"Subject별문제수\", \n",
    "                              \"Domain별정확도\", \"Domain별문제수\", \"Subdomain별정확도\", \"Subdomain별문제수\"]:\n",
    "            # 업데이트할 시트가 아닌 경우 기존 데이터 읽기\n",
    "            existing_sheets[sheet_name] = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# 모든 시트를 새 파일로 저장\n",
    "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode='w') as writer:\n",
    "    # 기존 시트 유지\n",
    "    for sheet_name, df in existing_sheets.items():\n",
    "        df.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "    # 기본 시트들 업데이트\n",
    "    df_sample.to_excel(writer, index=False, sheet_name=\"전체데이터\")\n",
    "    pred_wide.to_excel(writer, index=False, sheet_name=\"모델별예측\")\n",
    "    acc_by_model.to_excel(writer, index=False, sheet_name=\"정확도\")\n",
    "    \n",
    "    # subject별 정확도 계산 및 저장 (subject 컬럼이 있는 경우)\n",
    "    if 'subject' in df_sample.columns:\n",
    "        subject_info = df_sample[[\"id\", \"subject\"]].copy()\n",
    "        merged_with_subject = merged.merge(subject_info, on=\"id\", how=\"left\")\n",
    "        \n",
    "        subject_acc = (\n",
    "            merged_with_subject.groupby([\"subject\", \"model_name\"], dropna=False)[\"correct\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .pivot(index=\"subject\", columns=\"model_name\", values=\"correct\")\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "        subject_acc.to_excel(writer, index=False, sheet_name=\"Subject별정확도\")\n",
    "        \n",
    "        # Subject별 문제 수 통계\n",
    "        subject_stats = df_sample.groupby('subject').size().reset_index(name='question_count')\n",
    "        subject_stats.to_excel(writer, index=False, sheet_name=\"Subject별문제수\")\n",
    "    \n",
    "    # domain별 정확도 계산 및 저장 (domain 컬럼이 있는 경우)\n",
    "    if 'domain' in df_sample.columns:\n",
    "        domain_info = df_sample[[\"id\", \"domain\"]].copy()\n",
    "        merged_with_domain = merged.merge(domain_info, on=\"id\", how=\"left\")\n",
    "        \n",
    "        domain_acc = (\n",
    "            merged_with_domain.groupby([\"domain\", \"model_name\"], dropna=False)[\"correct\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .pivot(index=\"domain\", columns=\"model_name\", values=\"correct\")\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "        domain_acc.to_excel(writer, index=False, sheet_name=\"Domain별정확도\")\n",
    "        \n",
    "        # Domain별 문제 수 통계\n",
    "        domain_stats = df_sample.groupby('domain').size().reset_index(name='question_count')\n",
    "        domain_stats.to_excel(writer, index=False, sheet_name=\"Domain별문제수\")\n",
    "    \n",
    "    # subdomain별 정확도 계산 및 저장 (subdomain 컬럼이 있는 경우)\n",
    "    if 'subdomain' in df_sample.columns:\n",
    "        subdomain_info = df_sample[[\"id\", \"domain\", \"subdomain\"]].copy()\n",
    "        merged_with_subdomain = merged.merge(subdomain_info, on=\"id\", how=\"left\")\n",
    "        \n",
    "        subdomain_acc = (\n",
    "            merged_with_subdomain.groupby([\"domain\", \"subdomain\", \"model_name\"], dropna=False)[\"correct\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .pivot(index=[\"domain\", \"subdomain\"], columns=\"model_name\", values=\"correct\")\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "        subdomain_acc.to_excel(writer, index=False, sheet_name=\"Subdomain별정확도\")\n",
    "        \n",
    "        # Subdomain별 문제 수 통계\n",
    "        subdomain_stats = df_sample.groupby(['domain', 'subdomain']).size().reset_index(name='question_count')\n",
    "        subdomain_stats.to_excel(writer, index=False, sheet_name=\"Subdomain별문제수\")\n",
    "\n",
    "print(f\"✅ Excel 파일 업데이트 완료: {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
