{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple subdomain 결과 재정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# domain = '경제'\n",
    "# with open(f'evaluation/eval_data/multiple_subdomain_results/{domain}_subdomain_classified.json', 'r', encoding='utf-8') as f:\n",
    "    # data = json.load(f)\n",
    "\n",
    "#  new_data = []\n",
    "# for d in data:\n",
    "#     if d['qna_subdomain_reason'] in d['qna_reason']:\n",
    "#         d['qna_reason'] = d['qna_reason'].replace(d['qna_subdomain_reason'], '').strip()\n",
    "#         # print(d)\n",
    "#     new_d = {\n",
    "#         'file_id': d['file_id'],\n",
    "#         'title': d['title'],\n",
    "#         'chapter': d['chapter'],\n",
    "#         'tag': d['tag'],\n",
    "#         'domain': d['domain'],\n",
    "#         'subdomain': d['subdomain'],\n",
    "#         'domain_reason': d['domain_reason'],\n",
    "#         'subdomain_reason': d['subdomain_reason'],\n",
    "#         'question': d['question'],\n",
    "#         'options': d['options'],\n",
    "#         'answer': d['qna_answer'],\n",
    "#         'explanation': d['explanation']\n",
    "#     }\n",
    "#     new_data.append(new_d)\n",
    "    \n",
    "# with open(f'evaluation/eval_data/subdomain_results_old/{domain}_subdomain_classified.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(new_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모의고사 만들기 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, json, random\n",
    "# from datetime import datetime\n",
    "\n",
    "# random.seed(42)\n",
    "\n",
    "# # 과목 분류\n",
    "# BBASE_DIR = '/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data'\n",
    "# with open(os.path.join(BBASE_DIR, 'exam_hierarchy.json'), 'r', encoding='utf-8') as f:\n",
    "#     subjects = json.load(f)\n",
    "\n",
    "# # subdomain 분류 완료된 데이터 > 모의고사 대상 문제주머니 추출\n",
    "# BASE_DIR = '/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple_with_subdomain'\n",
    "\n",
    "# with open(os.path.join(BASE_DIR, 'classification_statistics.json'), 'r', encoding='utf-8') as f:\n",
    "#     stats = json.load(f)\n",
    "\n",
    "# # 로그 파일 설정\n",
    "# log_output = []\n",
    "# # timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "# log_file = f'/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/logs/mock_exam_pipeline.log'\n",
    "\n",
    "# for json_file in os.listdir(BASE_DIR):\n",
    "#     if not json_file.endswith(\"_subdomain_classified.json\"):\n",
    "#         continue\n",
    "    \n",
    "#     with open(os.path.join(BASE_DIR, json_file), 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "    \n",
    "#     domain = json_file.replace(\"_subdomain_classified.json\", \"\")\n",
    "#     log_message = f\"=====================================\\n<<< {domain} 분야 모의고사용 문제 추출 >>>\"\n",
    "#     print(log_message)\n",
    "#     log_output.append(log_message)\n",
    "    \n",
    "#     total_questions = len(data)\n",
    "#     if total_questions == stats[domain]['total_questions']:\n",
    "#         mock_data = []\n",
    "#         need_more = {}\n",
    "#         mock_total_questions = round(total_questions)\n",
    "        \n",
    "#         log_message1 = f\"원본 문제 수: {total_questions}\"\n",
    "#         log_message2 = f\"추출 대상 문제 수: {mock_total_questions}\"\n",
    "#         print(log_message1)\n",
    "#         print(log_message2)\n",
    "#         log_output.extend([log_message1, log_message2])\n",
    "\n",
    "#         # subdomain 별로 모의고사 만들기\n",
    "#         for subdomain in stats[domain]['subdomain_distribution'].keys():\n",
    "#             subdomain_data = [d for d in data if d['subdomain'] == subdomain]\n",
    "#             random.shuffle(subdomain_data)\n",
    "#             try:\n",
    "#                 mock_subdomain_data = random.sample(subdomain_data, mock_total_questions // len(stats[domain]['subdomain_distribution']))\n",
    "#             except ValueError:\n",
    "#                 mock_subdomain_data = subdomain_data\n",
    "#                 need_more[subdomain] = mock_total_questions // len(stats[domain]['subdomain_distribution']) - len(mock_subdomain_data)\n",
    "            \n",
    "#             log_message = f\"  - {subdomain}: {len(mock_subdomain_data)}\"\n",
    "#             print(log_message)\n",
    "#             log_output.append(log_message)\n",
    "#             mock_data.extend(mock_subdomain_data)\n",
    "\n",
    "#         log_message1 = f\" ====> 총 추출 문제: {len(mock_data)}\"\n",
    "#         print(log_message1)\n",
    "#         log_output.append(log_message1)\n",
    "        \n",
    "#         if need_more:\n",
    "#             log_message2 = f\" ====> 모자란 문제: {need_more}\"\n",
    "#             print(log_message2)\n",
    "#             log_output.append(log_message2)\n",
    "#     else:\n",
    "#         log_message = \"갯수가 안맞아!\"\n",
    "#         print(log_message)\n",
    "#         log_output.append(log_message)\n",
    "    \n",
    "#     # 문제주머니 저장\n",
    "#     for domains in subjects.values():\n",
    "#         if domain in domains:\n",
    "#             subject = list(subjects.keys())[list(subjects.values()).index(domains)]\n",
    "    \n",
    "#     OUTPUT_DIR = f\"{BBASE_DIR}/3_multiple_mock/{subject}\"\n",
    "\n",
    "#     os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "#     with open(f'{OUTPUT_DIR}/{domain}_mock_data.json', 'w', encoding='utf-8') as f:\n",
    "#         json.dump(mock_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# # 로그 파일 저장\n",
    "# os.makedirs('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/logs', exist_ok=True)\n",
    "# with open(log_file, 'a', encoding='utf-8') as f:\n",
    "#     f.write('\\n'.join(log_output))\n",
    "\n",
    "# print(f\"\\n로그가 저장되었습니다: {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수정한 도메인 원본에 반영하기?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, json\n",
    "\n",
    "# MULTIPLE_EVAL_DIR = '/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_bronze_layer_subdomain/multiple_with_subdomain'\n",
    "# EXTRACTED_DIR = '/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/workbook_data'\n",
    "\n",
    "# for json_file in os.listdir(MULTIPLE_EVAL_DIR):\n",
    "#     if not json_file.endswith(\"_subdomain_classified.json\"):\n",
    "#         continue\n",
    "    \n",
    "#     with open(os.path.join(MULTIPLE_EVAL_DIR, json_file), 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "    \n",
    "#     for d in data:\n",
    "#         # print(d)\n",
    "#         file_path = os.popen(f\"find {EXTRACTED_DIR} -type f -name '{d['file_id']}_extracted_qna.json'\").read().strip()\n",
    "#         with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#             extracted_data = json.load(f)\n",
    "\n",
    "\n",
    "#         for extracted_d in extracted_data:\n",
    "#             print(extracted_d)\n",
    "#             break\n",
    "#         # for extracted_d in extracted_data:\n",
    "#         #     if extracted_d['id'] == d['file_id']:\n",
    "#         #         print(extracted_d)\n",
    "#         break\n",
    "        \n",
    "#     break\n",
    "    \n",
    "#     new_data = []\n",
    "#     other_domain = {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_d = extracted_data[0]\n",
    "extracted_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 조정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, json\n",
    "\n",
    "# BASE_DIR = '/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/multiple_with_subdomain'\n",
    "\n",
    "# for json_file in os.listdir(BASE_DIR):\n",
    "#     if not json_file.endswith(\"_subdomain_classified.json\"):\n",
    "#         continue\n",
    "    \n",
    "#     with open(os.path.join(BASE_DIR, json_file), 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "    \n",
    "#     domain = json_file.replace(\"_subdomain_classified.json\", \"\")\n",
    "    \n",
    "#     new_data = []\n",
    "#     other_domain = {}\n",
    "#     for d in data:\n",
    "#         if d['qna_domain'] != domain:\n",
    "#             other_domain[d['qna_domain']] = d\n",
    "#         else:\n",
    "#             new_data.append(d)\n",
    "    \n",
    "#     with open(os.path.join(BASE_DIR, f'{domain}_subdomain_classified.json'), 'w', encoding='utf-8') as f:\n",
    "#         json.dump(new_data, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "#     for other_domain_key in other_domain.keys():\n",
    "#         with open(os.path.join(BASE_DIR, f'{other_domain_key}_subdomain_classified.json'), 'r', encoding='utf-8') as f:\n",
    "#             other_domain_data = json.load(f)\n",
    "        \n",
    "#         other_domain_data.append(other_domain[other_domain_key])\n",
    "                \n",
    "#         with open(os.path.join(BASE_DIR, f'{other_domain_key}_subdomain_classified.json'), 'w', encoding='utf-8') as f:\n",
    "#             json.dump(other_domain_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mock 데이터에서 모의고사 문제 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "from datetime import datetime\n",
    "\n",
    "BASE_DIR = '/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data'\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, '2_subdomain')\n",
    "MOCK_DIR = os.path.join(BASE_DIR, '3_multiple_mock')\n",
    "EXAM_DIR = os.path.join(BASE_DIR, '4_multiple_exam')\n",
    "\n",
    "mock_exam_name = {\n",
    "    1 : '1st',\n",
    "    2 : '2nd',\n",
    "    3 : '3rd'\n",
    "}\n",
    "\n",
    "\n",
    "with open(os.path.join(BASE_DIR, 'exam_statistics.json'), 'r', encoding='utf-8') as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "# 로그 파일 설정\n",
    "log_output = []\n",
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "log_file = f'/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/logs/mock_exam_extraction.log'\n",
    "\n",
    "for subject in os.listdir(BASE_DIR):\n",
    "    if subject.endswith(\".json\"):\n",
    "        continue\n",
    "    \n",
    "    log_message = f\"=====================================\\n {subject}\"\n",
    "    print(log_message)\n",
    "    log_output.append(log_message)\n",
    "    \n",
    "    # 3세트를 위한 리스트 초기화\n",
    "    mock_exam_data = [[], [], []]\n",
    "    exam_questions = 250\n",
    "    for json_file in os.listdir(os.path.join(BASE_DIR, subject)):\n",
    "        if not json_file.endswith(\"_mock_data.json\"):\n",
    "            continue\n",
    "        \n",
    "        with open(os.path.join(BASE_DIR, subject, json_file), 'r', encoding='utf-8') as f:\n",
    "            json_file = json.load(f)\n",
    "        \n",
    "        domain = os.path.basename(f.name).replace(\"_mock_data.json\", \"\")\n",
    "        if (domain == '디지털') or (domain == '통계'):\n",
    "            continue\n",
    "        log_message = f\"-------------------------------------\\n {domain}\"\n",
    "        print(log_message)\n",
    "        log_output.append(log_message)\n",
    "    \n",
    "        # subdomain 별로 모의고사 만들기 - 3세트용\n",
    "        for subdomain in stats[subject][domain]['exam_subdomain_distribution'].keys():\n",
    "            subdomain_data = [d for d in json_file if d['qna_subdomain'] == subdomain]\n",
    "            random.shuffle(subdomain_data)\n",
    "            \n",
    "            needed_count = stats[subject][domain]['exam_subdomain_distribution'][subdomain]\n",
    "            \n",
    "            try:\n",
    "                # 1세트 샘플링\n",
    "                sample1 = random.sample(subdomain_data, needed_count)\n",
    "                remaining_data = [d for d in subdomain_data if d not in sample1]\n",
    "                \n",
    "                # 2세트 샘플링 (1세트 제외한 데이터에서)\n",
    "                sample2 = random.sample(remaining_data, needed_count)\n",
    "                remaining_data = [d for d in remaining_data if d not in sample2]\n",
    "                \n",
    "                # 3세트 샘플링 (1, 2세트 제외한 데이터에서)\n",
    "                sample3 = random.sample(remaining_data, needed_count)\n",
    "                \n",
    "                log_message = f\" - {subdomain}: {needed_count} x 3세트 (총 {len(subdomain_data)}개 중 {needed_count * 3}개 사용)\"\n",
    "                print(log_message)\n",
    "                log_output.append(log_message)\n",
    "                \n",
    "                # 각 세트에 추가\n",
    "                mock_exam_data[0].extend(sample1)\n",
    "                mock_exam_data[1].extend(sample2)\n",
    "                mock_exam_data[2].extend(sample3)\n",
    "                \n",
    "            except ValueError:\n",
    "                # 데이터가 부족한 경우\n",
    "                total_available = len(subdomain_data)\n",
    "                # per_set = total_available // 3\n",
    "                sample1 = subdomain_data[:needed_count]\n",
    "                sample2 = subdomain_data[needed_count:needed_count*2]\n",
    "                sample3 = subdomain_data[needed_count*2:]\n",
    "                \n",
    "                log_message = f\" - (ERROR) {subdomain}: {total_available}/{needed_count*3} (데이터 부족: {needed_count*3 - total_available}개 필요)\"\n",
    "                print(log_message)\n",
    "                log_output.append(log_message)\n",
    "                \n",
    "                mock_exam_data[0].extend(sample1)\n",
    "                mock_exam_data[1].extend(sample2)\n",
    "                mock_exam_data[2].extend(sample3)\n",
    "    \n",
    "    # 3개 파일로 저장\n",
    "    for set_num in range(3):\n",
    "        log_message = f\" ====> {set_num+1}세트: {len(mock_exam_data[set_num])}/{exam_questions} ({len(mock_exam_data[set_num])/exam_questions:.2%})\"\n",
    "        print(log_message)\n",
    "        log_output.append(log_message)\n",
    "        # 출력 디렉토리 생성\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR, mock_exam_name[set_num+1]), exist_ok=True)\n",
    "        with open(f'{OUTPUT_DIR}/{mock_exam_name[set_num+1]}/{subject}_mock_exam.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(mock_exam_data[set_num], f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 로그 파일 저장\n",
    "os.makedirs('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/logs', exist_ok=True)\n",
    "with open(log_file, 'a', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(log_output))\n",
    "\n",
    "print(f\"\\n로그가 저장되었습니다: {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple options 오류들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# with open(os.path.join(BBASE_DIR, 'exam_statistics.json'), 'r', encoding='utf-8') as f:\n",
    "    # stats = json.load(f)\n",
    "\n",
    "# for subject in stats.keys():\n",
    "    # print(\"================\\n\", subject)\n",
    "    # with open(f'evaluation/eval_data/mock_exam/1st/{subject}_mock_exam.json', 'r', encoding='utf-8') as f:\n",
    "        # data = json.load(f)\n",
    "\n",
    "# file_name = '/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/1_filter/multiple.json'\n",
    "file_name = '/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json'\n",
    "\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "if True:\n",
    "    # ①②③④⑤로 시작하지 않는 경우를 찾기\n",
    "    invalid_options = []\n",
    "\n",
    "    for d in data:\n",
    "        if d['options'] and isinstance(d['options'], list):\n",
    "            options = d['options']\n",
    "            \n",
    "            # 각 옵션을 확인\n",
    "            for i, option in enumerate(options):\n",
    "                # ①②③④⑤로 시작하지 않는 경우 찾기\n",
    "                if not re.match(r'^[①②③④⑤]', option.strip()):\n",
    "                    invalid_options.append({\n",
    "                        'file_id': d['file_id'],\n",
    "                        'domain': d['domain'],\n",
    "                        'subdomain': d['subdomain'],\n",
    "                        'tag': d['tag'],\n",
    "                        'option_index': i,\n",
    "                        'original_option': option,\n",
    "                        # 'first_char': option.strip()[0] if option.strip() else ''\n",
    "                    })\n",
    "\n",
    "    print(f\"①②③④⑤로 시작하지 않는 options 수: {len(invalid_options)}\")\n",
    "    invalid_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## short/essay인 객관식 조정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/essay_subdomain_classified_ALL.json', 'r', encoding='utf-8') as f:\n",
    "    essay = json.load(f)\n",
    "\n",
    "with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/short_subdomain_classified_ALL.json', 'r', encoding='utf-8') as f:\n",
    "    short = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_multiple = []\n",
    "\n",
    "# for e in essay:\n",
    "#     if isinstance(e['options'], list):\n",
    "#         to_multiple.append(e)\n",
    "# print(len(to_multiple))\n",
    "\n",
    "new_short = []\n",
    "for s in short:\n",
    "    if isinstance(s['options'], list):\n",
    "        to_multiple.append(s)\n",
    "    else:\n",
    "        new_short.append(s)\n",
    "print(len(to_multiple), len(short), len(new_short))\n",
    "# to_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/short_subdomain_classified_ALL.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(new_short, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple_shortans_classified_ALL.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(to_multiple, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원본에 옮기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for t in tqdm(to_multiple):\n",
    "    file_id = t.get('file_id')\n",
    "    file_list.append(file_id)\n",
    "    # print(file_id)\n",
    "    tag = t.get('tag')\n",
    "    time.sleep(0.5)\n",
    "        \n",
    "    file_path = os.popen(f\"find /Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/data/FINAL -type f -name '{file_id}_v2.json'\").read().strip()\n",
    "    if file_path == \"\":\n",
    "        file_path = os.popen(f\"find /Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/data/FINAL -type f -name '{file_id}.json'\").read().strip()\n",
    "    # print(file_path)\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    contents = data['contents']\n",
    "\n",
    "    for d in contents:\n",
    "        if d.get('page') == tag.split('_')[1]:\n",
    "            add_info = d.get('add_info')\n",
    "            for info in add_info:\n",
    "                if info.get('tag') == tag:\n",
    "                    if info.get('description').get('question') == t.get('question'):\n",
    "                        pass\n",
    "                    else:\n",
    "                        # print(\"질문 다름\")\n",
    "                        info['description']['question'] = t.get('question')\n",
    "\n",
    "                    if info.get('description').get('answer') == t.get('answer'):\n",
    "                        pass\n",
    "                    else:\n",
    "                        # print(\"답 다름\")\n",
    "                        info['description']['answer'] = t.get('answer')\n",
    "                    if info.get('description').get('options') == t.get('options'):\n",
    "                        pass\n",
    "                    else:\n",
    "                        # print(\"옵션 다름\")\n",
    "                        info['description']['options'] = t.get('options')\n",
    "    if file_path.endswith(\"_v2.json\"):\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "    else:\n",
    "        with open(file_path.replace(\".json\", \"_v2.json\"), 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(list(set(file_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiple 실패한거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, json\n",
    "\n",
    "# with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json', 'r', encoding='utf-8') as f:\n",
    "#     multiple = json.load(f)\n",
    "\n",
    "# # with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple-fail_response.json', 'r', encoding='utf-8') as f:\n",
    "# #     multiple_fail = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in multiple:\n",
    "#     # print(q)\n",
    "#     if q['domain'] == '분류실패':\n",
    "#         for m in multiple_fail:\n",
    "#             if (m['file_id'] == q['file_id']) and (m['tag'] == q['tag']):\n",
    "#                 q['domain'] = m['domain']\n",
    "#                 q['subdomain'] = m['subdomain']\n",
    "#                 q['classification_reason'] = m['classification_reason']\n",
    "#                 q['is_calculation'] = m['is_calculation']\n",
    "#                 # break\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(multiple, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple-fail_response_fail_again.json', 'r', encoding='utf-8') as f:\n",
    "#     multiple_fail_again = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in multiple:\n",
    "#     if q['domain'] == '':\n",
    "#         for m in multiple_fail_again:\n",
    "#             file_id = m['qna_id'].split('_')[0]\n",
    "#             tag = m['qna_id'].replace(file_id+'_', '')\n",
    "#             if (file_id == q['file_id']) and (tag == q['tag']):\n",
    "#                 q['domain'] = m['domain']\n",
    "#                 q['subdomain'] = m['subdomain']\n",
    "#                 q['classification_reason'] = m['reason']\n",
    "#                 q['is_calculation'] = m['is_calculation']\n",
    "#                 # print(q)\n",
    "#                 # break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from tools.evaluation import qna_subdomain_classifier\n",
    "\n",
    "\n",
    "with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json', 'r', encoding='utf-8') as f:\n",
    "    multiple = json.load(f)\n",
    "\n",
    "classifier = qna_subdomain_classifier.QnASubdomainClassifier()\n",
    "classifier.save_statistics(multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in multiple:\n",
    "    if m['subdomain'].count('-') >= 1:\n",
    "        # print(m)\n",
    "        # break\n",
    "        m['subdomain'] = m['subdomain'].split('-')[0].strip()\n",
    "        # print(m)\n",
    "        # break\n",
    "    elif m['subdomain'].count('.') >= 1:\n",
    "        m['subdomain'] = m['subdomain'].split('.')[1].strip()\n",
    "        \n",
    "\n",
    "classifier.save_statistics(multiple)\n",
    "    # print(\"없는데?\", m['subdomain'])\n",
    "\n",
    "with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(multiple, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json', 'r', encoding='utf-8') as f:\n",
    "    multiple = json.load(f)\n",
    "\n",
    "for m in multiple:\n",
    "    m['domain'] = \"\"\n",
    "    m['subdomain'] = \"\"\n",
    "    m['classification_reason'] = \"\"\n",
    "    m['is_calculation'] = False\n",
    "\n",
    "with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(multiple, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 객관식 문제 변형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple.json', 'r', encoding='utf-8') as f:\n",
    "    multiple = json.load(f)\n",
    "\n",
    "pick_right = []\n",
    "pick_wrong = []\n",
    "pick_abcd = []\n",
    "\n",
    "len(multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 리스트를 순회하면서 remove()를 하면 인덱스가 꼬이므로, 새로 분류하는 방식으로 변경\n",
    "remaining = []\n",
    "for m in multiple:\n",
    "    question = m['question']\n",
    "    \n",
    "    # 3. ㄱ/ㄴ/ㄷ/ㄹ 등에서 옳은 것을 모두 고르는 문제 (다중 선택)\n",
    "    # 종결어미 '다.' 제외: 줄바꿈, 문장 시작, 또는 공백 후에 나오고 뒤에 공백이 아닌 문자가 오는 경우만 매칭\n",
    "    # 가나다라마바사아자차카타파하까지 포함 (바, 사, 아 등도 포함)\n",
    "    if ('옳은 것을 모두 고른 것은?' in question) or \\\n",
    "         ('옳은 것을 모두 고르면?' in question) or \\\n",
    "         ('옳은 것을 모두 고른 것은' in question) or \\\n",
    "         ('옳은 것을 모두' in question and '?' in question) or \\\n",
    "         ('모두 고른 것은?' in question) or \\\n",
    "         ('모두 고르면?' in question) or \\\n",
    "         ('모두 고른 것은' in question) or \\\n",
    "         ('모두 묶인 것은?' in question) or \\\n",
    "         (re.search(r'[ㄱㄴㄷㄹ][\\.]', question) and ('모두 고른' in question or '모두 묶인' in question)) or \\\n",
    "         (re.search(r'(?:^|\\n| )[가나다라마바사아자차카타파하]\\.(?!\\s|$)', question) and ('모두 고른' in question or '모두 묶인' in question)) or \\\n",
    "         (re.search(r'[㉠㉡㉢㉣㉤]', question) and ('모두 고른' in question or '모두 묶인' in question)) or \\\n",
    "         (re.search(r'[ⓐⓑⓒⓓⓔ]', question) and ('모두 고른' in question or '모두 묶인' in question)):\n",
    "        pick_abcd.append(m)\n",
    "    # 1. 옳은 것을 고르는 문제 (단일 선택)\n",
    "    # if ('옳은' in question) or ('옳게' in question) or ('해당하는' in question) or ('적절한' in question) or ('적절하게' in question) or ('바르게' in question) or ('올바른' in question) or ('가장 깊은' in question) or ('가장 타당한' in question) or ('관련 있는' in question):\n",
    "    #     pick_right.append(m)\n",
    "    # 2. 옳지 않은 것을 고르는 문제 (단일 선택)\n",
    "    elif ('않은' in question) or ('못한' in question) or ('없는' in question) or ('거리가 먼' in question) or ('아닌' in question) or ('아니하는 것' in question) or ('않는' in question) or (\"않게\" in question) or ('잘못된' in question) or ('틀린' in question) or ('다른' in question) or ('무관한' in question) or ('가장 먼' in question) or ('어려운' in question):\n",
    "        pick_wrong.append(m)\n",
    "    else:\n",
    "        # 분류되지 않은 항목\n",
    "        # remaining.append(m)\n",
    "        pick_right.append(m)\n",
    "\n",
    "# 분류 결과 확인\n",
    "print(f\"전체: {len(multiple)}\")\n",
    "print(f\"옳은 것은? (단일 선택): {len(pick_right)}\")\n",
    "print(f\"옳지 않은 것은? (단일 선택): {len(pick_wrong)}\")\n",
    "print(f\"옳은 것을 모두 고른 것은? (다중 선택): {len(pick_abcd)}\")\n",
    "print(f\"미분류: {len(remaining)}\")\n",
    "print(f\"합계: {len(pick_right) + len(pick_wrong) + len(pick_abcd) + len(remaining)}\")\n",
    "\n",
    "len(remaining), len(pick_right), len(pick_wrong), len(pick_abcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in remaining:\n",
    "#     print(r['question'])\n",
    "#     print(\"---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_abcd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 옳지 않은 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
