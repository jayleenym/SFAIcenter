{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원래 있던 빈 도메인 채우기\n",
    "- (원래있던 multiple_domain_ALL 활용) fill_multiple_choice_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/evaluation/fill_multiple_choice_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 새로운 빈 도메인만 골라서 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json, os\n",
    "\n",
    "# with open('/Users/yejin/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation_yejin/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json', 'r', encoding='utf-8') as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# re_run_list = []\n",
    "\n",
    "# for d in data:\n",
    "#     if d['domain'] == '':\n",
    "#         re_run_list.append(d)\n",
    "\n",
    "# print(len(re_run_list))\n",
    "\n",
    "# with open('/Users/yejin/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation_yejin/eval_data/2_subdomain/multiple_re_run.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(re_run_list, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python hhhhh.py multiple-fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원래 있던거에 끼어넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, json\n",
    "\n",
    "# ONEDRIVE_PATH = os.path.join(os.path.expanduser(\"~\"), \"Library/CloudStorage/OneDrive-개인/데이터L/selectstar\")\n",
    "\n",
    "# file_name = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json')\n",
    "# with open(file_name, 'r', encoding='utf-8') as f:\n",
    "#     multiple = json.load(f)\n",
    "\n",
    "\n",
    "# file_failed_question = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data/2_subdomain/multiple-fail_response.json')\n",
    "# with open(file_failed_question, 'r', encoding='utf-8') as f:\n",
    "#     multiple_fail = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in multiple:\n",
    "#     # print(q)\n",
    "#     # if q['domain'] == '분류실패':\n",
    "#     if True:\n",
    "#         for m in multiple_fail:\n",
    "#             if (m['file_id'] == q['file_id']) and (m['tag'] == q['tag']):\n",
    "#                 q['domain'] = m['domain']\n",
    "#                 q['subdomain'] = m['subdomain']\n",
    "#                 q['classification_reason'] = m['classification_reason']\n",
    "#                 q['is_calculation'] = m['is_calculation']\n",
    "#                 # break\n",
    "#     # break\n",
    "# with open(file_name, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(multiple, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파싱 안된거 다시 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# file_fail_response = '/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple-fail_fail_response.json'\n",
    "\n",
    "# with open(file_fail_response, 'r', encoding='utf-8') as f:\n",
    "#     multiple_fail_again = json.load(f)\n",
    "\n",
    "# # response 파싱 다시 해보기\n",
    "# for q in multiple:\n",
    "#     # if q['domain'] == '':\n",
    "#     if True:\n",
    "#         for m in multiple_fail_again:\n",
    "#             file_id = m['qna_id'].split('_')[0]\n",
    "#             tag = m['qna_id'].replace(file_id+'_', '')\n",
    "#             if (file_id == q['file_id']) and (tag == q['tag']):\n",
    "#                 q['domain'] = m['domain']\n",
    "#                 q['subdomain'] = m['subdomain']\n",
    "#                 q['classification_reason'] = m['reason']\n",
    "#                 q['is_calculation'] = m['is_calculation']\n",
    "#                 # print(q)\n",
    "#                 # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모의고사 만들기 파이프라인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mock 데이터에서 모의고사 문제 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "ONEDRIVE_PATH = os.path.join(os.path.expanduser(\"~\"), \"Library/CloudStorage/OneDrive-개인/데이터L/selectstar\")\n",
    "BASE_DIR = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data')\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, '2_subdomain')\n",
    "EXAM_DIR = os.path.join(BASE_DIR, '4_multiple_exam')\n",
    "PROJECT_ROOT = os.path.join(os.path.expanduser(\"~\"), \"Desktop/Desktop_AICenter✨/SFAIcenter\")\n",
    "\n",
    "# 세트 이름 매핑\n",
    "set_names = {\n",
    "    1: '1st',\n",
    "    2: '2nd',\n",
    "    3: '3rd',\n",
    "    4: '4th',\n",
    "    5: '5th'\n",
    "}\n",
    "\n",
    "# 로깅 설정\n",
    "log_file = os.path.join(PROJECT_ROOT, 'logs/mock_exam_extraction.log')\n",
    "os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
    "\n",
    "logger = logging.getLogger('mock_exam_extraction')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# 기존 핸들러 제거 (중복 방지)\n",
    "if logger.handlers:\n",
    "    logger.handlers.clear()\n",
    "\n",
    "# 파일 핸들러\n",
    "file_handler = logging.FileHandler(log_file, encoding='utf-8', mode='a')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "\n",
    "# 콘솔 핸들러\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "\n",
    "# 포맷 설정\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "file_handler.setFormatter(formatter)\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "# 핸들러 추가\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# 부모 로거로 전파 방지 (중복 출력 방지)\n",
    "logger.propagate = False\n",
    "\n",
    "# multiple_subdomain_classified_ALL.json 파일에서 모든 데이터 로드\n",
    "ALL_DATA_FILE = os.path.join(PROCESSED_DIR, 'multiple_subdomain_classified_ALL.json')\n",
    "\n",
    "logger.info(f\"데이터 파일 로딩 시작: {ALL_DATA_FILE}\")\n",
    "with open(ALL_DATA_FILE, 'r', encoding='utf-8') as f:\n",
    "    all_data = json.load(f)\n",
    "logger.info(f\"데이터 로딩 완료: 총 {len(all_data)}개 문제\")\n",
    "\n",
    "with open(os.path.join(BASE_DIR, 'exam_statistics.json'), 'r', encoding='utf-8') as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "# 사용된 문제 추적 (file_id, tag) 튜플로 식별\n",
    "used_questions = set()\n",
    "\n",
    "# 4개의 과목별로 처리 (금융일반, 금융심화, 금융실무1, 금융실무2)\n",
    "for exam_name in stats.keys():\n",
    "    logger.info(f\"{'='*50}\")\n",
    "    logger.info(f\"과목: {exam_name}\")\n",
    "    \n",
    "    # 3세트를 위한 리스트 초기화\n",
    "    exam_data_sets = [[], [], [], [], []]\n",
    "    total_exam_questions = 0\n",
    "    \n",
    "    # domain별로 처리\n",
    "    for domain in stats[exam_name].keys():\n",
    "        logger.info(f\"{'-'*50}\")\n",
    "        logger.info(f\"도메인: {domain}\")\n",
    "        \n",
    "        domain_exam_questions = stats[exam_name][domain]['exam_questions']\n",
    "        total_exam_questions += domain_exam_questions\n",
    "        \n",
    "        # 해당 domain의 데이터 필터링\n",
    "        domain_data = [d for d in all_data if d['domain'] == domain]\n",
    "        \n",
    "        # subdomain 별로 문제 추출 - 5세트용\n",
    "        for subdomain, needed_count in stats[exam_name][domain]['exam_subdomain_distribution'].items():\n",
    "            # 해당 subdomain의 데이터 필터링\n",
    "            subdomain_data = [d for d in domain_data if d['subdomain'] == subdomain]\n",
    "            random.shuffle(subdomain_data)\n",
    "            \n",
    "            try:\n",
    "                # 1세트 샘플링\n",
    "                sample1 = random.sample(subdomain_data, needed_count)\n",
    "                remaining_data = [d for d in subdomain_data if d not in sample1]\n",
    "                \n",
    "                # 2세트 샘플링 (1세트 제외한 데이터에서)\n",
    "                sample2 = random.sample(remaining_data, needed_count)\n",
    "                remaining_data = [d for d in remaining_data if d not in sample2]\n",
    "                \n",
    "                # 3세트 샘플링 (1, 2세트 제외한 데이터에서)\n",
    "                sample3 = random.sample(remaining_data, needed_count)\n",
    "                remaining_data = [d for d in remaining_data if d not in sample3]\n",
    "                \n",
    "                # 4세트 샘플링 (1, 2, 3세트 제외한 데이터에서)\n",
    "                sample4 = random.sample(remaining_data, needed_count)\n",
    "                remaining_data = [d for d in remaining_data if d not in sample4]\n",
    "\n",
    "                # 5세트 샘플링 (1, 2, 3, 4세트 제외한 데이터에서)\n",
    "                sample5 = random.sample(remaining_data, needed_count)\n",
    "                remaining_data = [d for d in remaining_data if d not in sample5]\n",
    "                \n",
    "                logger.info(f\"  - {subdomain}: {needed_count} x 5세트 (총 {len(subdomain_data)}개 중 {needed_count * 5}개 사용)\")\n",
    "                \n",
    "                # 각 세트에 추가 및 사용된 문제 추적\n",
    "                for item in sample1 + sample2 + sample3 + sample4 + sample5:\n",
    "                    question_id = (item.get('file_id', ''), item.get('tag', ''))\n",
    "                    used_questions.add(question_id)\n",
    "                \n",
    "                exam_data_sets[0].extend(sample1)\n",
    "                exam_data_sets[1].extend(sample2)\n",
    "                exam_data_sets[2].extend(sample3)\n",
    "                exam_data_sets[3].extend(sample4)\n",
    "                exam_data_sets[4].extend(sample5)\n",
    "                \n",
    "            except ValueError:\n",
    "                # 데이터가 부족한 경우\n",
    "                total_available = len(subdomain_data)\n",
    "                sample1 = subdomain_data[:needed_count] if subdomain_data else []\n",
    "                sample2 = subdomain_data[needed_count:needed_count*2] if len(subdomain_data) > needed_count else []\n",
    "                sample3 = subdomain_data[needed_count*2:needed_count*3] if len(subdomain_data) > needed_count*2 else []\n",
    "                sample4 = subdomain_data[needed_count*3:needed_count*4] if len(subdomain_data) > needed_count*3 else []\n",
    "                sample5 = subdomain_data[needed_count*4:] if len(subdomain_data) > needed_count*4 else []\n",
    "                \n",
    "                logger.warning(f\"  - (ERROR) {subdomain}: {total_available}/{needed_count*5} (데이터 부족: {needed_count*5 - total_available}개 필요)\")\n",
    "                \n",
    "                # 사용된 문제 추적\n",
    "                for item in sample1 + sample2 + sample3 + sample4 + sample5:\n",
    "                    question_id = (item.get('file_id', ''), item.get('tag', ''))\n",
    "                    used_questions.add(question_id)\n",
    "                \n",
    "                exam_data_sets[0].extend(sample1)\n",
    "                exam_data_sets[1].extend(sample2)\n",
    "                exam_data_sets[2].extend(sample3)\n",
    "                exam_data_sets[3].extend(sample4)\n",
    "                exam_data_sets[4].extend(sample5)\n",
    "    \n",
    "    # 5개 세트로 저장\n",
    "    for set_num in range(5):\n",
    "        percentage_total = (len(exam_data_sets[set_num])/total_exam_questions*100) if total_exam_questions > 0 else 0\n",
    "        logger.info(f\"  ====> {set_names[set_num+1]}세트: {len(exam_data_sets[set_num])}/{total_exam_questions} ({percentage_total:.2f}%)\")\n",
    "        \n",
    "        # 출력 디렉토리 생성\n",
    "        set_dir = os.path.join(EXAM_DIR, set_names[set_num+1])\n",
    "        os.makedirs(set_dir, exist_ok=True)\n",
    "        output_file = os.path.join(set_dir, f'{exam_name}_exam.json')\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(exam_data_sets[set_num], f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        logger.info(f\"  ====> 저장 완료: {output_file}\")\n",
    "\n",
    "# 사용되지 않은 나머지 문제 필터링\n",
    "logger.info(f\"\\n{'='*50}\")\n",
    "logger.info(\"사용되지 않은 나머지 문제 필터링 시작...\")\n",
    "remaining_data = []\n",
    "for item in all_data:\n",
    "    question_id = (item.get('file_id', ''), item.get('tag', ''))\n",
    "    if question_id not in used_questions:\n",
    "        remaining_data.append(item)\n",
    "\n",
    "# 나머지 문제 저장\n",
    "logger.info(f\"사용되지 않은 나머지 문제: {len(remaining_data)}개\")\n",
    "\n",
    "remaining_file = os.path.join(PROCESSED_DIR, 'multiple_remaining.json')\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "with open(remaining_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(remaining_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "logger.info(f\"나머지 문제 저장 완료: {remaining_file}\")\n",
    "logger.info(f\"전체: {len(all_data)}개, 사용: {len(used_questions)}개, 남음: {len(remaining_data)}개\")\n",
    "logger.info(\"모든 작업 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple options 오류들\n",
    "- find_multiple_choice_invalid_options.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## short/essay인 객관식 조정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, json\n",
    "\n",
    "# with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/essay_subdomain_classified_ALL.json', 'r', encoding='utf-8') as f:\n",
    "#     essay = json.load(f)\n",
    "\n",
    "# with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/short_subdomain_classified_ALL.json', 'r', encoding='utf-8') as f:\n",
    "#     short = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_multiple = []\n",
    "\n",
    "# # for e in essay:\n",
    "# #     if isinstance(e['options'], list):\n",
    "# #         to_multiple.append(e)\n",
    "# # print(len(to_multiple))\n",
    "\n",
    "# new_short = []\n",
    "# for s in short:\n",
    "#     if isinstance(s['options'], list):\n",
    "#         to_multiple.append(s)\n",
    "#     else:\n",
    "#         new_short.append(s)\n",
    "# print(len(to_multiple), len(short), len(new_short))\n",
    "# # to_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/short_subdomain_classified_ALL.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(new_short, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple_shortans_classified_ALL.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(to_multiple, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원본에 옮기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, time\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# file_list = []\n",
    "\n",
    "# for t in tqdm(to_multiple):\n",
    "#     file_id = t.get('file_id')\n",
    "#     file_list.append(file_id)\n",
    "#     # print(file_id)\n",
    "#     tag = t.get('tag')\n",
    "#     time.sleep(0.5)\n",
    "        \n",
    "#     file_path = os.popen(f\"find /Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/data/FINAL -type f -name '{file_id}_v2.json'\").read().strip()\n",
    "#     if file_path == \"\":\n",
    "#         file_path = os.popen(f\"find /Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/data/FINAL -type f -name '{file_id}.json'\").read().strip()\n",
    "#     # print(file_path)\n",
    "\n",
    "#     with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "    \n",
    "#     contents = data['contents']\n",
    "\n",
    "#     for d in contents:\n",
    "#         if d.get('page') == tag.split('_')[1]:\n",
    "#             add_info = d.get('add_info')\n",
    "#             for info in add_info:\n",
    "#                 if info.get('tag') == tag:\n",
    "#                     if info.get('description').get('question') == t.get('question'):\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         # print(\"질문 다름\")\n",
    "#                         info['description']['question'] = t.get('question')\n",
    "\n",
    "#                     if info.get('description').get('answer') == t.get('answer'):\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         # print(\"답 다름\")\n",
    "#                         info['description']['answer'] = t.get('answer')\n",
    "#                     if info.get('description').get('options') == t.get('options'):\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         # print(\"옵션 다름\")\n",
    "#                         info['description']['options'] = t.get('options')\n",
    "#     if file_path.endswith(\"_v2.json\"):\n",
    "#         with open(file_path, 'w', encoding='utf-8') as f:\n",
    "#             json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "#     else:\n",
    "#         with open(file_path.replace(\".json\", \"_v2.json\"), 'w', encoding='utf-8') as f:\n",
    "#             json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(list(set(file_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from tools.evaluation import qna_subdomain_classifier\n",
    "\n",
    "ONEDRIVE_PATH = os.path.join(os.path.expanduser(\"~\"), \"Library/CloudStorage/OneDrive-개인/데이터L/selectstar\")\n",
    "\n",
    "file_name = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json')\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    multiple = json.load(f)\n",
    "\n",
    "classifier = qna_subdomain_classifier.QnASubdomainClassifier()\n",
    "classifier.save_statistics(multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 처음 subdomain 돌리고 잘못 부여된 subdomain 조정\n",
    "# for m in multiple:\n",
    "#     if m['subdomain'].count('-') >= 1:\n",
    "#         # print(m)\n",
    "#         # break\n",
    "#         m['subdomain'] = m['subdomain'].split('-')[0].strip()\n",
    "#         # print(m)\n",
    "#         # break\n",
    "#     elif m['subdomain'].count('.') >= 1:\n",
    "#         m['subdomain'] = m['subdomain'].split('.')[1].strip()\n",
    "        \n",
    "\n",
    "# classifier.save_statistics(multiple)\n",
    "#     # print(\"없는데?\", m['subdomain'])\n",
    "\n",
    "# with open(file_name, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(multiple, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(file_name, 'r', encoding='utf-8') as f:\n",
    "#     multiple = json.load(f)\n",
    "\n",
    "# for m in multiple:\n",
    "#     m['domain'] = \"\"\n",
    "#     m['subdomain'] = \"\"\n",
    "#     m['classification_reason'] = \"\"\n",
    "#     m['is_calculation'] = False\n",
    "\n",
    "# with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(multiple, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도메인별 통계 계산\n",
    "from collections import defaultdict\n",
    "\n",
    "calculation = defaultdict(int)  # 계산 문제 개수\n",
    "total_by_domain = defaultdict(int)  # 전체 문제 개수\n",
    "\n",
    "for question in first_exam:\n",
    "    domain = question.get('domain', '미분류')\n",
    "    total_by_domain[domain] += 1\n",
    "    if question.get('is_calculation') == True:\n",
    "        calculation[domain] += 1\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=\" * 60)\n",
    "print(\"도메인별 통계\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'도메인':<20} {'전체':<10} {'계산문제':<10} {'비율':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for domain in sorted(total_by_domain.keys()):\n",
    "    total = total_by_domain[domain]\n",
    "    calc_count = calculation[domain]\n",
    "    ratio = (calc_count / total * 100) if total > 0 else 0\n",
    "    print(f\"{domain:<20} {total:<10} {calc_count:<10} {ratio:.2f}%\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'합계':<20} {sum(total_by_domain.values()):<10} {sum(calculation.values()):<10} {sum(calculation.values())/sum(total_by_domain.values())*100:.2f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation 파일 수정하고 다시 돌리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "from tools.pipeline.config import ONEDRIVE_PATH\n",
    "\n",
    "EXAM_DIR = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data/4_multiple_exam')\n",
    "# EXAM_DIR = os.path.join(os.path.expanduser(\"~\"), '4_multiple_exam')\n",
    "\n",
    "for exams in os.listdir(EXAM_DIR):\n",
    "    if exams == \"1st\":\n",
    "        first_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "            with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "                first_exam += json.load(f)\n",
    "    elif exams == \"2nd\":\n",
    "        second_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "            with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "                second_exam += json.load(f)\n",
    "    elif exams == \"3rd\":\n",
    "        third_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "            with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "                third_exam += json.load(f)\n",
    "    elif exams == \"4th\":\n",
    "        fourth_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "            with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "                fourth_exam += json.load(f)\n",
    "    elif exams == \"5th\":\n",
    "        fifth_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "            with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "                fifth_exam += json.load(f)\n",
    "\n",
    "multiple = first_exam + second_exam + third_exam + fourth_exam + fifth_exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tools.pipeline.config import ONEDRIVE_PATH\n",
    "\n",
    "model_name = 'ALL'\n",
    "excel_path = os.path.join(ONEDRIVE_PATH, f'evaluation/eval_data/6_exam_evaluation/5th/5th_evaluation_{model_name}.xlsx')\n",
    "print(excel_path)\n",
    "pred_wide = pd.read_excel(excel_path, sheet_name='모델별예측')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty_ids = pred_wide[pred_wide['openai/gpt-5.1'].isna()].id.tolist()\n",
    "print(pred_wide.columns[-1])\n",
    "# print(empty_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_json = []\n",
    "for q in empty_ids:\n",
    "    for m in fifth_exam:\n",
    "        if m['file_id']+\"_\"+m['tag'] == q:\n",
    "            # print(m)\n",
    "            new_json.append(m)\n",
    "\n",
    "print(len(new_json) == len(empty_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(os.path.join(ONEDRIVE_PATH, 'evaluation/model_new.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(new_json, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel 파일에서 정확도 계산 (전체, subject별, domain별, subdomain별)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Set\n",
    "import ast\n",
    "\n",
    "# Excel 파일 경로 설정\n",
    "# excel_path = f'/Users/yejin/Downloads/2nd_evaluation_ALL.xlsx'\n",
    "\n",
    "# Excel 파일 읽기\n",
    "df_sample = pd.read_excel(excel_path, sheet_name='전체데이터')\n",
    "pred_wide = pd.read_excel(excel_path, sheet_name='모델별예측')\n",
    "\n",
    "# pred_wide를 pred_long 형식으로 변환 (melt 사용)\n",
    "# pred_wide는 id 컬럼과 각 모델명이 컬럼으로 있는 와이드 포맷\n",
    "# pred_long은 id, model_name, answer 컬럼이 있는 롱 포맷\n",
    "pred_long = pred_wide.melt(\n",
    "    id_vars=['id'],  # id 컬럼은 그대로 유지\n",
    "    var_name='model_name',  # 모델명 컬럼 이름\n",
    "    value_name='answer'  # 예측값 컬럼 이름\n",
    ")\n",
    "\n",
    "# answer_set을 Set[int]로 변환하는 헬퍼 함수\n",
    "def _parse_answer_set(answer_set):\n",
    "    if isinstance(answer_set, set):\n",
    "        return answer_set\n",
    "    elif isinstance(answer_set, str):\n",
    "        try:\n",
    "            # 문자열을 파싱해서 Set[int]로 변환\n",
    "            parsed = ast.literal_eval(answer_set)\n",
    "            if isinstance(parsed, set):\n",
    "                return parsed\n",
    "            elif isinstance(parsed, (list, tuple)):\n",
    "                return set(parsed)\n",
    "            else:\n",
    "                return {int(parsed)}\n",
    "        except:\n",
    "            # 파싱 실패 시 빈 집합 반환\n",
    "            return set()\n",
    "    else:\n",
    "        # 숫자나 다른 타입인 경우\n",
    "        try:\n",
    "            return {int(answer_set)}\n",
    "        except:\n",
    "            return set()\n",
    "\n",
    "# 정답 여부 계산 함수\n",
    "def _is_correct(pred: float, s: Set[int]) -> float:\n",
    "    if np.isnan(pred) or not s:\n",
    "        return np.nan\n",
    "    return float(int(pred) in s)\n",
    "\n",
    "# 데이터 병합 및 정확도 계산\n",
    "key = df_sample[[\"id\", \"answer_set\"]].copy()\n",
    "merged = pred_long.merge(key, on=\"id\", how=\"left\")\n",
    "merged[\"answer_set\"] = merged[\"answer_set\"].apply(_parse_answer_set)\n",
    "merged[\"correct\"] = merged.apply(lambda r: _is_correct(r[\"answer\"], r[\"answer_set\"]), axis=1)\n",
    "\n",
    "# 전체 정확도 계산\n",
    "acc_by_model = (\n",
    "    merged.groupby(\"model_name\", dropna=False)[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"correct\": \"accuracy\"})\n",
    "    .sort_values(\"accuracy\", ascending=False)\n",
    ")\n",
    "\n",
    "# Excel 파일에 결과 저장\n",
    "# 기존 파일을 읽어서 모든 시트를 유지하면서 특정 시트만 업데이트\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# 기존 파일의 모든 시트 읽기 (업데이트할 시트 제외)\n",
    "existing_sheets = {}\n",
    "try:\n",
    "    book = load_workbook(excel_path)\n",
    "    for sheet_name in book.sheetnames:\n",
    "        if sheet_name not in [\"전체데이터\", \"모델별예측\", \"정확도\", \"Subject별정확도\", \"Subject별문제수\", \n",
    "                              \"Domain별정확도\", \"Domain별문제수\", \"Subdomain별정확도\", \"Subdomain별문제수\"]:\n",
    "            # 업데이트할 시트가 아닌 경우 기존 데이터 읽기\n",
    "            existing_sheets[sheet_name] = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# 모든 시트를 새 파일로 저장\n",
    "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode='w') as writer:\n",
    "    # 기존 시트 유지\n",
    "    for sheet_name, df in existing_sheets.items():\n",
    "        df.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "    # 기본 시트들 업데이트\n",
    "    df_sample.to_excel(writer, index=False, sheet_name=\"전체데이터\")\n",
    "    pred_wide.to_excel(writer, index=False, sheet_name=\"모델별예측\")\n",
    "    acc_by_model.to_excel(writer, index=False, sheet_name=\"정확도\")\n",
    "    \n",
    "    # subject별 정확도 계산 및 저장 (subject 컬럼이 있는 경우)\n",
    "    if 'subject' in df_sample.columns:\n",
    "        subject_info = df_sample[[\"id\", \"subject\"]].copy()\n",
    "        merged_with_subject = merged.merge(subject_info, on=\"id\", how=\"left\")\n",
    "        \n",
    "        subject_acc = (\n",
    "            merged_with_subject.groupby([\"subject\", \"model_name\"], dropna=False)[\"correct\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .pivot(index=\"subject\", columns=\"model_name\", values=\"correct\")\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "        subject_acc.to_excel(writer, index=False, sheet_name=\"Subject별정확도\")\n",
    "        \n",
    "        # Subject별 문제 수 통계\n",
    "        subject_stats = df_sample.groupby('subject').size().reset_index(name='question_count')\n",
    "        subject_stats.to_excel(writer, index=False, sheet_name=\"Subject별문제수\")\n",
    "    \n",
    "    # domain별 정확도 계산 및 저장 (domain 컬럼이 있는 경우)\n",
    "    if 'domain' in df_sample.columns:\n",
    "        domain_info = df_sample[[\"id\", \"domain\"]].copy()\n",
    "        merged_with_domain = merged.merge(domain_info, on=\"id\", how=\"left\")\n",
    "        \n",
    "        domain_acc = (\n",
    "            merged_with_domain.groupby([\"domain\", \"model_name\"], dropna=False)[\"correct\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .pivot(index=\"domain\", columns=\"model_name\", values=\"correct\")\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "        domain_acc.to_excel(writer, index=False, sheet_name=\"Domain별정확도\")\n",
    "        \n",
    "        # Domain별 문제 수 통계\n",
    "        domain_stats = df_sample.groupby('domain').size().reset_index(name='question_count')\n",
    "        domain_stats.to_excel(writer, index=False, sheet_name=\"Domain별문제수\")\n",
    "    \n",
    "    # subdomain별 정확도 계산 및 저장 (subdomain 컬럼이 있는 경우)\n",
    "    if 'subdomain' in df_sample.columns:\n",
    "        subdomain_info = df_sample[[\"id\", \"domain\", \"subdomain\"]].copy()\n",
    "        merged_with_subdomain = merged.merge(subdomain_info, on=\"id\", how=\"left\")\n",
    "        \n",
    "        subdomain_acc = (\n",
    "            merged_with_subdomain.groupby([\"domain\", \"subdomain\", \"model_name\"], dropna=False)[\"correct\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .pivot(index=[\"domain\", \"subdomain\"], columns=\"model_name\", values=\"correct\")\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "        subdomain_acc.to_excel(writer, index=False, sheet_name=\"Subdomain별정확도\")\n",
    "        \n",
    "        # Subdomain별 문제 수 통계\n",
    "        subdomain_stats = df_sample.groupby(['domain', 'subdomain']).size().reset_index(name='question_count')\n",
    "        subdomain_stats.to_excel(writer, index=False, sheet_name=\"Subdomain별문제수\")\n",
    "\n",
    "print(f\"✅ Excel 파일 업데이트 완료: {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
