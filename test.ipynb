{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì›ë˜ ìˆë˜ ë¹ˆ ë„ë©”ì¸ ì±„ìš°ê¸°\n",
    "- (ì›ë˜ìˆë˜ multiple_domain_ALL í™œìš©) fill_multiple_choice_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/evaluation/fill_multiple_choice_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìƒˆë¡œìš´ ë¹ˆ ë„ë©”ì¸ë§Œ ê³¨ë¼ì„œ ì±„ìš°ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json, os\n",
    "\n",
    "# with open('/Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/evaluation_yejin/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json', 'r', encoding='utf-8') as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# re_run_list = []\n",
    "\n",
    "# for d in data:\n",
    "#     if d['domain'] == '':\n",
    "#         re_run_list.append(d)\n",
    "\n",
    "# print(len(re_run_list))\n",
    "\n",
    "# with open('/Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/evaluation_yejin/eval_data/2_subdomain/multiple_re_run.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(re_run_list, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python hhhhh.py multiple-fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì›ë˜ ìˆë˜ê±°ì— ë¼ì–´ë„£ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, json\n",
    "\n",
    "# ONEDRIVE_PATH = os.path.join(os.path.expanduser(\"~\"), \"Library/CloudStorage/OneDrive-á„€á…¢á„‹á…µá†«/á„ƒá…¦á„‹á…µá„á…¥L/selectstar\")\n",
    "\n",
    "# file_name = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json')\n",
    "# with open(file_name, 'r', encoding='utf-8') as f:\n",
    "#     multiple = json.load(f)\n",
    "\n",
    "\n",
    "# file_failed_question = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data/2_subdomain/multiple-fail_response.json')\n",
    "# with open(file_failed_question, 'r', encoding='utf-8') as f:\n",
    "#     multiple_fail = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in multiple:\n",
    "#     # print(q)\n",
    "#     # if q['domain'] == 'ë¶„ë¥˜ì‹¤íŒ¨':\n",
    "#     if True:\n",
    "#         for m in multiple_fail:\n",
    "#             if (m['file_id'] == q['file_id']) and (m['tag'] == q['tag']):\n",
    "#                 q['domain'] = m['domain']\n",
    "#                 q['subdomain'] = m['subdomain']\n",
    "#                 q['classification_reason'] = m['classification_reason']\n",
    "#                 q['is_calculation'] = m['is_calculation']\n",
    "#                 # break\n",
    "#     # break\n",
    "# with open(file_name, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(multiple, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### íŒŒì‹± ì•ˆëœê±° ë‹¤ì‹œ í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# file_fail_response = '/Users/jinym/Desktop/Desktop_AICenterâœ¨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple-fail_fail_response.json'\n",
    "\n",
    "# with open(file_fail_response, 'r', encoding='utf-8') as f:\n",
    "#     multiple_fail_again = json.load(f)\n",
    "\n",
    "# # response íŒŒì‹± ë‹¤ì‹œ í•´ë³´ê¸°\n",
    "# for q in multiple:\n",
    "#     # if q['domain'] == '':\n",
    "#     if True:\n",
    "#         for m in multiple_fail_again:\n",
    "#             file_id = m['qna_id'].split('_')[0]\n",
    "#             tag = m['qna_id'].replace(file_id+'_', '')\n",
    "#             if (file_id == q['file_id']) and (tag == q['tag']):\n",
    "#                 q['domain'] = m['domain']\n",
    "#                 q['subdomain'] = m['subdomain']\n",
    "#                 q['classification_reason'] = m['reason']\n",
    "#                 q['is_calculation'] = m['is_calculation']\n",
    "#                 # print(q)\n",
    "#                 # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª¨ì˜ê³ ì‚¬ ë§Œë“¤ê¸° íŒŒì´í”„ë¼ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mock ë°ì´í„°ì—ì„œ ëª¨ì˜ê³ ì‚¬ ë¬¸ì œ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "ONEDRIVE_PATH = os.path.join(os.path.expanduser(\"~\"), \"Library/CloudStorage/OneDrive-á„€á…¢á„‹á…µá†«/á„ƒá…¦á„‹á…µá„á…¥L/selectstar\")\n",
    "BASE_DIR = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data')\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, '2_subdomain')\n",
    "EXAM_DIR = os.path.join(BASE_DIR, '4_multiple_exam')\n",
    "PROJECT_ROOT = os.path.join(os.path.expanduser(\"~\"), \"Desktop/Desktop_AICenterâœ¨/SFAIcenter\")\n",
    "\n",
    "# ì„¸íŠ¸ ì´ë¦„ ë§¤í•‘\n",
    "set_names = {\n",
    "    1: '1st',\n",
    "    2: '2nd',\n",
    "    3: '3rd',\n",
    "    4: '4th',\n",
    "    5: '5th'\n",
    "}\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "log_file = os.path.join(PROJECT_ROOT, 'logs/mock_exam_extraction.log')\n",
    "os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
    "\n",
    "logger = logging.getLogger('mock_exam_extraction')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)\n",
    "if logger.handlers:\n",
    "    logger.handlers.clear()\n",
    "\n",
    "# íŒŒì¼ í•¸ë“¤ëŸ¬\n",
    "file_handler = logging.FileHandler(log_file, encoding='utf-8', mode='a')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "\n",
    "# ì½˜ì†” í•¸ë“¤ëŸ¬\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "\n",
    "# í¬ë§· ì„¤ì •\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "file_handler.setFormatter(formatter)\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "# í•¸ë“¤ëŸ¬ ì¶”ê°€\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# ë¶€ëª¨ ë¡œê±°ë¡œ ì „íŒŒ ë°©ì§€ (ì¤‘ë³µ ì¶œë ¥ ë°©ì§€)\n",
    "logger.propagate = False\n",
    "\n",
    "# multiple_subdomain_classified_ALL.json íŒŒì¼ì—ì„œ ëª¨ë“  ë°ì´í„° ë¡œë“œ\n",
    "ALL_DATA_FILE = os.path.join(PROCESSED_DIR, 'multiple_subdomain_classified_ALL.json')\n",
    "\n",
    "logger.info(f\"ë°ì´í„° íŒŒì¼ ë¡œë”© ì‹œì‘: {ALL_DATA_FILE}\")\n",
    "with open(ALL_DATA_FILE, 'r', encoding='utf-8') as f:\n",
    "    all_data = json.load(f)\n",
    "logger.info(f\"ë°ì´í„° ë¡œë”© ì™„ë£Œ: ì´ {len(all_data)}ê°œ ë¬¸ì œ\")\n",
    "\n",
    "with open(os.path.join(BASE_DIR, 'exam_statistics.json'), 'r', encoding='utf-8') as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "# ì‚¬ìš©ëœ ë¬¸ì œ ì¶”ì  (file_id, tag) íŠœí”Œë¡œ ì‹ë³„\n",
    "used_questions = set()\n",
    "\n",
    "# 4ê°œì˜ ê³¼ëª©ë³„ë¡œ ì²˜ë¦¬ (ê¸ˆìœµì¼ë°˜, ê¸ˆìœµì‹¬í™”, ê¸ˆìœµì‹¤ë¬´1, ê¸ˆìœµì‹¤ë¬´2)\n",
    "for exam_name in stats.keys():\n",
    "    logger.info(f\"{'='*50}\")\n",
    "    logger.info(f\"ê³¼ëª©: {exam_name}\")\n",
    "    \n",
    "    # 3ì„¸íŠ¸ë¥¼ ìœ„í•œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "    exam_data_sets = [[], [], [], [], []]\n",
    "    total_exam_questions = 0\n",
    "    \n",
    "    # domainë³„ë¡œ ì²˜ë¦¬\n",
    "    for domain in stats[exam_name].keys():\n",
    "        logger.info(f\"{'-'*50}\")\n",
    "        logger.info(f\"ë„ë©”ì¸: {domain}\")\n",
    "        \n",
    "        domain_exam_questions = stats[exam_name][domain]['exam_questions']\n",
    "        total_exam_questions += domain_exam_questions\n",
    "        \n",
    "        # í•´ë‹¹ domainì˜ ë°ì´í„° í•„í„°ë§\n",
    "        domain_data = [d for d in all_data if d['domain'] == domain]\n",
    "        \n",
    "        # subdomain ë³„ë¡œ ë¬¸ì œ ì¶”ì¶œ - 5ì„¸íŠ¸ìš©\n",
    "        for subdomain, needed_count in stats[exam_name][domain]['exam_subdomain_distribution'].items():\n",
    "            # í•´ë‹¹ subdomainì˜ ë°ì´í„° í•„í„°ë§\n",
    "            subdomain_data = [d for d in domain_data if d['subdomain'] == subdomain]\n",
    "            random.shuffle(subdomain_data)\n",
    "            \n",
    "            try:\n",
    "                # 1ì„¸íŠ¸ ìƒ˜í”Œë§\n",
    "                sample1 = random.sample(subdomain_data, needed_count)\n",
    "                remaining_data = [d for d in subdomain_data if d not in sample1]\n",
    "                \n",
    "                # 2ì„¸íŠ¸ ìƒ˜í”Œë§ (1ì„¸íŠ¸ ì œì™¸í•œ ë°ì´í„°ì—ì„œ)\n",
    "                sample2 = random.sample(remaining_data, needed_count)\n",
    "                remaining_data = [d for d in remaining_data if d not in sample2]\n",
    "                \n",
    "                # 3ì„¸íŠ¸ ìƒ˜í”Œë§ (1, 2ì„¸íŠ¸ ì œì™¸í•œ ë°ì´í„°ì—ì„œ)\n",
    "                sample3 = random.sample(remaining_data, needed_count)\n",
    "                remaining_data = [d for d in remaining_data if d not in sample3]\n",
    "                \n",
    "                # 4ì„¸íŠ¸ ìƒ˜í”Œë§ (1, 2, 3ì„¸íŠ¸ ì œì™¸í•œ ë°ì´í„°ì—ì„œ)\n",
    "                sample4 = random.sample(remaining_data, needed_count)\n",
    "                remaining_data = [d for d in remaining_data if d not in sample4]\n",
    "\n",
    "                # 5ì„¸íŠ¸ ìƒ˜í”Œë§ (1, 2, 3, 4ì„¸íŠ¸ ì œì™¸í•œ ë°ì´í„°ì—ì„œ)\n",
    "                sample5 = random.sample(remaining_data, needed_count)\n",
    "                remaining_data = [d for d in remaining_data if d not in sample5]\n",
    "                \n",
    "                logger.info(f\"  - {subdomain}: {needed_count} x 5ì„¸íŠ¸ (ì´ {len(subdomain_data)}ê°œ ì¤‘ {needed_count * 5}ê°œ ì‚¬ìš©)\")\n",
    "                \n",
    "                # ê° ì„¸íŠ¸ì— ì¶”ê°€ ë° ì‚¬ìš©ëœ ë¬¸ì œ ì¶”ì \n",
    "                for item in sample1 + sample2 + sample3 + sample4 + sample5:\n",
    "                    question_id = (item.get('file_id', ''), item.get('tag', ''))\n",
    "                    used_questions.add(question_id)\n",
    "                \n",
    "                exam_data_sets[0].extend(sample1)\n",
    "                exam_data_sets[1].extend(sample2)\n",
    "                exam_data_sets[2].extend(sample3)\n",
    "                exam_data_sets[3].extend(sample4)\n",
    "                exam_data_sets[4].extend(sample5)\n",
    "                \n",
    "            except ValueError:\n",
    "                # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš°\n",
    "                total_available = len(subdomain_data)\n",
    "                sample1 = subdomain_data[:needed_count] if subdomain_data else []\n",
    "                sample2 = subdomain_data[needed_count:needed_count*2] if len(subdomain_data) > needed_count else []\n",
    "                sample3 = subdomain_data[needed_count*2:needed_count*3] if len(subdomain_data) > needed_count*2 else []\n",
    "                sample4 = subdomain_data[needed_count*3:needed_count*4] if len(subdomain_data) > needed_count*3 else []\n",
    "                sample5 = subdomain_data[needed_count*4:] if len(subdomain_data) > needed_count*4 else []\n",
    "                \n",
    "                logger.warning(f\"  - (ERROR) {subdomain}: {total_available}/{needed_count*5} (ë°ì´í„° ë¶€ì¡±: {needed_count*5 - total_available}ê°œ í•„ìš”)\")\n",
    "                \n",
    "                # ì‚¬ìš©ëœ ë¬¸ì œ ì¶”ì \n",
    "                for item in sample1 + sample2 + sample3 + sample4 + sample5:\n",
    "                    question_id = (item.get('file_id', ''), item.get('tag', ''))\n",
    "                    used_questions.add(question_id)\n",
    "                \n",
    "                exam_data_sets[0].extend(sample1)\n",
    "                exam_data_sets[1].extend(sample2)\n",
    "                exam_data_sets[2].extend(sample3)\n",
    "                exam_data_sets[3].extend(sample4)\n",
    "                exam_data_sets[4].extend(sample5)\n",
    "    \n",
    "    # 5ê°œ ì„¸íŠ¸ë¡œ ì €ì¥\n",
    "    for set_num in range(5):\n",
    "        percentage_total = (len(exam_data_sets[set_num])/total_exam_questions*100) if total_exam_questions > 0 else 0\n",
    "        logger.info(f\"  ====> {set_names[set_num+1]}ì„¸íŠ¸: {len(exam_data_sets[set_num])}/{total_exam_questions} ({percentage_total:.2f}%)\")\n",
    "        \n",
    "        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "        set_dir = os.path.join(EXAM_DIR, set_names[set_num+1])\n",
    "        os.makedirs(set_dir, exist_ok=True)\n",
    "        output_file = os.path.join(set_dir, f'{exam_name}_exam.json')\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(exam_data_sets[set_num], f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        logger.info(f\"  ====> ì €ì¥ ì™„ë£Œ: {output_file}\")\n",
    "\n",
    "# ì‚¬ìš©ë˜ì§€ ì•Šì€ ë‚˜ë¨¸ì§€ ë¬¸ì œ í•„í„°ë§\n",
    "logger.info(f\"\\n{'='*50}\")\n",
    "logger.info(\"ì‚¬ìš©ë˜ì§€ ì•Šì€ ë‚˜ë¨¸ì§€ ë¬¸ì œ í•„í„°ë§ ì‹œì‘...\")\n",
    "remaining_data = []\n",
    "for item in all_data:\n",
    "    question_id = (item.get('file_id', ''), item.get('tag', ''))\n",
    "    if question_id not in used_questions:\n",
    "        remaining_data.append(item)\n",
    "\n",
    "# ë‚˜ë¨¸ì§€ ë¬¸ì œ ì €ì¥\n",
    "logger.info(f\"ì‚¬ìš©ë˜ì§€ ì•Šì€ ë‚˜ë¨¸ì§€ ë¬¸ì œ: {len(remaining_data)}ê°œ\")\n",
    "\n",
    "remaining_file = os.path.join(PROCESSED_DIR, 'multiple_remaining.json')\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "with open(remaining_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(remaining_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "logger.info(f\"ë‚˜ë¨¸ì§€ ë¬¸ì œ ì €ì¥ ì™„ë£Œ: {remaining_file}\")\n",
    "logger.info(f\"ì „ì²´: {len(all_data)}ê°œ, ì‚¬ìš©: {len(used_questions)}ê°œ, ë‚¨ìŒ: {len(remaining_data)}ê°œ\")\n",
    "logger.info(\"ëª¨ë“  ì‘ì—… ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple options ì˜¤ë¥˜ë“¤\n",
    "- find_multiple_choice_invalid_options.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## short/essayì¸ ê°ê´€ì‹ ì¡°ì •í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, json\n",
    "\n",
    "# with open('/Users/jinym/Desktop/Desktop_AICenterâœ¨/SFAIcenter/evaluation/eval_data/2_subdomain/essay_subdomain_classified_ALL.json', 'r', encoding='utf-8') as f:\n",
    "#     essay = json.load(f)\n",
    "\n",
    "# with open('/Users/jinym/Desktop/Desktop_AICenterâœ¨/SFAIcenter/evaluation/eval_data/2_subdomain/short_subdomain_classified_ALL.json', 'r', encoding='utf-8') as f:\n",
    "#     short = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_multiple = []\n",
    "\n",
    "# # for e in essay:\n",
    "# #     if isinstance(e['options'], list):\n",
    "# #         to_multiple.append(e)\n",
    "# # print(len(to_multiple))\n",
    "\n",
    "# new_short = []\n",
    "# for s in short:\n",
    "#     if isinstance(s['options'], list):\n",
    "#         to_multiple.append(s)\n",
    "#     else:\n",
    "#         new_short.append(s)\n",
    "# print(len(to_multiple), len(short), len(new_short))\n",
    "# # to_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/jinym/Desktop/Desktop_AICenterâœ¨/SFAIcenter/evaluation/eval_data/2_subdomain/short_subdomain_classified_ALL.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(new_short, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# with open('/Users/jinym/Desktop/Desktop_AICenterâœ¨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple_shortans_classified_ALL.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(to_multiple, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì›ë³¸ì— ì˜®ê¸°ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, time\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# file_list = []\n",
    "\n",
    "# for t in tqdm(to_multiple):\n",
    "#     file_id = t.get('file_id')\n",
    "#     file_list.append(file_id)\n",
    "#     # print(file_id)\n",
    "#     tag = t.get('tag')\n",
    "#     time.sleep(0.5)\n",
    "        \n",
    "#     file_path = os.popen(f\"find /Users/jinym/Desktop/Desktop_AICenterâœ¨/SFAIcenter/data/FINAL -type f -name '{file_id}_v2.json'\").read().strip()\n",
    "#     if file_path == \"\":\n",
    "#         file_path = os.popen(f\"find /Users/jinym/Desktop/Desktop_AICenterâœ¨/SFAIcenter/data/FINAL -type f -name '{file_id}.json'\").read().strip()\n",
    "#     # print(file_path)\n",
    "\n",
    "#     with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "    \n",
    "#     contents = data['contents']\n",
    "\n",
    "#     for d in contents:\n",
    "#         if d.get('page') == tag.split('_')[1]:\n",
    "#             add_info = d.get('add_info')\n",
    "#             for info in add_info:\n",
    "#                 if info.get('tag') == tag:\n",
    "#                     if info.get('description').get('question') == t.get('question'):\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         # print(\"ì§ˆë¬¸ ë‹¤ë¦„\")\n",
    "#                         info['description']['question'] = t.get('question')\n",
    "\n",
    "#                     if info.get('description').get('answer') == t.get('answer'):\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         # print(\"ë‹µ ë‹¤ë¦„\")\n",
    "#                         info['description']['answer'] = t.get('answer')\n",
    "#                     if info.get('description').get('options') == t.get('options'):\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         # print(\"ì˜µì…˜ ë‹¤ë¦„\")\n",
    "#                         info['description']['options'] = t.get('options')\n",
    "#     if file_path.endswith(\"_v2.json\"):\n",
    "#         with open(file_path, 'w', encoding='utf-8') as f:\n",
    "#             json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "#     else:\n",
    "#         with open(file_path.replace(\".json\", \"_v2.json\"), 'w', encoding='utf-8') as f:\n",
    "#             json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(list(set(file_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í†µê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from tools.evaluation import qna_subdomain_classifier\n",
    "\n",
    "ONEDRIVE_PATH = os.path.join(os.path.expanduser(\"~\"), \"Library/CloudStorage/OneDrive-á„€á…¢á„‹á…µá†«/á„ƒá…¦á„‹á…µá„á…¥L/selectstar\")\n",
    "\n",
    "file_name = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json')\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    multiple = json.load(f)\n",
    "\n",
    "classifier = qna_subdomain_classifier.QnASubdomainClassifier()\n",
    "classifier.save_statistics(multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ì²˜ìŒ subdomain ëŒë¦¬ê³  ì˜ëª» ë¶€ì—¬ëœ subdomain ì¡°ì •\n",
    "# for m in multiple:\n",
    "#     if m['subdomain'].count('-') >= 1:\n",
    "#         # print(m)\n",
    "#         # break\n",
    "#         m['subdomain'] = m['subdomain'].split('-')[0].strip()\n",
    "#         # print(m)\n",
    "#         # break\n",
    "#     elif m['subdomain'].count('.') >= 1:\n",
    "#         m['subdomain'] = m['subdomain'].split('.')[1].strip()\n",
    "        \n",
    "\n",
    "# classifier.save_statistics(multiple)\n",
    "#     # print(\"ì—†ëŠ”ë°?\", m['subdomain'])\n",
    "\n",
    "# with open(file_name, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(multiple, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(file_name, 'r', encoding='utf-8') as f:\n",
    "#     multiple = json.load(f)\n",
    "\n",
    "# for m in multiple:\n",
    "#     m['domain'] = \"\"\n",
    "#     m['subdomain'] = \"\"\n",
    "#     m['classification_reason'] = \"\"\n",
    "#     m['is_calculation'] = False\n",
    "\n",
    "# with open('/Users/jinym/Desktop/Desktop_AICenterâœ¨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(multiple, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ê°ê´€ì‹ ë¬¸ì œ ë³€í˜•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "ONEDRIVE_PATH = os.path.join(os.path.expanduser(\"~\"), \"Library/CloudStorage/OneDrive-á„€á…¢á„‹á…µá†«/á„ƒá…¦á„‹á…µá„á…¥L/selectstar\")\n",
    "EXAM_DIR = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data/4_multiple_exam')\n",
    "\n",
    "for exams in os.listdir(EXAM_DIR):\n",
    "    if exams == \"1st\":\n",
    "        first_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "            with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "                first_exam += json.load(f)\n",
    "    elif exams == \"2nd\":\n",
    "        second_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "            with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "                second_exam += json.load(f)\n",
    "    elif exams == \"3rd\":\n",
    "        third_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "            with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "                third_exam += json.load(f)\n",
    "    elif exams == \"4th\":\n",
    "        fourth_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "            with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "                fourth_exam += json.load(f)\n",
    "    elif exams == \"5th\":\n",
    "        fifth_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "            with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "                fifth_exam += json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´: 4957\n",
      "ì˜³ì€ ê²ƒì€? (ë‹¨ì¼ ì„ íƒ): 1963\n",
      "ì˜³ì§€ ì•Šì€ ê²ƒì€? (ë‹¨ì¼ ì„ íƒ): 2672\n",
      "ì˜³ì€ ê²ƒì„ ëª¨ë‘ ê³ ë¥¸ ê²ƒì€? (ë‹¤ì¤‘ ì„ íƒ): 322\n",
      "ê°¯ìˆ˜ ì¼ì¹˜ ì—¬ë¶€: True\n"
     ]
    }
   ],
   "source": [
    "multiple = first_exam + second_exam + third_exam + fourth_exam + fifth_exam\n",
    "\n",
    "pick_right = []\n",
    "pick_wrong = []\n",
    "pick_abcd = []\n",
    "\n",
    "# ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•˜ë©´ì„œ remove()ë¥¼ í•˜ë©´ ì¸ë±ìŠ¤ê°€ ê¼¬ì´ë¯€ë¡œ, ìƒˆë¡œ ë¶„ë¥˜í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½\n",
    "# remaining = []\n",
    "for m in multiple:\n",
    "    question = m['question']\n",
    "    \n",
    "    # 3. ã„±/ã„´/ã„·/ã„¹ ë“±ì—ì„œ ì˜³ì€ ê²ƒì„ ëª¨ë‘ ê³ ë¥´ëŠ” ë¬¸ì œ (ë‹¤ì¤‘ ì„ íƒ)\n",
    "    # ì¢…ê²°ì–´ë¯¸ 'ë‹¤.' ì œì™¸: ì¤„ë°”ê¿ˆ, ë¬¸ì¥ ì‹œì‘, ë˜ëŠ” ê³µë°± í›„ì— ë‚˜ì˜¤ê³  ë’¤ì— ê³µë°±ì´ ì•„ë‹Œ ë¬¸ìê°€ ì˜¤ëŠ” ê²½ìš°ë§Œ ë§¤ì¹­\n",
    "    # ê°€ë‚˜ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜ê¹Œì§€ í¬í•¨ (ë°”, ì‚¬, ì•„ ë“±ë„ í¬í•¨)\n",
    "    if  ('ë³´ê¸°' in question) or \\\n",
    "        ('ì˜³ì€ ê²ƒì„ ëª¨ë‘ ê³ ë¥¸ ê²ƒì€?' in question) or \\\n",
    "         ('ì˜³ì€ ê²ƒì„ ëª¨ë‘ ê³ ë¥´ë©´?' in question) or \\\n",
    "         ('ì˜³ì€ ê²ƒì„ ëª¨ë‘ ê³ ë¥¸ ê²ƒì€' in question) or \\\n",
    "         ('ì˜³ì€ ê²ƒì„ ëª¨ë‘' in question and '?' in question) or \\\n",
    "         ('ëª¨ë‘ ê³ ë¥¸ ê²ƒì€?' in question) or \\\n",
    "         ('ëª¨ë‘ ê³ ë¥´ë©´?' in question) or \\\n",
    "         ('ëª¨ë‘ ê³ ë¥¸ ê²ƒì€' in question) or \\\n",
    "         ('ëª¨ë‘ ë¬¶ì¸ ê²ƒì€?' in question) or \\\n",
    "         (re.search(r'[ã„±ã„´ã„·ã„¹][\\.]', question) and ('ëª¨ë‘ ê³ ë¥¸' in question or 'ëª¨ë‘ ë¬¶ì¸' in question)) or \\\n",
    "         (re.search(r'(?:^|\\n| )[ê°€ë‚˜ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜]\\.(?!\\s|$)', question) and ('ëª¨ë‘ ê³ ë¥¸' in question or 'ëª¨ë‘ ë¬¶ì¸' in question)) or \\\n",
    "         (re.search(r'[ã‰ ã‰¡ã‰¢ã‰£ã‰¤]', question) and ('ëª¨ë‘ ê³ ë¥¸' in question or 'ëª¨ë‘ ë¬¶ì¸' in question)) or \\\n",
    "         (re.search(r'[â“â“‘â“’â““â“”]', question) and ('ëª¨ë‘ ê³ ë¥¸' in question or 'ëª¨ë‘ ë¬¶ì¸' in question)):\n",
    "        pick_abcd.append(m)\n",
    "    # 1. ì˜³ì€ ê²ƒì„ ê³ ë¥´ëŠ” ë¬¸ì œ (ë‹¨ì¼ ì„ íƒ)\n",
    "    # if ('ì˜³ì€' in question) or ('ì˜³ê²Œ' in question) or ('í•´ë‹¹í•˜ëŠ”' in question) or ('ì ì ˆí•œ' in question) or ('ì ì ˆí•˜ê²Œ' in question) or ('ë°”ë¥´ê²Œ' in question) or ('ì˜¬ë°”ë¥¸' in question) or ('ê°€ì¥ ê¹Šì€' in question) or ('ê°€ì¥ íƒ€ë‹¹í•œ' in question) or ('ê´€ë ¨ ìˆëŠ”' in question):\n",
    "    #     pick_right.append(m)\n",
    "    # 2. ì˜³ì§€ ì•Šì€ ê²ƒì„ ê³ ë¥´ëŠ” ë¬¸ì œ (ë‹¨ì¼ ì„ íƒ)\n",
    "    elif ('ì•Šì€' in question) or ('ëª»í•œ' in question) or ('ì—†ëŠ”' in question) or ('ê±°ë¦¬ê°€ ë¨¼' in question) or ('ì•„ë‹Œ' in question) or ('ì•„ë‹ˆí•˜ëŠ” ê²ƒ' in question) or ('ì•ŠëŠ”' in question) or (\"ì•Šê²Œ\" in question) or ('ì˜ëª»ëœ' in question) or ('í‹€ë¦°' in question) or ('ë‹¤ë¥¸' in question) or ('ë¬´ê´€í•œ' in question) or ('ê°€ì¥ ë¨¼' in question) or ('ì–´ë ¤ìš´' in question):\n",
    "        pick_wrong.append(m)\n",
    "    else:\n",
    "        # ë¶„ë¥˜ë˜ì§€ ì•Šì€ í•­ëª©\n",
    "        # remaining.append(m)\n",
    "        pick_right.append(m)\n",
    "\n",
    "# ë¶„ë¥˜ ê²°ê³¼ í™•ì¸\n",
    "print(f\"ì „ì²´: {len(multiple)}\")\n",
    "print(f\"ì˜³ì€ ê²ƒì€? (ë‹¨ì¼ ì„ íƒ): {len(pick_right)}\")\n",
    "print(f\"ì˜³ì§€ ì•Šì€ ê²ƒì€? (ë‹¨ì¼ ì„ íƒ): {len(pick_wrong)}\")\n",
    "print(f\"ì˜³ì€ ê²ƒì„ ëª¨ë‘ ê³ ë¥¸ ê²ƒì€? (ë‹¤ì¤‘ ì„ íƒ): {len(pick_abcd)}\")\n",
    "# print(f\"ë¯¸ë¶„ë¥˜: {len(remaining)}\")\n",
    "print(f\"ê°¯ìˆ˜ ì¼ì¹˜ ì—¬ë¶€: {len(pick_right) + len(pick_wrong) + len(pick_abcd) == len(multiple)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì˜³ì§€ ì•Šì€ ê²ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "ë‹¹ì‹ ì€ 15ë…„ ê²½ë ¥ì˜ ë¬¸ì œ ì¶œì œ ê²½í—˜ì´ ë›°ì–´ë‚œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒ ë¬¸ì œëŠ” ì˜³ì§€ ì•Šì€ ê²ƒì„ ê³ ë¥´ëŠ” ë¬¸ì œì´ê³ , ì˜³ì€ ê²ƒì„ ê³ ë¥´ëŠ” ë¬¸ì œë¡œ ë³€í˜•í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "ì£¼ì–´ì§„ ë‹µê³¼ í•´ì„¤ì„ ë³´ê³  ë‹µì„ ì˜³ì€ ì„ íƒì§€ë¡œ ë³€í˜•í•˜ì„¸ìš”.\n",
    "ì´ë•Œ ë³€í˜•ì€ ì •ë‹µì¸ ì„ íƒì§€ì˜ ë‹¨ì–´ë¥¼ ë°”ê¿” ìµœì†Œí™”í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. (ex. ë†’ì€ -> ë‚®ì€, ì—†ë‹¤ -> ìˆë‹¤)\n",
    "\n",
    "### ì¶œë ¥í˜•ì‹\n",
    "[ {\n",
    "\"question_id\": \"ë¬¸ì œë²ˆí˜¸\",\n",
    "\"question\": \"ë¬¸ì œ\",\n",
    "\"options\": \"ì„ íƒì§€\",\n",
    "\"answer\": \"ë‹µ\",\n",
    "\"explanation\": \"í•´ì„¤\"\n",
    "}, \n",
    "{\n",
    "\"question_id\": \"ë¬¸ì œë²ˆí˜¸\",\n",
    "\"question\": \"ë¬¸ì œ\",\n",
    "\"options\": \"ì„ íƒì§€\",\n",
    "\"answer\": \"ë‹µ\",\n",
    "\"explanation\": \"í•´ì„¤\"\n",
    "}\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# random.seed(42)\n",
    "user_prompt = ''\n",
    "\n",
    "to_json = []\n",
    "\n",
    "\n",
    "for i, p in enumerate(random.sample(pick_wrong, 30)):\n",
    "    question_id = p['file_id'] + '_' + p['tag']\n",
    "    question = p['question']\n",
    "    options = p['options']\n",
    "    answer = p['answer']\n",
    "    explanation = p['explanation']\n",
    "\n",
    "    single_user_prompt = f\"\"\"ë¬¸ì œë²ˆí˜¸: {question_id}\n",
    "ë¬¸ì œ: {question}\n",
    "ì„ íƒì§€: {options}\n",
    "ë‹µ: {answer}\n",
    "í•´ì„¤: {explanation}\n",
    "=====================\n",
    "\"\"\"\n",
    "    to_json.append(\n",
    "        {\n",
    "            \"question_id\": question_id,\n",
    "            \"question\": question,\n",
    "            \"options\": options,\n",
    "            \"answer\": answer,\n",
    "            \"explanation\": explanation\n",
    "        }\n",
    "    )\n",
    "\n",
    "    user_prompt += single_user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONEDRIVE_PATH = os.path.join(os.path.expanduser(\"~\"), \"Library/CloudStorage/OneDrive-á„€á…¢á„‹á…µá†«/á„ƒá…¦á„‹á…µá„á…¥L/selectstar\")\n",
    "BASE_DIR = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data/5_multiple_rw')\n",
    "\n",
    "with open(os.path.join(BASE_DIR, 'wrong','multiple_1wrong.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(to_json, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/aic/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-09 21:33:42 [__init__.py:216] Automatically detected platform cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 21:33:44,177 - INFO - ì¶œë ¥ ë””ë ‰í† ë¦¬: /Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/evaluation_yejin/eval_data/multiple_with_subdomain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/tools\n",
      "/Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/tools\n",
      "[DEBUG] Config file path: /Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/llm_config.ini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 21:33:44,888 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from tools.QueryModels import query_openrouter\n",
    "from tools.evaluation import qna_subdomain_classifier\n",
    "\n",
    "classifier = qna_subdomain_classifier.QnASubdomainClassifier()\n",
    "\n",
    "# for model_path in ['anthropic/claude-sonnet-4.5', 'openai/o3', 'google/gemini-2.5-pro']:\n",
    "for model_path in ['openai/gpt-5']:\n",
    "    model_name = model_path.split('/')[-1]\n",
    "    company = model_path.split('/')[0]\n",
    "\n",
    "    response = query_openrouter(system_prompt, user_prompt, model_name=model_path)\n",
    "    response = classifier.parse_api_response(response)\n",
    "    \n",
    "    with open(os.path.join(BASE_DIR, 'wrong', f'multiple_5right_{model_name}.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(response, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì´ì œ ì „ë¶€ ì˜³ì€ ê²ƒì„! -> ì „ë¶€ ì˜³ì§€ ì•Šì€ ê²ƒìœ¼ë¡œ ë°”ê¾¸ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "ë‹¹ì‹ ì€ 15ë…„ ê²½ë ¥ì˜ ë¬¸ì œ ì¶œì œ ê²½í—˜ì´ ë›°ì–´ë‚œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒ ë¬¸ì œëŠ” ì„ íƒì§€ê°€ ëª¨ë‘ ì˜³ì€ ê²ƒìœ¼ë¡œ, ëª¨ë‘ ì˜³ì§€ ì•Šì€ ì„ ì§€ë¡œ ë³€í˜•í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "ì£¼ì–´ì§„ ì„ íƒì§€ë“¤ê³¼ í•´ì„¤ì„ ë³´ê³ , ë¬¸ì¥ì˜ ì—­/ì´/ëŒ€ìš°ë¥¼ í™œìš©í•˜ì—¬ ì˜³ì§€ ì•Šì€ ì„ íƒì§€ë¡œ ë³€í˜•í•˜ì„¸ìš”.\n",
    "ì´ë•Œ ë³€í˜•ì€ ì„ íƒì§€ì˜ ë‹¨ì–´ë¥¼ ë°”ê¿” í• ë£¨ì‹œë„¤ì´ì…˜ì„ ìµœì†Œí™”í•´ì•¼ í•©ë‹ˆë‹¤. (ex. ë†’ì€ -> ë‚®ì€, ì—†ë‹¤ -> ìˆë‹¤)\n",
    "\n",
    "### ì¶œë ¥í˜•ì‹\n",
    "[ {\n",
    "\"question_id\": \"ë¬¸ì œë²ˆí˜¸\",\n",
    "\"question\": \"ë¬¸ì œ\",\n",
    "\"options\": \"ì„ íƒì§€\",\n",
    "\"answer\": \"ë‹µ\",\n",
    "\"explanation\": \"í•´ì„¤\"\n",
    "}, \n",
    "{\n",
    "\"question_id\": \"ë¬¸ì œë²ˆí˜¸\",\n",
    "\"question\": \"ë¬¸ì œ\",\n",
    "\"options\": \"ì„ íƒì§€\",\n",
    "\"answer\": \"ë‹µ\",\n",
    "\"explanation\": \"í•´ì„¤\"\n",
    "}\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 21:42:30,553 - INFO - ì¶œë ¥ ë””ë ‰í† ë¦¬: /Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/evaluation_yejin/eval_data/multiple_with_subdomain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/tools\n",
      "[DEBUG] Config file path: /Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/llm_config.ini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 21:42:34,176 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/tools\n",
      "[DEBUG] Config file path: /Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/llm_config.ini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 21:44:54,706 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/tools\n",
      "[DEBUG] Config file path: /Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/llm_config.ini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 21:51:11,461 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/tools\n",
      "[DEBUG] Config file path: /Users/yejin/Desktop/Desktop_AICenterâœ¨/SFAIcenter/llm_config.ini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 21:52:01,272 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from tools.QueryModels import query_openrouter\n",
    "from tools.evaluation import qna_subdomain_classifier\n",
    "\n",
    "classifier = qna_subdomain_classifier.QnASubdomainClassifier()\n",
    "\n",
    "for model_path in ['google/gemini-2.5-pro', 'openai/gpt-5','anthropic/claude-sonnet-4.5', 'openai/o3']:\n",
    "    model_name = model_path.split('/')[-1]\n",
    "    company = model_path.split('/')[0]\n",
    "\n",
    "    user_prompt = ''\n",
    "    with open(os.path.join(BASE_DIR, 'wrong', f'multiple_5right_{model_name}.json'), 'r', encoding='utf-8') as f:\n",
    "        multiple_wrong = json.load(f)\n",
    "\n",
    "    for i, p in enumerate(multiple_wrong):\n",
    "        question_id = p['question_id']\n",
    "        question = p['question']\n",
    "        options = p['options']\n",
    "        answer = p['answer']\n",
    "        explanation = p['explanation']\n",
    "\n",
    "        single_user_prompt = f\"\"\"ë¬¸ì œë²ˆí˜¸: {question_id}\n",
    "    ë¬¸ì œ: {question}\n",
    "    ì„ íƒì§€: {options}\n",
    "    ë‹µ: {answer}\n",
    "    í•´ì„¤: {explanation}\n",
    "    =====================\n",
    "    \"\"\"\n",
    "\n",
    "        user_prompt += single_user_prompt\n",
    "\n",
    "    response = query_openrouter(system_prompt, user_prompt, model_name=model_path)\n",
    "    response = classifier.parse_api_response(response)\n",
    "    \n",
    "    with open(os.path.join(BASE_DIR, 'wrong', f'multiple_5wrong_{model_name}.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(response, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì˜³ì€ ê²ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "for p in pick_right[:10]:\n",
    "    new.append(\n",
    "        {\n",
    "            \"question_id\": p['file_id'] + '_' + p['tag'],\n",
    "            \"question\": p['question'],\n",
    "            \"options\": p['options'],\n",
    "            \"answer\": p['answer'],\n",
    "            \"explanation\": p['explanation']\n",
    "        }\n",
    "    )\n",
    "with open('multiple_right.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(new, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë„ë©”ì¸ë³„ í†µê³„ ê³„ì‚°\n",
    "from collections import defaultdict\n",
    "\n",
    "calculation = defaultdict(int)  # ê³„ì‚° ë¬¸ì œ ê°œìˆ˜\n",
    "total_by_domain = defaultdict(int)  # ì „ì²´ ë¬¸ì œ ê°œìˆ˜\n",
    "\n",
    "for question in first_exam:\n",
    "    domain = question.get('domain', 'ë¯¸ë¶„ë¥˜')\n",
    "    total_by_domain[domain] += 1\n",
    "    if question.get('is_calculation') == True:\n",
    "        calculation[domain] += 1\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=\" * 60)\n",
    "print(\"ë„ë©”ì¸ë³„ í†µê³„\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'ë„ë©”ì¸':<20} {'ì „ì²´':<10} {'ê³„ì‚°ë¬¸ì œ':<10} {'ë¹„ìœ¨':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for domain in sorted(total_by_domain.keys()):\n",
    "    total = total_by_domain[domain]\n",
    "    calc_count = calculation[domain]\n",
    "    ratio = (calc_count / total * 100) if total > 0 else 0\n",
    "    print(f\"{domain:<20} {total:<10} {calc_count:<10} {ratio:.2f}%\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'í•©ê³„':<20} {sum(total_by_domain.values()):<10} {sum(calculation.values()):<10} {sum(calculation.values())/sum(total_by_domain.values())*100:.2f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel íŒŒì¼ì—ì„œ ì •í™•ë„ ê³„ì‚° (ì „ì²´, subjectë³„, domainë³„, subdomainë³„)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Set\n",
    "import ast\n",
    "\n",
    "# Excel íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "excel_path = '/home/yjmoon/Library/CloudStorage/OneDrive-ê°œì¸/ë°ì´í„°L/selectstar/evaluation/eval_data/6_exam_evaluation/1st_evaluation_EXAONE-4.0-32B.xlsx'\n",
    "\n",
    "# Excel íŒŒì¼ ì½ê¸°\n",
    "df_sample = pd.read_excel(excel_path, sheet_name='ì „ì²´ë°ì´í„°')\n",
    "pred_long = pd.read_excel(excel_path, sheet_name='ëª¨ë¸ë³„ì˜ˆì¸¡')\n",
    "\n",
    "# answer_setì„ Set[int]ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜\n",
    "def _parse_answer_set(answer_set):\n",
    "    if isinstance(answer_set, set):\n",
    "        return answer_set\n",
    "    elif isinstance(answer_set, str):\n",
    "        try:\n",
    "            # ë¬¸ìì—´ì„ íŒŒì‹±í•´ì„œ Set[int]ë¡œ ë³€í™˜\n",
    "            parsed = ast.literal_eval(answer_set)\n",
    "            if isinstance(parsed, set):\n",
    "                return parsed\n",
    "            elif isinstance(parsed, (list, tuple)):\n",
    "                return set(parsed)\n",
    "            else:\n",
    "                return {int(parsed)}\n",
    "        except:\n",
    "            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¹ˆ ì§‘í•© ë°˜í™˜\n",
    "            return set()\n",
    "    else:\n",
    "        # ìˆ«ìë‚˜ ë‹¤ë¥¸ íƒ€ì…ì¸ ê²½ìš°\n",
    "        try:\n",
    "            return {int(answer_set)}\n",
    "        except:\n",
    "            return set()\n",
    "\n",
    "# ì •ë‹µ ì—¬ë¶€ ê³„ì‚° í•¨ìˆ˜\n",
    "def _is_correct(pred: float, s: Set[int]) -> float:\n",
    "    if np.isnan(pred) or not s:\n",
    "        return np.nan\n",
    "    return float(int(pred) in s)\n",
    "\n",
    "# ë°ì´í„° ë³‘í•© ë° ì •í™•ë„ ê³„ì‚°\n",
    "key = df_sample[[\"id\", \"answer_set\"]].copy()\n",
    "merged = pred_long.merge(key, on=\"id\", how=\"left\")\n",
    "merged[\"answer_set\"] = merged[\"answer_set\"].apply(_parse_answer_set)\n",
    "merged[\"correct\"] = merged.apply(lambda r: _is_correct(r[\"answer\"], r[\"answer_set\"]), axis=1)\n",
    "\n",
    "# ì „ì²´ ì •í™•ë„ ê³„ì‚°\n",
    "acc_by_model = (\n",
    "    merged.groupby(\"model_name\", dropna=False)[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"correct\": \"accuracy\"})\n",
    "    .sort_values(\"accuracy\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“Š ì „ì²´ ì •í™•ë„\")\n",
    "print(\"=\" * 80)\n",
    "for _, row in acc_by_model.iterrows():\n",
    "    print(f\"  {row['model_name']}: {row['accuracy']:.3f} ({row['accuracy']*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# subjectë³„ ì •í™•ë„ ê³„ì‚° (subject ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)\n",
    "if 'subject' in df_sample.columns:\n",
    "    subject_info = df_sample[[\"id\", \"subject\"]].copy()\n",
    "    merged_with_subject = merged.merge(subject_info, on=\"id\", how=\"left\")\n",
    "    \n",
    "    subject_acc = (\n",
    "        merged_with_subject.groupby([\"subject\", \"model_name\"], dropna=False)[\"correct\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .pivot(index=\"subject\", columns=\"model_name\", values=\"correct\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“š Subjectë³„ ì •í™•ë„\")\n",
    "    print(\"=\" * 80)\n",
    "    print(subject_acc.to_string(index=False))\n",
    "    print()\n",
    "    \n",
    "    # Subjectë³„ ë¬¸ì œ ìˆ˜ í†µê³„\n",
    "    subject_stats = df_sample.groupby('subject').size().reset_index(name='question_count')\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“ˆ Subjectë³„ ë¬¸ì œ ìˆ˜\")\n",
    "    print(\"=\" * 80)\n",
    "    print(subject_stats.to_string(index=False))\n",
    "    print()\n",
    "\n",
    "# domainë³„ ì •í™•ë„ ê³„ì‚° (domain ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)\n",
    "if 'domain' in df_sample.columns:\n",
    "    domain_info = df_sample[[\"id\", \"domain\"]].copy()\n",
    "    merged_with_domain = merged.merge(domain_info, on=\"id\", how=\"left\")\n",
    "    \n",
    "    domain_acc = (\n",
    "        merged_with_domain.groupby([\"domain\", \"model_name\"], dropna=False)[\"correct\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .pivot(index=\"domain\", columns=\"model_name\", values=\"correct\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ† Domainë³„ ì •í™•ë„\")\n",
    "    print(\"=\" * 80)\n",
    "    print(domain_acc.to_string(index=False))\n",
    "    print()\n",
    "    \n",
    "    # Domainë³„ ë¬¸ì œ ìˆ˜ í†µê³„\n",
    "    domain_stats = df_sample.groupby('domain').size().reset_index(name='question_count')\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“ˆ Domainë³„ ë¬¸ì œ ìˆ˜\")\n",
    "    print(\"=\" * 80)\n",
    "    print(domain_stats.to_string(index=False))\n",
    "    print()\n",
    "\n",
    "# subdomainë³„ ì •í™•ë„ ê³„ì‚° (subdomain ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)\n",
    "if 'subdomain' in df_sample.columns:\n",
    "    subdomain_info = df_sample[[\"id\", \"domain\", \"subdomain\"]].copy()\n",
    "    merged_with_subdomain = merged.merge(subdomain_info, on=\"id\", how=\"left\")\n",
    "    \n",
    "    subdomain_acc = (\n",
    "        merged_with_subdomain.groupby([\"domain\", \"subdomain\", \"model_name\"], dropna=False)[\"correct\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .pivot(index=[\"domain\", \"subdomain\"], columns=\"model_name\", values=\"correct\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“‹ Subdomainë³„ ì •í™•ë„\")\n",
    "    print(\"=\" * 80)\n",
    "    print(subdomain_acc.to_string(index=False))\n",
    "    print()\n",
    "    \n",
    "    # Subdomainë³„ ë¬¸ì œ ìˆ˜ í†µê³„\n",
    "    subdomain_stats = df_sample.groupby(['domain', 'subdomain']).size().reset_index(name='question_count')\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“ˆ Subdomainë³„ ë¬¸ì œ ìˆ˜\")\n",
    "    print(\"=\" * 80)\n",
    "    print(subdomain_stats.to_string(index=False))\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"âœ… ì •í™•ë„ ê³„ì‚° ì™„ë£Œ\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
