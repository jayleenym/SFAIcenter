{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운거 빈 도메인만..\n",
    "\n",
    "!python hhhhh.py multiple-fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple options 오류들\n",
    "- find_multiple_choice_invalid_options.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원본에 옮기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, time\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# file_list = []\n",
    "\n",
    "# for t in tqdm(to_multiple):\n",
    "#     file_id = t.get('file_id')\n",
    "#     file_list.append(file_id)\n",
    "#     # print(file_id)\n",
    "#     tag = t.get('tag')\n",
    "#     time.sleep(0.5)\n",
    "        \n",
    "#     file_path = os.popen(f\"find /Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/data/FINAL -type f -name '{file_id}_v2.json'\").read().strip()\n",
    "#     if file_path == \"\":\n",
    "#         file_path = os.popen(f\"find /Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/data/FINAL -type f -name '{file_id}.json'\").read().strip()\n",
    "#     # print(file_path)\n",
    "\n",
    "#     with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "    \n",
    "#     contents = data['contents']\n",
    "\n",
    "#     for d in contents:\n",
    "#         if d.get('page') == tag.split('_')[1]:\n",
    "#             add_info = d.get('add_info')\n",
    "#             for info in add_info:\n",
    "#                 if info.get('tag') == tag:\n",
    "#                     if info.get('description').get('question') == t.get('question'):\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         # print(\"질문 다름\")\n",
    "#                         info['description']['question'] = t.get('question')\n",
    "\n",
    "#                     if info.get('description').get('answer') == t.get('answer'):\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         # print(\"답 다름\")\n",
    "#                         info['description']['answer'] = t.get('answer')\n",
    "#                     if info.get('description').get('options') == t.get('options'):\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         # print(\"옵션 다름\")\n",
    "#                         info['description']['options'] = t.get('options')\n",
    "#     if file_path.endswith(\"_v2.json\"):\n",
    "#         with open(file_path, 'w', encoding='utf-8') as f:\n",
    "#             json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "#     else:\n",
    "#         with open(file_path.replace(\".json\", \"_v2.json\"), 'w', encoding='utf-8') as f:\n",
    "#             json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(list(set(file_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from tools.qna.processing.qna_subdomain_classifier import QnASubdomainClassifier\n",
    "from tools.pipeline.config import ONEDRIVE_PATH\n",
    "\n",
    "# file_name = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json')\n",
    "file_name = os.path.join(ONEDRIVE_PATH, 'evaluation', 'eval_data', '2_subdomain', 'multiple_subdomain_classified_ALL.json')\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    multiple = json.load(f)\n",
    "\n",
    "classifier = QnASubdomainClassifier()\n",
    "classifier.save_statistics(multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도메인별 통계 계산\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "calculation = defaultdict(int)  # 계산 문제 개수\n",
    "total_by_domain = defaultdict(int)  # 전체 문제 개수\n",
    "\n",
    "for question in fifth_exam:\n",
    "    domain = question.get('domain', '미분류')\n",
    "    total_by_domain[domain] += 1\n",
    "    if question.get('is_calculation') == True:\n",
    "        calculation[domain] += 1\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=\" * 60)\n",
    "print(\"도메인별 통계\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'도메인':<20} {'전체':<10} {'계산문제':<10} {'비율':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for domain in sorted(total_by_domain.keys()):\n",
    "    total = total_by_domain[domain]\n",
    "    calc_count = calculation[domain]\n",
    "    ratio = (calc_count / total * 100) if total > 0 else 0\n",
    "    print(f\"{domain:<20} {total:<10} {calc_count:<10} {ratio:.2f}%\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'합계':<20} {sum(total_by_domain.values()):<10} {sum(calculation.values()):<10} {sum(calculation.values())/sum(total_by_domain.values())*100:.2f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python tools/main_pipeline.py --steps evaluate_exams --eval_sets 5 --eval_models google/gemini-2.5-pro openai/gpt-5 anthropic/claude-sonnet-4.5 google/gemini-2.5-flash anthropic/claude-3.7-sonnet openai/gpt-4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation 파일 수정하고 다시 돌리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "from tools.pipeline.config import ONEDRIVE_PATH\n",
    "\n",
    "EXAM_DIR = os.path.join(ONEDRIVE_PATH, 'evaluation','eval_data','4_multiple_exam')\n",
    "# EXAM_DIR = os.path.join(os.path.expanduser(\"~\"), '4_multiple_exam')\n",
    "\n",
    "for exams in os.listdir(EXAM_DIR):\n",
    "    if exams == \"1st\":\n",
    "        first_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, 'backup', exams)):\n",
    "            with open(os.path.join(EXAM_DIR, 'backup', exams, exam), 'r', encoding='utf-8') as f:\n",
    "                first_exam += json.load(f)\n",
    "    elif exams == \"2nd\":\n",
    "        second_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, 'backup', exams)):\n",
    "            with open(os.path.join(EXAM_DIR, 'backup', exams, exam), 'r', encoding='utf-8') as f:\n",
    "                second_exam += json.load(f)\n",
    "    elif exams == \"3rd\":\n",
    "        third_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, 'backup', exams)):\n",
    "            with open(os.path.join(EXAM_DIR, 'backup', exams, exam), 'r', encoding='utf-8') as f:\n",
    "                third_exam += json.load(f)\n",
    "    elif exams == \"4th\":\n",
    "        fourth_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, 'backup', exams)):\n",
    "            with open(os.path.join(EXAM_DIR, 'backup', exams, exam), 'r', encoding='utf-8') as f:\n",
    "                fourth_exam += json.load(f)\n",
    "    if exams == \"5th\":\n",
    "        fifth_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "            with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "                fifth_exam += json.load(f)\n",
    "\n",
    "# multiple = first_exam + second_exam + third_exam + fourth_exam + fifth_exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tools.pipeline.config import ONEDRIVE_PATH\n",
    "\n",
    "time = '5th'\n",
    "model_name = 'gemini-3-pro-preview'\n",
    "excel_path = os.path.join(ONEDRIVE_PATH, f'evaluation/eval_data/4_multiple_exam/exam_result/{time}/{time}_evaluation_{model_name}.xlsx')\n",
    "print(excel_path)\n",
    "pred_wide = pd.read_excel(excel_path, sheet_name='모델별예측')\n",
    "\n",
    "\n",
    "exams = {\n",
    "    '1st': first_exam,\n",
    "    '2nd': second_exam,\n",
    "    '3rd': third_exam,\n",
    "    '4th': fourth_exam,\n",
    "    '5th': fifth_exam\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_ids = pred_wide[pred_wide[pred_wide.columns[-1]].isna()].id.tolist()\n",
    "print(pred_wide.columns[-1])\n",
    "print(empty_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_json = []\n",
    "for q in empty_ids:\n",
    "    for m in exams[time]:\n",
    "        if m['file_id']+\"_\"+m['tag'] == q:\n",
    "            # print(m)\n",
    "            new_json.append(m)\n",
    "\n",
    "print(len(new_json) == len(empty_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(os.path.join(ONEDRIVE_PATH, 'evaluation/model_new.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(new_json, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/main_pipeline.py --steps evaluate_exams --eval_exam_dir evaluation/model_new.json --eval_models google/gemini-3-pro-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel 파일에서 정확도 계산 (전체, subject별, domain별, subdomain별)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Set\n",
    "import ast\n",
    "\n",
    "# Excel 파일 경로 설정\n",
    "# excel_path = f'/Users/yejin/Downloads/2nd_evaluation_ALL.xlsx'\n",
    "\n",
    "# Excel 파일 읽기\n",
    "df_sample = pd.read_excel(excel_path, sheet_name='전체데이터')\n",
    "pred_wide = pd.read_excel(excel_path, sheet_name='모델별예측')\n",
    "\n",
    "# pred_wide를 pred_long 형식으로 변환 (melt 사용)\n",
    "# pred_wide는 id 컬럼과 각 모델명이 컬럼으로 있는 와이드 포맷\n",
    "# pred_long은 id, model_name, answer 컬럼이 있는 롱 포맷\n",
    "pred_long = pred_wide.melt(\n",
    "    id_vars=['id'],  # id 컬럼은 그대로 유지\n",
    "    var_name='model_name',  # 모델명 컬럼 이름\n",
    "    value_name='answer'  # 예측값 컬럼 이름\n",
    ")\n",
    "\n",
    "# answer_set을 Set[int]로 변환하는 헬퍼 함수\n",
    "def _parse_answer_set(answer_set):\n",
    "    if isinstance(answer_set, set):\n",
    "        return answer_set\n",
    "    elif isinstance(answer_set, str):\n",
    "        try:\n",
    "            # 문자열을 파싱해서 Set[int]로 변환\n",
    "            parsed = ast.literal_eval(answer_set)\n",
    "            if isinstance(parsed, set):\n",
    "                return parsed\n",
    "            elif isinstance(parsed, (list, tuple)):\n",
    "                return set(parsed)\n",
    "            else:\n",
    "                return {int(parsed)}\n",
    "        except:\n",
    "            # 파싱 실패 시 빈 집합 반환\n",
    "            return set()\n",
    "    else:\n",
    "        # 숫자나 다른 타입인 경우\n",
    "        try:\n",
    "            return {int(answer_set)}\n",
    "        except:\n",
    "            return set()\n",
    "\n",
    "# 정답 여부 계산 함수\n",
    "def _is_correct(pred: float, s: Set[int]) -> float:\n",
    "    if np.isnan(pred) or not s:\n",
    "        return np.nan\n",
    "    return float(int(pred) in s)\n",
    "\n",
    "# 데이터 병합 및 정확도 계산\n",
    "key = df_sample[[\"id\", \"answer_set\"]].copy()\n",
    "merged = pred_long.merge(key, on=\"id\", how=\"left\")\n",
    "merged[\"answer_set\"] = merged[\"answer_set\"].apply(_parse_answer_set)\n",
    "merged[\"correct\"] = merged.apply(lambda r: _is_correct(r[\"answer\"], r[\"answer_set\"]), axis=1)\n",
    "\n",
    "# 전체 정확도 계산\n",
    "acc_by_model = (\n",
    "    merged.groupby(\"model_name\", dropna=False)[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"correct\": \"accuracy\"})\n",
    "    .sort_values(\"accuracy\", ascending=False)\n",
    ")\n",
    "\n",
    "# Excel 파일에 결과 저장\n",
    "# 기존 파일을 읽어서 모든 시트를 유지하면서 특정 시트만 업데이트\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# 기존 파일의 모든 시트 읽기 (업데이트할 시트 제외)\n",
    "existing_sheets = {}\n",
    "try:\n",
    "    book = load_workbook(excel_path)\n",
    "    for sheet_name in book.sheetnames:\n",
    "        if sheet_name not in [\"전체데이터\", \"모델별예측\", \"정확도\", \"Subject별정확도\", \"Subject별문제수\", \n",
    "                              \"Domain별정확도\", \"Domain별문제수\", \"Subdomain별정확도\", \"Subdomain별문제수\"]:\n",
    "            # 업데이트할 시트가 아닌 경우 기존 데이터 읽기\n",
    "            existing_sheets[sheet_name] = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# 모든 시트를 새 파일로 저장\n",
    "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode='w') as writer:\n",
    "    # 기존 시트 유지\n",
    "    for sheet_name, df in existing_sheets.items():\n",
    "        df.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "    # 기본 시트들 업데이트\n",
    "    df_sample.to_excel(writer, index=False, sheet_name=\"전체데이터\")\n",
    "    pred_wide.to_excel(writer, index=False, sheet_name=\"모델별예측\")\n",
    "    acc_by_model.to_excel(writer, index=False, sheet_name=\"정확도\")\n",
    "    \n",
    "    # subject별 정확도 계산 및 저장 (subject 컬럼이 있는 경우)\n",
    "    if 'subject' in df_sample.columns:\n",
    "        subject_info = df_sample[[\"id\", \"subject\"]].copy()\n",
    "        merged_with_subject = merged.merge(subject_info, on=\"id\", how=\"left\")\n",
    "        \n",
    "        subject_acc = (\n",
    "            merged_with_subject.groupby([\"subject\", \"model_name\"], dropna=False)[\"correct\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .pivot(index=\"subject\", columns=\"model_name\", values=\"correct\")\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "        subject_acc.to_excel(writer, index=False, sheet_name=\"Subject별정확도\")\n",
    "        \n",
    "        # Subject별 문제 수 통계\n",
    "        subject_stats = df_sample.groupby('subject').size().reset_index(name='question_count')\n",
    "        subject_stats.to_excel(writer, index=False, sheet_name=\"Subject별문제수\")\n",
    "    \n",
    "    # domain별 정확도 계산 및 저장 (domain 컬럼이 있는 경우)\n",
    "    if 'domain' in df_sample.columns:\n",
    "        domain_info = df_sample[[\"id\", \"domain\"]].copy()\n",
    "        merged_with_domain = merged.merge(domain_info, on=\"id\", how=\"left\")\n",
    "        \n",
    "        domain_acc = (\n",
    "            merged_with_domain.groupby([\"domain\", \"model_name\"], dropna=False)[\"correct\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .pivot(index=\"domain\", columns=\"model_name\", values=\"correct\")\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "        domain_acc.to_excel(writer, index=False, sheet_name=\"Domain별정확도\")\n",
    "        \n",
    "        # Domain별 문제 수 통계\n",
    "        domain_stats = df_sample.groupby('domain').size().reset_index(name='question_count')\n",
    "        domain_stats.to_excel(writer, index=False, sheet_name=\"Domain별문제수\")\n",
    "    \n",
    "    # subdomain별 정확도 계산 및 저장 (subdomain 컬럼이 있는 경우)\n",
    "    if 'subdomain' in df_sample.columns:\n",
    "        subdomain_info = df_sample[[\"id\", \"domain\", \"subdomain\"]].copy()\n",
    "        merged_with_subdomain = merged.merge(subdomain_info, on=\"id\", how=\"left\")\n",
    "        \n",
    "        subdomain_acc = (\n",
    "            merged_with_subdomain.groupby([\"domain\", \"subdomain\", \"model_name\"], dropna=False)[\"correct\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .pivot(index=[\"domain\", \"subdomain\"], columns=\"model_name\", values=\"correct\")\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "        subdomain_acc.to_excel(writer, index=False, sheet_name=\"Subdomain별정확도\")\n",
    "        \n",
    "        # Subdomain별 문제 수 통계\n",
    "        subdomain_stats = df_sample.groupby(['domain', 'subdomain']).size().reset_index(name='question_count')\n",
    "        subdomain_stats.to_excel(writer, index=False, sheet_name=\"Subdomain별문제수\")\n",
    "\n",
    "print(f\"✅ Excel 파일 업데이트 완료: {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 한번에 읽고 한번에 정확도 뽑기\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "exam_+_result 디렉토리의 엑셀 파일들에서 정확도 시트를 읽고\n",
    "1st/2nd/3rd/4th/5th, 모델명, 정확도(소수점 넷째자리까지)를 출력하는 스크립트\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "def extract_evaluation_number(filename: str) -> Optional[str]:\n",
    "    \"\"\"파일명에서 평가 차수(1st, 2nd, 3rd, 4th, 5th) 추출\"\"\"\n",
    "    # 파일명에서 숫자와 st/nd/rd/th 패턴 찾기\n",
    "    pattern = r'(\\d+)(st|nd|rd|th)'\n",
    "    match = re.search(pattern, filename, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(0).lower()\n",
    "    return None\n",
    "\n",
    "def extract_model_name(filename: str) -> str:\n",
    "    \"\"\"파일명에서 모델명 추출\"\"\"\n",
    "    # 파일명에서 확장자 제거\n",
    "    basename = os.path.splitext(os.path.basename(filename))[0]\n",
    "    # \"evaluation_\" 이후의 부분을 모델명으로 추출\n",
    "    if 'evaluation_' in basename:\n",
    "        model_name = basename.split('evaluation_', 1)[1]\n",
    "        return model_name\n",
    "    return basename\n",
    "\n",
    "def read_accuracy_sheet(excel_path: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"엑셀 파일에서 '정확도' 시트 읽기\"\"\"\n",
    "    try:\n",
    "        # 먼저 시트 이름 확인\n",
    "        excel_file = pd.ExcelFile(excel_path)\n",
    "        sheet_names = excel_file.sheet_names\n",
    "        \n",
    "        # '정확도' 시트 찾기\n",
    "        accuracy_sheet = None\n",
    "        for sheet in sheet_names:\n",
    "            if '정확도' in sheet:\n",
    "                accuracy_sheet = sheet\n",
    "                break\n",
    "        \n",
    "        if accuracy_sheet is None:\n",
    "            print(f\"⚠️  {excel_path}: '정확도' 시트를 찾을 수 없습니다. (시트 목록: {sheet_names})\")\n",
    "            return None\n",
    "        \n",
    "        # 정확도 시트 읽기\n",
    "        df = pd.read_excel(excel_path, sheet_name=accuracy_sheet)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {excel_path} 읽기 오류: {e}\")\n",
    "        return None\n",
    "\n",
    "def print_accuracy_results(directory: str = \"oci_result\"):\n",
    "    \"\"\"디렉토리 내의 모든 엑셀 파일에서 정확도 정보 출력\"\"\"\n",
    "    base_path = Path(directory)\n",
    "    \n",
    "    if not base_path.exists():\n",
    "        print(f\"❌ 디렉토리를 찾을 수 없습니다: {directory}\")\n",
    "        return\n",
    "    \n",
    "    # 엑셀 파일 목록 가져오기\n",
    "    excel_files = sorted(base_path.glob(\"*.xlsx\"))\n",
    "    \n",
    "    if not excel_files:\n",
    "        print(f\"⚠️  {directory} 디렉토리에 엑셀 파일이 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"정확도 결과 출력 ({len(excel_files)}개 파일)\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    print(f\"{'차수':<8} {'모델명':<50} {'정확도':<15}\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for excel_file in excel_files:\n",
    "        # 평가 차수 추출\n",
    "        eval_number = extract_evaluation_number(excel_file.name)\n",
    "        if eval_number is None:\n",
    "            eval_number = \"N/A\"\n",
    "        \n",
    "        # 모델명 추출\n",
    "        model_name = extract_model_name(excel_file.name)\n",
    "        \n",
    "        # 정확도 시트 읽기\n",
    "        df_accuracy = read_accuracy_sheet(str(excel_file))\n",
    "        \n",
    "        if df_accuracy is not None and not df_accuracy.empty:\n",
    "            # 정확도 컬럼 찾기\n",
    "            accuracy_col = None\n",
    "            model_col = None\n",
    "            \n",
    "            # 가능한 정확도 컬럼 이름들\n",
    "            for col in df_accuracy.columns:\n",
    "                col_lower = str(col).lower()\n",
    "                if 'accuracy' in col_lower or '정확도' in col_lower or 'acc' in col_lower:\n",
    "                    accuracy_col = col\n",
    "                if 'model' in col_lower or '모델' in col_lower:\n",
    "                    model_col = col\n",
    "            \n",
    "            # 정확도 값 찾기\n",
    "            if accuracy_col:\n",
    "                # 각 행의 정확도 출력 (모델별로 여러 행이 있을 수 있음)\n",
    "                for idx, row in df_accuracy.iterrows():\n",
    "                    accuracy_value = row[accuracy_col]\n",
    "                    \n",
    "                    # 모델명이 시트에 있는 경우 사용\n",
    "                    if model_col and model_col in df_accuracy.columns:\n",
    "                        sheet_model_name = str(row[model_col])\n",
    "                    else:\n",
    "                        sheet_model_name = model_name\n",
    "                    \n",
    "                    # 정확도 값을 숫자로 변환\n",
    "                    try:\n",
    "                        if pd.isna(accuracy_value):\n",
    "                            continue\n",
    "                        accuracy_float = float(accuracy_value)\n",
    "                        accuracy_str = f\"{accuracy_float:.4f}\"\n",
    "                        \n",
    "                        results.append({\n",
    "                            'eval': eval_number,\n",
    "                            'model': sheet_model_name,\n",
    "                            'accuracy': accuracy_float\n",
    "                        })\n",
    "                        \n",
    "                        print(f\"{eval_number:<8} {sheet_model_name:<50} {accuracy_str:<15}\")\n",
    "                    except (ValueError, TypeError):\n",
    "                        continue\n",
    "            else:\n",
    "                # 정확도 컬럼을 찾지 못한 경우, 첫 번째 숫자 컬럼을 정확도로 간주\n",
    "                print(f\"⚠️  {excel_file.name}: 정확도 컬럼을 찾을 수 없습니다. (컬럼: {list(df_accuracy.columns)})\")\n",
    "        else:\n",
    "            print(f\"⚠️  {excel_file.name}: 정확도 데이터를 읽을 수 없습니다.\")\n",
    "    \n",
    "    print(f\"{'-'*80}\")\n",
    "    print(f\"\\n총 {len(results)}개 결과 출력 완료\\n\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     import sys\n",
    "    \n",
    "#     # 디렉토리 경로 설정\n",
    "#     # 명령줄 인자로 디렉토리 경로를 받을 수 있음\n",
    "#     if len(sys.argv) > 1:\n",
    "#         result_dir = sys.argv[1]\n",
    "#     else:\n",
    "#         # 기본값: exam_+_result 또는 oci_result\n",
    "#         # 사용자가 원하는 디렉토리 경로로 변경 가능\n",
    "#         result_dir = \"oci_result\"  # 또는 \"exam_+_result\" 등\n",
    "    \n",
    "#     print_accuracy_results(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "정확도 결과 출력 (20개 파일)\n",
      "================================================================================\n",
      "\n",
      "차수       모델명                                                정확도            \n",
      "--------------------------------------------------------------------------------\n",
      "1st      anthropic/claude-3.7-sonnet                        0.3160         \n",
      "1st      anthropic/claude-sonnet-4.5                        0.3580         \n",
      "1st      google/gemini-2.5-flash                            0.3497         \n",
      "1st      openai/gpt-4.1                                     0.3290         \n",
      "2nd      anthropic/claude-3.7-sonnet                        0.3390         \n",
      "2nd      anthropic/claude-sonnet-4.5                        0.3840         \n",
      "2nd      google/gemini-2.5-flash                            0.3574         \n",
      "2nd      openai/gpt-4.1                                     0.3290         \n",
      "3rd      anthropic/claude-3.7-sonnet                        0.3310         \n",
      "3rd      anthropic/claude-sonnet-4.5                        0.3524         \n",
      "3rd      google/gemini-2.5-flash                            0.3647         \n",
      "3rd      openai/gpt-4.1                                     0.3410         \n",
      "4th      anthropic/claude-3.7-sonnet                        0.3550         \n",
      "4th      anthropic/claude-sonnet-4.5                        0.3500         \n",
      "4th      google/gemini-2.5-flash                            0.3558         \n",
      "4th      openai/gpt-4.1                                     0.3624         \n",
      "5th      anthropic/claude-3.7-sonnet                        0.3250         \n",
      "5th      anthropic/claude-sonnet-4.5                        0.3720         \n",
      "5th      google/gemini-2.5-flash                            0.3410         \n",
      "5th      openai/gpt-4.1                                     0.3480         \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "총 20개 결과 출력 완료\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_accuracy_results('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/8_multiple_exam_+/exam_+_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
