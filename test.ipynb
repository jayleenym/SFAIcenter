{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원래 있던 빈 도메인 채우기\n",
    "- (원래있던 multiple_domain_ALL 활용) fill_multiple_choice_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/evaluation/fill_multiple_choice_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 새로운 빈 도메인만 골라서 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json, os\n",
    "\n",
    "# with open('/Users/yejin/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation_yejin/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json', 'r', encoding='utf-8') as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# re_run_list = []\n",
    "\n",
    "# for d in data:\n",
    "#     if d['domain'] == '':\n",
    "#         re_run_list.append(d)\n",
    "\n",
    "# print(len(re_run_list))\n",
    "\n",
    "# with open('/Users/yejin/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation_yejin/eval_data/2_subdomain/multiple_re_run.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(re_run_list, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python hhhhh.py multiple-fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원래 있던거에 끼어넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, json\n",
    "\n",
    "# ONEDRIVE_PATH = os.path.join(os.path.expanduser(\"~\"), \"Library/CloudStorage/OneDrive-개인/데이터L/selectstar\")\n",
    "\n",
    "# file_name = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json')\n",
    "# with open(file_name, 'r', encoding='utf-8') as f:\n",
    "#     multiple = json.load(f)\n",
    "\n",
    "\n",
    "# file_failed_question = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data/2_subdomain/multiple-fail_response.json')\n",
    "# with open(file_failed_question, 'r', encoding='utf-8') as f:\n",
    "#     multiple_fail = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in multiple:\n",
    "#     # print(q)\n",
    "#     # if q['domain'] == '분류실패':\n",
    "#     if True:\n",
    "#         for m in multiple_fail:\n",
    "#             if (m['file_id'] == q['file_id']) and (m['tag'] == q['tag']):\n",
    "#                 q['domain'] = m['domain']\n",
    "#                 q['subdomain'] = m['subdomain']\n",
    "#                 q['classification_reason'] = m['classification_reason']\n",
    "#                 q['is_calculation'] = m['is_calculation']\n",
    "#                 # break\n",
    "#     # break\n",
    "# with open(file_name, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(multiple, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파싱 안된거 다시 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# file_fail_response = '/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple-fail_fail_response.json'\n",
    "\n",
    "# with open(file_fail_response, 'r', encoding='utf-8') as f:\n",
    "#     multiple_fail_again = json.load(f)\n",
    "\n",
    "# # response 파싱 다시 해보기\n",
    "# for q in multiple:\n",
    "#     # if q['domain'] == '':\n",
    "#     if True:\n",
    "#         for m in multiple_fail_again:\n",
    "#             file_id = m['qna_id'].split('_')[0]\n",
    "#             tag = m['qna_id'].replace(file_id+'_', '')\n",
    "#             if (file_id == q['file_id']) and (tag == q['tag']):\n",
    "#                 q['domain'] = m['domain']\n",
    "#                 q['subdomain'] = m['subdomain']\n",
    "#                 q['classification_reason'] = m['reason']\n",
    "#                 q['is_calculation'] = m['is_calculation']\n",
    "#                 # print(q)\n",
    "#                 # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Q&A 타입별 분류 (multiple_subdomain_classified_ALL.json 만들기 전에 실행)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\subprocess.py\", line 1515, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb8 in position 6: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\subprocess.py\", line 1515, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb8 in position 6: invalid start byte\n",
      "2025-11-19 01:12:15,890 - INFO - === 3단계: Q&A 타입별 분류 (모든 사이클) ===\n",
      "2025-11-19 01:12:15,900 - INFO - 로그 파일 생성/추가: c:\\Users\\Jin\\Desktop\\SFAICenter\\logs\\step3_classify.log\n",
      "2025-11-19 01:12:15,910 - INFO - 모든 사이클의 파일을 찾습니다: C:\\Users\\Jin\\OneDrive\\데이터L\\selectstar\\evaluation\\workbook_data\n",
      "2025-11-19 01:12:15,944 - INFO - 총 94개의 extracted_qna 파일을 찾았습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step3 실행 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 01:13:29,997 - INFO - multiple-choice: 기존 파일 발견: 58482개 항목 로드\n",
      "2025-11-19 01:13:34,485 - INFO - multiple-choice: 새 항목 1956개 추가 (기존 58482개 + 새 1956개 = 총 60438개)\n",
      "2025-11-19 01:13:35,198 - INFO - short-answer: 기존 파일 발견: 3718개 항목 로드\n",
      "2025-11-19 01:13:35,494 - INFO - short-answer: 새 항목 2개 추가 (기존 3718개 + 새 2개 = 총 3720개)\n",
      "2025-11-19 01:13:36,761 - INFO - essay: 기존 파일 발견: 1175개 항목 로드\n",
      "2025-11-19 01:13:36,945 - INFO - essay: 중복 항목으로 인해 새 항목 없음 (기존 1175개 유지)\n",
      "2025-11-19 01:13:37,428 - INFO - etc: 기존 파일 발견: 449개 항목 로드\n",
      "2025-11-19 01:13:37,537 - INFO - etc: 새 항목 266개 추가 (기존 449개 + 새 266개 = 총 715개)\n",
      "2025-11-19 01:13:37,537 - INFO - Q&A 타입별 분류 완료\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step3 실행 완료!\n",
      "결과: {'success': True, 'classified_data': {'multiple-choice': 60438, 'short-answer': 3720, 'essay': 1175, 'etc': 715}}\n"
     ]
    }
   ],
   "source": [
    "from tools.pipeline.steps.step3_classify import Step3Classify\n",
    "\n",
    "# Step3 실행\n",
    "# cycle=None이면 workbook_data 전체에서 모든 사이클의 파일을 자동으로 찾아서 처리합니다\n",
    "# 특정 cycle만 실행하려면 cycle=1, cycle=2, cycle=3 중 하나를 지정하세요\n",
    "step3 = Step3Classify()\n",
    "\n",
    "# cycle 설정 (None이면 모든 사이클 자동 처리)\n",
    "cycle = None  # 또는 특정 cycle: 1, 2, 3\n",
    "\n",
    "print(\"Step3 실행 중...\")\n",
    "result = step3.execute(cycle=cycle)\n",
    "print(\"Step3 실행 완료!\")\n",
    "print(f\"결과: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3 결과 파일 중복 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Step3 결과 파일 중복 확인\n",
      "============================================================\n",
      "\n",
      "multiple-choice.json:\n",
      "  총 항목 수: 60438\n",
      "  고유 항목 수: 60438\n",
      "  중복 항목 수: 0\n",
      "  ✅ 중복 없음\n",
      "\n",
      "short-answer.json:\n",
      "  총 항목 수: 3720\n",
      "  고유 항목 수: 3720\n",
      "  중복 항목 수: 0\n",
      "  ✅ 중복 없음\n",
      "\n",
      "essay.json:\n",
      "  총 항목 수: 1175\n",
      "  고유 항목 수: 1175\n",
      "  중복 항목 수: 0\n",
      "  ✅ 중복 없음\n",
      "\n",
      "etc.json:\n",
      "  총 항목 수: 715\n",
      "  고유 항목 수: 715\n",
      "  중복 항목 수: 0\n",
      "  ✅ 중복 없음\n",
      "\n",
      "============================================================\n",
      "전체 통계:\n",
      "  총 항목 수: 66048\n",
      "  총 중복 항목 수: 0\n",
      "  ✅ 모든 파일에 중복이 없습니다.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "from tools.pipeline.config import ONEDRIVE_PATH\n",
    "\n",
    "# Step3 결과 파일 경로\n",
    "output_dir = os.path.join(ONEDRIVE_PATH, 'evaluation', 'eval_data', '1_filter_with_tags')\n",
    "\n",
    "# 타입별 파일명\n",
    "qna_types = ['multiple-choice', 'short-answer', 'essay', 'etc']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step3 결과 파일 중복 확인\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_duplicates = 0\n",
    "total_items = 0\n",
    "\n",
    "for qna_type in qna_types:\n",
    "    file_path = os.path.join(output_dir, f'{qna_type}.json')\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"\\n{qna_type}.json: 파일 없음\")\n",
    "        continue\n",
    "    \n",
    "    # 파일 로드\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        items = json.load(f)\n",
    "    \n",
    "    if not isinstance(items, list):\n",
    "        print(f\"\\n{qna_type}.json: 잘못된 형식 (리스트가 아님)\")\n",
    "        continue\n",
    "    \n",
    "    total_items += len(items)\n",
    "    \n",
    "    # 중복 확인: (file_id, tag) 기준\n",
    "    keys = []\n",
    "    duplicates = []\n",
    "    duplicate_keys = Counter()\n",
    "    \n",
    "    for item in items:\n",
    "        file_id = item.get('file_id', '')\n",
    "        tag = item.get('tag', '')\n",
    "        key = (file_id, tag)\n",
    "        keys.append(key)\n",
    "        duplicate_keys[key] += 1\n",
    "    \n",
    "    # 중복된 키 찾기\n",
    "    for key, count in duplicate_keys.items():\n",
    "        if count > 1:\n",
    "            duplicates.append((key, count))\n",
    "            total_duplicates += (count - 1)  # 중복 개수 (원본 제외)\n",
    "    \n",
    "    # 중복 개수 계산\n",
    "    duplicate_count = sum(count - 1 for _, count in duplicates)\n",
    "    total_duplicates += duplicate_count\n",
    "    \n",
    "    print(f\"\\n{qna_type}.json:\")\n",
    "    print(f\"  총 항목 수: {len(items)}\")\n",
    "    print(f\"  고유 항목 수: {len(duplicate_keys)}\")\n",
    "    print(f\"  중복 항목 수: {duplicate_count}\")\n",
    "    \n",
    "    if duplicates:\n",
    "        print(f\"  ⚠️ 중복 발견: {len(duplicates)}개 키가 중복됨\")\n",
    "        print(f\"  중복 예시 (최대 5개):\")\n",
    "        for i, (key, count) in enumerate(duplicates[:5]):\n",
    "            print(f\"    - {key}: {count}회\")\n",
    "    else:\n",
    "        print(f\"  ✅ 중복 없음\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"전체 통계:\")\n",
    "print(f\"  총 항목 수: {total_items}\")\n",
    "print(f\"  총 중복 항목 수: {total_duplicates}\")\n",
    "if total_duplicates > 0:\n",
    "    print(f\"  ⚠️ 중복이 발견되었습니다! 중복 제거를 권장합니다.\")\n",
    "else:\n",
    "    print(f\"  ✅ 모든 파일에 중복이 없습니다.\")\n",
    "print(f\"{'=' * 60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3 결과 파일 중복 제거\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Step3 결과 파일 중복 제거\n",
      "============================================================\n",
      "\n",
      "multiple-choice.json:\n",
      "  항목 수: 60438개\n",
      "  ✅ 중복 없음 (변경 없음)\n",
      "\n",
      "short-answer.json:\n",
      "  항목 수: 3720개\n",
      "  ✅ 중복 없음 (변경 없음)\n",
      "\n",
      "essay.json:\n",
      "  항목 수: 1175개\n",
      "  ✅ 중복 없음 (변경 없음)\n",
      "\n",
      "etc.json:\n",
      "  항목 수: 715개\n",
      "  ✅ 중복 없음 (변경 없음)\n",
      "\n",
      "============================================================\n",
      "전체 통계:\n",
      "  제거 전 총 항목 수: 66048\n",
      "  제거 후 총 항목 수: 66048\n",
      "  제거된 중복 항목 수: 0\n",
      "  ✅ 모든 파일에 중복이 없습니다.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tools.pipeline.config import ONEDRIVE_PATH\n",
    "\n",
    "# Step3 결과 파일 경로\n",
    "output_dir = os.path.join(ONEDRIVE_PATH, 'evaluation', 'eval_data', '1_filter_with_tags')\n",
    "\n",
    "# 타입별 파일명\n",
    "qna_types = ['multiple-choice', 'short-answer', 'essay', 'etc']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step3 결과 파일 중복 제거\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_removed = 0\n",
    "total_items_before = 0\n",
    "total_items_after = 0\n",
    "\n",
    "for qna_type in qna_types:\n",
    "    file_path = os.path.join(output_dir, f'{qna_type}.json')\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"\\n{qna_type}.json: 파일 없음 (건너뜀)\")\n",
    "        continue\n",
    "    \n",
    "    # 파일 로드\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        items = json.load(f)\n",
    "    \n",
    "    if not isinstance(items, list):\n",
    "        print(f\"\\n{qna_type}.json: 잘못된 형식 (리스트가 아님, 건너뜀)\")\n",
    "        continue\n",
    "    \n",
    "    items_before = len(items)\n",
    "    total_items_before += items_before\n",
    "    \n",
    "    # 중복 제거: (file_id, tag) 기준, 마지막 항목 유지\n",
    "    seen_keys = {}\n",
    "    unique_items = []\n",
    "    removed_count = 0\n",
    "    \n",
    "    # 역순으로 순회하여 마지막 항목을 유지\n",
    "    for item in reversed(items):\n",
    "        file_id = item.get('file_id', '')\n",
    "        tag = item.get('tag', '')\n",
    "        key = (file_id, tag)\n",
    "        \n",
    "        if key not in seen_keys:\n",
    "            seen_keys[key] = True\n",
    "            unique_items.append(item)\n",
    "        else:\n",
    "            removed_count += 1\n",
    "    \n",
    "    # 역순으로 다시 뒤집어서 원래 순서 유지 (마지막 항목 우선)\n",
    "    unique_items.reverse()\n",
    "    \n",
    "    items_after = len(unique_items)\n",
    "    total_items_after += items_after\n",
    "    total_removed += removed_count\n",
    "    \n",
    "    if removed_count > 0:\n",
    "        # 백업 파일 생성\n",
    "        backup_path = file_path + '.backup'\n",
    "        with open(backup_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(items, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # 중복 제거된 데이터 저장\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(unique_items, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"\\n{qna_type}.json:\")\n",
    "        print(f\"  제거 전: {items_before}개\")\n",
    "        print(f\"  제거 후: {items_after}개\")\n",
    "        print(f\"  제거된 중복: {removed_count}개\")\n",
    "        print(f\"  백업 파일: {backup_path}\")\n",
    "        print(f\"  ✅ 중복 제거 완료\")\n",
    "    else:\n",
    "        print(f\"\\n{qna_type}.json:\")\n",
    "        print(f\"  항목 수: {items_after}개\")\n",
    "        print(f\"  ✅ 중복 없음 (변경 없음)\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"전체 통계:\")\n",
    "print(f\"  제거 전 총 항목 수: {total_items_before}\")\n",
    "print(f\"  제거 후 총 항목 수: {total_items_after}\")\n",
    "print(f\"  제거된 중복 항목 수: {total_removed}\")\n",
    "if total_removed > 0:\n",
    "    print(f\"  ✅ 중복 제거 완료! 백업 파일이 생성되었습니다.\")\n",
    "else:\n",
    "    print(f\"  ✅ 모든 파일에 중복이 없습니다.\")\n",
    "print(f\"{'=' * 60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모의고사 만들기 파이프라인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mock 데이터에서 모의고사 문제 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "ONEDRIVE_PATH = os.path.join(os.path.expanduser(\"~\"), \"Library/CloudStorage/OneDrive-개인/데이터L/selectstar\")\n",
    "BASE_DIR = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data')\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, '2_subdomain')\n",
    "EXAM_DIR = os.path.join(BASE_DIR, '4_multiple_exam')\n",
    "PROJECT_ROOT = os.path.join(os.path.expanduser(\"~\"), \"Desktop/Desktop_AICenter✨/SFAIcenter\")\n",
    "\n",
    "# 세트 이름 매핑\n",
    "set_names = {\n",
    "    1: '1st',\n",
    "    2: '2nd',\n",
    "    3: '3rd',\n",
    "    4: '4th',\n",
    "    5: '5th'\n",
    "}\n",
    "\n",
    "# 로깅 설정\n",
    "log_file = os.path.join(PROJECT_ROOT, 'logs/mock_exam_extraction.log')\n",
    "os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
    "\n",
    "logger = logging.getLogger('mock_exam_extraction')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# 기존 핸들러 제거 (중복 방지)\n",
    "if logger.handlers:\n",
    "    logger.handlers.clear()\n",
    "\n",
    "# 파일 핸들러\n",
    "file_handler = logging.FileHandler(log_file, encoding='utf-8', mode='a')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "\n",
    "# 콘솔 핸들러\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "\n",
    "# 포맷 설정\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "file_handler.setFormatter(formatter)\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "# 핸들러 추가\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# 부모 로거로 전파 방지 (중복 출력 방지)\n",
    "logger.propagate = False\n",
    "\n",
    "# multiple_subdomain_classified_ALL.json 파일에서 모든 데이터 로드\n",
    "ALL_DATA_FILE = os.path.join(PROCESSED_DIR, 'multiple_subdomain_classified_ALL.json')\n",
    "\n",
    "logger.info(f\"데이터 파일 로딩 시작: {ALL_DATA_FILE}\")\n",
    "with open(ALL_DATA_FILE, 'r', encoding='utf-8') as f:\n",
    "    all_data = json.load(f)\n",
    "logger.info(f\"데이터 로딩 완료: 총 {len(all_data)}개 문제\")\n",
    "\n",
    "with open(os.path.join(BASE_DIR, 'exam_statistics.json'), 'r', encoding='utf-8') as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "# 사용된 문제 추적 (file_id, tag) 튜플로 식별\n",
    "used_questions = set()\n",
    "\n",
    "# 4개의 과목별로 처리 (금융일반, 금융심화, 금융실무1, 금융실무2)\n",
    "for exam_name in stats.keys():\n",
    "    logger.info(f\"{'='*50}\")\n",
    "    logger.info(f\"과목: {exam_name}\")\n",
    "    \n",
    "    # 3세트를 위한 리스트 초기화\n",
    "    exam_data_sets = [[], [], [], [], []]\n",
    "    total_exam_questions = 0\n",
    "    \n",
    "    # domain별로 처리\n",
    "    for domain in stats[exam_name].keys():\n",
    "        logger.info(f\"{'-'*50}\")\n",
    "        logger.info(f\"도메인: {domain}\")\n",
    "        \n",
    "        domain_exam_questions = stats[exam_name][domain]['exam_questions']\n",
    "        total_exam_questions += domain_exam_questions\n",
    "        \n",
    "        # 해당 domain의 데이터 필터링\n",
    "        domain_data = [d for d in all_data if d['domain'] == domain]\n",
    "        \n",
    "        # subdomain 별로 문제 추출 - 5세트용\n",
    "        for subdomain, needed_count in stats[exam_name][domain]['exam_subdomain_distribution'].items():\n",
    "            # 해당 subdomain의 데이터 필터링\n",
    "            subdomain_data = [d for d in domain_data if d['subdomain'] == subdomain]\n",
    "            random.shuffle(subdomain_data)\n",
    "            \n",
    "            try:\n",
    "                # 1세트 샘플링\n",
    "                sample1 = random.sample(subdomain_data, needed_count)\n",
    "                remaining_data = [d for d in subdomain_data if d not in sample1]\n",
    "                \n",
    "                # 2세트 샘플링 (1세트 제외한 데이터에서)\n",
    "                sample2 = random.sample(remaining_data, needed_count)\n",
    "                remaining_data = [d for d in remaining_data if d not in sample2]\n",
    "                \n",
    "                # 3세트 샘플링 (1, 2세트 제외한 데이터에서)\n",
    "                sample3 = random.sample(remaining_data, needed_count)\n",
    "                remaining_data = [d for d in remaining_data if d not in sample3]\n",
    "                \n",
    "                # 4세트 샘플링 (1, 2, 3세트 제외한 데이터에서)\n",
    "                sample4 = random.sample(remaining_data, needed_count)\n",
    "                remaining_data = [d for d in remaining_data if d not in sample4]\n",
    "\n",
    "                # 5세트 샘플링 (1, 2, 3, 4세트 제외한 데이터에서)\n",
    "                sample5 = random.sample(remaining_data, needed_count)\n",
    "                remaining_data = [d for d in remaining_data if d not in sample5]\n",
    "                \n",
    "                logger.info(f\"  - {subdomain}: {needed_count} x 5세트 (총 {len(subdomain_data)}개 중 {needed_count * 5}개 사용)\")\n",
    "                \n",
    "                # 각 세트에 추가 및 사용된 문제 추적\n",
    "                for item in sample1 + sample2 + sample3 + sample4 + sample5:\n",
    "                    question_id = (item.get('file_id', ''), item.get('tag', ''))\n",
    "                    used_questions.add(question_id)\n",
    "                \n",
    "                exam_data_sets[0].extend(sample1)\n",
    "                exam_data_sets[1].extend(sample2)\n",
    "                exam_data_sets[2].extend(sample3)\n",
    "                exam_data_sets[3].extend(sample4)\n",
    "                exam_data_sets[4].extend(sample5)\n",
    "                \n",
    "            except ValueError:\n",
    "                # 데이터가 부족한 경우\n",
    "                total_available = len(subdomain_data)\n",
    "                sample1 = subdomain_data[:needed_count] if subdomain_data else []\n",
    "                sample2 = subdomain_data[needed_count:needed_count*2] if len(subdomain_data) > needed_count else []\n",
    "                sample3 = subdomain_data[needed_count*2:needed_count*3] if len(subdomain_data) > needed_count*2 else []\n",
    "                sample4 = subdomain_data[needed_count*3:needed_count*4] if len(subdomain_data) > needed_count*3 else []\n",
    "                sample5 = subdomain_data[needed_count*4:] if len(subdomain_data) > needed_count*4 else []\n",
    "                \n",
    "                logger.warning(f\"  - (ERROR) {subdomain}: {total_available}/{needed_count*5} (데이터 부족: {needed_count*5 - total_available}개 필요)\")\n",
    "                \n",
    "                # 사용된 문제 추적\n",
    "                for item in sample1 + sample2 + sample3 + sample4 + sample5:\n",
    "                    question_id = (item.get('file_id', ''), item.get('tag', ''))\n",
    "                    used_questions.add(question_id)\n",
    "                \n",
    "                exam_data_sets[0].extend(sample1)\n",
    "                exam_data_sets[1].extend(sample2)\n",
    "                exam_data_sets[2].extend(sample3)\n",
    "                exam_data_sets[3].extend(sample4)\n",
    "                exam_data_sets[4].extend(sample5)\n",
    "    \n",
    "    # 5개 세트로 저장\n",
    "    for set_num in range(5):\n",
    "        percentage_total = (len(exam_data_sets[set_num])/total_exam_questions*100) if total_exam_questions > 0 else 0\n",
    "        logger.info(f\"  ====> {set_names[set_num+1]}세트: {len(exam_data_sets[set_num])}/{total_exam_questions} ({percentage_total:.2f}%)\")\n",
    "        \n",
    "        # 출력 디렉토리 생성\n",
    "        set_dir = os.path.join(EXAM_DIR, set_names[set_num+1])\n",
    "        os.makedirs(set_dir, exist_ok=True)\n",
    "        output_file = os.path.join(set_dir, f'{exam_name}_exam.json')\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(exam_data_sets[set_num], f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        logger.info(f\"  ====> 저장 완료: {output_file}\")\n",
    "\n",
    "# 사용되지 않은 나머지 문제 필터링\n",
    "logger.info(f\"\\n{'='*50}\")\n",
    "logger.info(\"사용되지 않은 나머지 문제 필터링 시작...\")\n",
    "remaining_data = []\n",
    "for item in all_data:\n",
    "    question_id = (item.get('file_id', ''), item.get('tag', ''))\n",
    "    if question_id not in used_questions:\n",
    "        remaining_data.append(item)\n",
    "\n",
    "# 나머지 문제 저장\n",
    "logger.info(f\"사용되지 않은 나머지 문제: {len(remaining_data)}개\")\n",
    "\n",
    "remaining_file = os.path.join(PROCESSED_DIR, 'multiple_remaining.json')\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "with open(remaining_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(remaining_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "logger.info(f\"나머지 문제 저장 완료: {remaining_file}\")\n",
    "logger.info(f\"전체: {len(all_data)}개, 사용: {len(used_questions)}개, 남음: {len(remaining_data)}개\")\n",
    "logger.info(\"모든 작업 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple options 오류들\n",
    "- find_multiple_choice_invalid_options.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## short/essay인 객관식 조정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, json\n",
    "\n",
    "# with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/essay_subdomain_classified_ALL.json', 'r', encoding='utf-8') as f:\n",
    "#     essay = json.load(f)\n",
    "\n",
    "# with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/short_subdomain_classified_ALL.json', 'r', encoding='utf-8') as f:\n",
    "#     short = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_multiple = []\n",
    "\n",
    "# # for e in essay:\n",
    "# #     if isinstance(e['options'], list):\n",
    "# #         to_multiple.append(e)\n",
    "# # print(len(to_multiple))\n",
    "\n",
    "# new_short = []\n",
    "# for s in short:\n",
    "#     if isinstance(s['options'], list):\n",
    "#         to_multiple.append(s)\n",
    "#     else:\n",
    "#         new_short.append(s)\n",
    "# print(len(to_multiple), len(short), len(new_short))\n",
    "# # to_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/short_subdomain_classified_ALL.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(new_short, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# with open('/Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/evaluation/eval_data/2_subdomain/multiple_shortans_classified_ALL.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(to_multiple, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원본에 옮기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, time\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# file_list = []\n",
    "\n",
    "# for t in tqdm(to_multiple):\n",
    "#     file_id = t.get('file_id')\n",
    "#     file_list.append(file_id)\n",
    "#     # print(file_id)\n",
    "#     tag = t.get('tag')\n",
    "#     time.sleep(0.5)\n",
    "        \n",
    "#     file_path = os.popen(f\"find /Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/data/FINAL -type f -name '{file_id}_v2.json'\").read().strip()\n",
    "#     if file_path == \"\":\n",
    "#         file_path = os.popen(f\"find /Users/jinym/Desktop/Desktop_AICenter✨/SFAIcenter/data/FINAL -type f -name '{file_id}.json'\").read().strip()\n",
    "#     # print(file_path)\n",
    "\n",
    "#     with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "    \n",
    "#     contents = data['contents']\n",
    "\n",
    "#     for d in contents:\n",
    "#         if d.get('page') == tag.split('_')[1]:\n",
    "#             add_info = d.get('add_info')\n",
    "#             for info in add_info:\n",
    "#                 if info.get('tag') == tag:\n",
    "#                     if info.get('description').get('question') == t.get('question'):\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         # print(\"질문 다름\")\n",
    "#                         info['description']['question'] = t.get('question')\n",
    "\n",
    "#                     if info.get('description').get('answer') == t.get('answer'):\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         # print(\"답 다름\")\n",
    "#                         info['description']['answer'] = t.get('answer')\n",
    "#                     if info.get('description').get('options') == t.get('options'):\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         # print(\"옵션 다름\")\n",
    "#                         info['description']['options'] = t.get('options')\n",
    "#     if file_path.endswith(\"_v2.json\"):\n",
    "#         with open(file_path, 'w', encoding='utf-8') as f:\n",
    "#             json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "#     else:\n",
    "#         with open(file_path.replace(\".json\", \"_v2.json\"), 'w', encoding='utf-8') as f:\n",
    "#             json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(list(set(file_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\subprocess.py\", line 1515, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb8 in position 6: invalid start byte\n",
      "Exception in thread Thread-6 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\subprocess.py\", line 1515, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "  File \"c:\\Users\\Jin\\miniconda3\\envs\\aic\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb8 in position 6: invalid start byte\n",
      "2025-11-19 00:21:08,160 - INFO - exam_config.json에서 도메인-서브도메인 매핑 로드 완료\n",
      "2025-11-19 00:21:08,170 - INFO - 출력 디렉토리: C:\\Users\\Jin\\OneDrive\\데이터L\\selectstar\\evaluation\\eval_data\\2_subdomain\n",
      "2025-11-19 00:21:08,326 - INFO - 통계 정보 저장 완료: C:\\Users\\Jin\\OneDrive\\데이터L\\selectstar\\evaluation\\eval_data\\2_subdomain\\STATS_multiple_subdomain.md\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from tools.qna.processing.qna_subdomain_classifier import QnASubdomainClassifier\n",
    "from tools.pipeline.config import ONEDRIVE_PATH\n",
    "\n",
    "# file_name = os.path.join(ONEDRIVE_PATH, 'evaluation/eval_data/2_subdomain/multiple_subdomain_classified_ALL.json')\n",
    "file_name = os.path.join(ONEDRIVE_PATH, 'evaluation', 'eval_data', '2_subdomain', 'multiple_subdomain_classified_ALL.json')\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    multiple = json.load(f)\n",
    "\n",
    "classifier = QnASubdomainClassifier()\n",
    "classifier.save_statistics(multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "도메인별 통계\n",
      "============================================================\n",
      "도메인                  전체         계산문제       비율        \n",
      "------------------------------------------------------------\n",
      "경영                   104        10         9.62%\n",
      "경제                   125        24         19.20%\n",
      "내부통제                 63         0          0.00%\n",
      "노무                   83         0          0.00%\n",
      "리스크관리                62         9          14.52%\n",
      "보상처리                 112        18         16.07%\n",
      "보험계약                 125        5          4.00%\n",
      "세무                   83         15         18.07%\n",
      "영업                   53         0          0.00%\n",
      "자산운용                 63         10         15.87%\n",
      "회계                   84         37         44.05%\n",
      "------------------------------------------------------------\n",
      "합계                   957        128        13.38%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 도메인별 통계 계산\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "calculation = defaultdict(int)  # 계산 문제 개수\n",
    "total_by_domain = defaultdict(int)  # 전체 문제 개수\n",
    "\n",
    "for question in fifth_exam:\n",
    "    domain = question.get('domain', '미분류')\n",
    "    total_by_domain[domain] += 1\n",
    "    if question.get('is_calculation') == True:\n",
    "        calculation[domain] += 1\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=\" * 60)\n",
    "print(\"도메인별 통계\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'도메인':<20} {'전체':<10} {'계산문제':<10} {'비율':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for domain in sorted(total_by_domain.keys()):\n",
    "    total = total_by_domain[domain]\n",
    "    calc_count = calculation[domain]\n",
    "    ratio = (calc_count / total * 100) if total > 0 else 0\n",
    "    print(f\"{domain:<20} {total:<10} {calc_count:<10} {ratio:.2f}%\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'합계':<20} {sum(total_by_domain.values()):<10} {sum(calculation.values()):<10} {sum(calculation.values())/sum(total_by_domain.values())*100:.2f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation 파일 수정하고 다시 돌리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "from tools.pipeline.config import ONEDRIVE_PATH\n",
    "\n",
    "EXAM_DIR = os.path.join(ONEDRIVE_PATH, 'evaluation','eval_data','4_multiple_exam')\n",
    "# EXAM_DIR = os.path.join(os.path.expanduser(\"~\"), '4_multiple_exam')\n",
    "\n",
    "for exams in os.listdir(EXAM_DIR):\n",
    "    # if exams == \"1st\":\n",
    "    #     first_exam = []\n",
    "    #     for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "    #         with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "    #             first_exam += json.load(f)\n",
    "    # elif exams == \"2nd\":\n",
    "    #     second_exam = []\n",
    "    #     for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "    #         with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "    #             second_exam += json.load(f)\n",
    "    # elif exams == \"3rd\":\n",
    "    #     third_exam = []\n",
    "    #     for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "    #         with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "    #             third_exam += json.load(f)\n",
    "    # elif exams == \"4th\":\n",
    "    #     fourth_exam = []\n",
    "    #     for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "    #         with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "    #             fourth_exam += json.load(f)\n",
    "    if exams == \"5th\":\n",
    "        fifth_exam = []\n",
    "        for exam in os.listdir(os.path.join(EXAM_DIR, exams)):\n",
    "            with open(os.path.join(EXAM_DIR, exams, exam), 'r', encoding='utf-8') as f:\n",
    "                fifth_exam += json.load(f)\n",
    "\n",
    "# multiple = first_exam + second_exam + third_exam + fourth_exam + fifth_exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tools.pipeline.config import ONEDRIVE_PATH\n",
    "\n",
    "model_name = 'ALL'\n",
    "excel_path = os.path.join(ONEDRIVE_PATH, f'evaluation/eval_data/6_exam_evaluation/5th/5th_evaluation_{model_name}.xlsx')\n",
    "print(excel_path)\n",
    "pred_wide = pd.read_excel(excel_path, sheet_name='모델별예측')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty_ids = pred_wide[pred_wide['openai/gpt-5.1'].isna()].id.tolist()\n",
    "print(pred_wide.columns[-1])\n",
    "# print(empty_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_json = []\n",
    "for q in empty_ids:\n",
    "    for m in fifth_exam:\n",
    "        if m['file_id']+\"_\"+m['tag'] == q:\n",
    "            # print(m)\n",
    "            new_json.append(m)\n",
    "\n",
    "print(len(new_json) == len(empty_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(os.path.join(ONEDRIVE_PATH, 'evaluation/model_new.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(new_json, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel 파일에서 정확도 계산 (전체, subject별, domain별, subdomain별)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Set\n",
    "import ast\n",
    "\n",
    "# Excel 파일 경로 설정\n",
    "# excel_path = f'/Users/yejin/Downloads/2nd_evaluation_ALL.xlsx'\n",
    "\n",
    "# Excel 파일 읽기\n",
    "df_sample = pd.read_excel(excel_path, sheet_name='전체데이터')\n",
    "pred_wide = pd.read_excel(excel_path, sheet_name='모델별예측')\n",
    "\n",
    "# pred_wide를 pred_long 형식으로 변환 (melt 사용)\n",
    "# pred_wide는 id 컬럼과 각 모델명이 컬럼으로 있는 와이드 포맷\n",
    "# pred_long은 id, model_name, answer 컬럼이 있는 롱 포맷\n",
    "pred_long = pred_wide.melt(\n",
    "    id_vars=['id'],  # id 컬럼은 그대로 유지\n",
    "    var_name='model_name',  # 모델명 컬럼 이름\n",
    "    value_name='answer'  # 예측값 컬럼 이름\n",
    ")\n",
    "\n",
    "# answer_set을 Set[int]로 변환하는 헬퍼 함수\n",
    "def _parse_answer_set(answer_set):\n",
    "    if isinstance(answer_set, set):\n",
    "        return answer_set\n",
    "    elif isinstance(answer_set, str):\n",
    "        try:\n",
    "            # 문자열을 파싱해서 Set[int]로 변환\n",
    "            parsed = ast.literal_eval(answer_set)\n",
    "            if isinstance(parsed, set):\n",
    "                return parsed\n",
    "            elif isinstance(parsed, (list, tuple)):\n",
    "                return set(parsed)\n",
    "            else:\n",
    "                return {int(parsed)}\n",
    "        except:\n",
    "            # 파싱 실패 시 빈 집합 반환\n",
    "            return set()\n",
    "    else:\n",
    "        # 숫자나 다른 타입인 경우\n",
    "        try:\n",
    "            return {int(answer_set)}\n",
    "        except:\n",
    "            return set()\n",
    "\n",
    "# 정답 여부 계산 함수\n",
    "def _is_correct(pred: float, s: Set[int]) -> float:\n",
    "    if np.isnan(pred) or not s:\n",
    "        return np.nan\n",
    "    return float(int(pred) in s)\n",
    "\n",
    "# 데이터 병합 및 정확도 계산\n",
    "key = df_sample[[\"id\", \"answer_set\"]].copy()\n",
    "merged = pred_long.merge(key, on=\"id\", how=\"left\")\n",
    "merged[\"answer_set\"] = merged[\"answer_set\"].apply(_parse_answer_set)\n",
    "merged[\"correct\"] = merged.apply(lambda r: _is_correct(r[\"answer\"], r[\"answer_set\"]), axis=1)\n",
    "\n",
    "# 전체 정확도 계산\n",
    "acc_by_model = (\n",
    "    merged.groupby(\"model_name\", dropna=False)[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"correct\": \"accuracy\"})\n",
    "    .sort_values(\"accuracy\", ascending=False)\n",
    ")\n",
    "\n",
    "# Excel 파일에 결과 저장\n",
    "# 기존 파일을 읽어서 모든 시트를 유지하면서 특정 시트만 업데이트\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# 기존 파일의 모든 시트 읽기 (업데이트할 시트 제외)\n",
    "existing_sheets = {}\n",
    "try:\n",
    "    book = load_workbook(excel_path)\n",
    "    for sheet_name in book.sheetnames:\n",
    "        if sheet_name not in [\"전체데이터\", \"모델별예측\", \"정확도\", \"Subject별정확도\", \"Subject별문제수\", \n",
    "                              \"Domain별정확도\", \"Domain별문제수\", \"Subdomain별정확도\", \"Subdomain별문제수\"]:\n",
    "            # 업데이트할 시트가 아닌 경우 기존 데이터 읽기\n",
    "            existing_sheets[sheet_name] = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# 모든 시트를 새 파일로 저장\n",
    "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode='w') as writer:\n",
    "    # 기존 시트 유지\n",
    "    for sheet_name, df in existing_sheets.items():\n",
    "        df.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "    # 기본 시트들 업데이트\n",
    "    df_sample.to_excel(writer, index=False, sheet_name=\"전체데이터\")\n",
    "    pred_wide.to_excel(writer, index=False, sheet_name=\"모델별예측\")\n",
    "    acc_by_model.to_excel(writer, index=False, sheet_name=\"정확도\")\n",
    "    \n",
    "    # subject별 정확도 계산 및 저장 (subject 컬럼이 있는 경우)\n",
    "    if 'subject' in df_sample.columns:\n",
    "        subject_info = df_sample[[\"id\", \"subject\"]].copy()\n",
    "        merged_with_subject = merged.merge(subject_info, on=\"id\", how=\"left\")\n",
    "        \n",
    "        subject_acc = (\n",
    "            merged_with_subject.groupby([\"subject\", \"model_name\"], dropna=False)[\"correct\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .pivot(index=\"subject\", columns=\"model_name\", values=\"correct\")\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "        subject_acc.to_excel(writer, index=False, sheet_name=\"Subject별정확도\")\n",
    "        \n",
    "        # Subject별 문제 수 통계\n",
    "        subject_stats = df_sample.groupby('subject').size().reset_index(name='question_count')\n",
    "        subject_stats.to_excel(writer, index=False, sheet_name=\"Subject별문제수\")\n",
    "    \n",
    "    # domain별 정확도 계산 및 저장 (domain 컬럼이 있는 경우)\n",
    "    if 'domain' in df_sample.columns:\n",
    "        domain_info = df_sample[[\"id\", \"domain\"]].copy()\n",
    "        merged_with_domain = merged.merge(domain_info, on=\"id\", how=\"left\")\n",
    "        \n",
    "        domain_acc = (\n",
    "            merged_with_domain.groupby([\"domain\", \"model_name\"], dropna=False)[\"correct\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .pivot(index=\"domain\", columns=\"model_name\", values=\"correct\")\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "        domain_acc.to_excel(writer, index=False, sheet_name=\"Domain별정확도\")\n",
    "        \n",
    "        # Domain별 문제 수 통계\n",
    "        domain_stats = df_sample.groupby('domain').size().reset_index(name='question_count')\n",
    "        domain_stats.to_excel(writer, index=False, sheet_name=\"Domain별문제수\")\n",
    "    \n",
    "    # subdomain별 정확도 계산 및 저장 (subdomain 컬럼이 있는 경우)\n",
    "    if 'subdomain' in df_sample.columns:\n",
    "        subdomain_info = df_sample[[\"id\", \"domain\", \"subdomain\"]].copy()\n",
    "        merged_with_subdomain = merged.merge(subdomain_info, on=\"id\", how=\"left\")\n",
    "        \n",
    "        subdomain_acc = (\n",
    "            merged_with_subdomain.groupby([\"domain\", \"subdomain\", \"model_name\"], dropna=False)[\"correct\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .pivot(index=[\"domain\", \"subdomain\"], columns=\"model_name\", values=\"correct\")\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "        subdomain_acc.to_excel(writer, index=False, sheet_name=\"Subdomain별정확도\")\n",
    "        \n",
    "        # Subdomain별 문제 수 통계\n",
    "        subdomain_stats = df_sample.groupby(['domain', 'subdomain']).size().reset_index(name='question_count')\n",
    "        subdomain_stats.to_excel(writer, index=False, sheet_name=\"Subdomain별문제수\")\n",
    "\n",
    "print(f\"✅ Excel 파일 업데이트 완료: {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
